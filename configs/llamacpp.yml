model_parameters:
  temperature: 0.8
  top_p: 0.9
  top_k: 40
  min_p: 0.1
  # tfs_z: 1.0
  repeat_penalty: 1.2
  max_tokens: 1024  # Maximum tokens to generate

# Configuration parameters for llamacpp
llama_cpp_parameters:
  n_batch: 512
  n_threads: 6      # Number of CPU threads
  n_ctx: 8192       # Context window size