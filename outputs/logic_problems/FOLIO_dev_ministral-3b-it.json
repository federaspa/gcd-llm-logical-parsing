[
  {
    "id": 0,
    "nl_problem": {
      "context": [
        "If people perform in school talent shows often, then they attend and are very engaged with school events.",
        "People either perform in school talent shows often or are inactive and disinterested members of their community.",
        "If people chaperone high school dances, then they are not students who attend the school.",
        "All people who are inactive and disinterested members of their community chaperone high school dances.",
        "All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.",
        "Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school. "
      ],
      "question": "Bonnie performs in school talent shows often.",
      "options": []
    },
    "answer": "C"
  },
  {
    "id": 1,
    "nl_problem": {
      "context": [
        "If people perform in school talent shows often, then they attend and are very engaged with school events.",
        "People either perform in school talent shows often or are inactive and disinterested members of their community.",
        "If people chaperone high school dances, then they are not students who attend the school.",
        "All people who are inactive and disinterested members of their community chaperone high school dances.",
        "All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.",
        "Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school. "
      ],
      "question": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Personalized(x)",
        "Personalized(y)",
        "Personalized(z)",
        "Personalized(z)"
      ],
      "fol_consts": [
        "personalized",
        "personalized",
        "personalized",
        "personalized"
      ],
      "fol_rules": [
        "(Personalized(x) ∧ Personalized(y)) ∧ Personalized(z) → ∀x (Personalized(x) ∧ Personalized(y))",
        "Urnt(x) ∧ Unauthentin(x) → ∀x (Personalized(x) ∧ Unauthentin(x))",
        "Personalized(x) ∧ Personalized(y) → ∀x (Personalized(x) ∧ Personalized(y))",
        "Personalized(x) ∧ Personalized(y) → ∀x (Personalized(x) ∧ Personalized(y))",
        "Personalized(x) ∧ Personalized(y) → ∀x (Personalized(x) ∧ Personalized(y))",
        "Personalized(x) ∧ Personalized(y) → ∀x (Personalized(x) ∧ Personalized(y))"
      ],
      "fol_conc": "Personalized(x) ∧ Personalized(y) → ∀x (Personalized(x) ∧ Personalized(y))",
      "perplexity": 2.9511425495147705
    }
  },
  {
    "id": 2,
    "nl_problem": {
      "context": [
        "If people perform in school talent shows often, then they attend and are very engaged with school events.",
        "People either perform in school talent shows often or are inactive and disinterested members of their community.",
        "If people chaperone high school dances, then they are not students who attend the school.",
        "All people who are inactive and disinterested members of their community chaperone high school dances.",
        "All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.",
        "Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school. "
      ],
      "question": "If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 3,
    "nl_problem": {
      "context": [
        "All employees who schedule a meeting with their customers will appear in the company today. ",
        "Everyone who has lunch in the company schedules meetings with their customers. ",
        "Employees will either have lunch in the company or have lunch at home.",
        "If an employee has lunch at home, then he/she is working remotely from home.",
        "All employees who are in other countries work remotely from home. ",
        "No managers work remotely from home. ",
        "James is either a manager and appears in the company today or neither a manager nor appears in the company today."
      ],
      "question": "James has lunch in the company.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "description": "Cucucucucucucub",
      "perplexity": [
        1.1722805500030518,
        10.487457275390625
      ]
    }
  },
  {
    "id": 4,
    "nl_problem": {
      "context": [
        "All employees who schedule a meeting with their customers will appear in the company today. ",
        "Everyone who has lunch in the company schedules meetings with their customers. ",
        "Employees will either have lunch in the company or have lunch at home.",
        "If an employee has lunch at home, then he/she is working remotely from home.",
        "All employees who are in other countries work remotely from home. ",
        "No managers work remotely from home. ",
        "James is either a manager and appears in the company today or neither a manager nor appears in the company today."
      ],
      "question": "James does not have lunch in the company.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "description": "Dogs are not a type of animal.",
      "perplexity": [
        1.1119762659072876,
        5.4251322746276855
      ]
    }
  },
  {
    "id": 5,
    "nl_problem": {
      "context": [
        "All employees who schedule a meeting with their customers will appear in the company today. ",
        "Everyone who has lunch in the company schedules meetings with their customers. ",
        "Employees will either have lunch in the company or have lunch at home.",
        "If an employee has lunch at home, then he/she is working remotely from home.",
        "All employees who are in other countries work remotely from home. ",
        "No managers work remotely from home. ",
        "James is either a manager and appears in the company today or neither a manager nor appears in the company today."
      ],
      "question": "If James is either a manager or in other countries,  then James either has lunch at home and works remotely from home, or neither has lunch at home nor works remotely from home.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "Dogs are not a type of animal.",
      "perplexity": [
        1.1341708898544312,
        5.0784077644348145
      ]
    }
  },
  {
    "id": 6,
    "nl_problem": {
      "context": [
        "Monkeypox is an infectious disease caused by the monkeypox virus.",
        "Monkeypox virus can occur in certain animals, including humans.",
        "Humans are mammals.",
        "Mammals are animals.",
        "Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.",
        "People feel tired when they get a glu."
      ],
      "question": "There is an animal.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "The answer is not in the first-order linguistics.",
      "perplexity": [
        1.2280211448669434,
        3.3277065753936768
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Monkeypox(x)",
        "Monkeypox(x)",
        "Monkeypox(x)",
        "Mommyoos(x)"
      ],
      "fol_consts": [
        "mommyoos",
        "monkeypoos",
        "monkeypoos",
        "mommyoos"
      ],
      "fol_rules": [
        "(Mommyoos(x) ∧ ¬Isnak(x))",
        "(Mommyoos(x) ∧ ¬Isnak(x))",
        "(Mommyoos(x) ∧ ¬Isnak(x))",
        "(Mommyoos(x) ∧ ¬Isnak(x))",
        "(Mommyoos(x) ∧ ¬Isnak(x))"
      ],
      "fol_conc": "Mommyoos(x) ∧ Isnak(x) ∧ Isnak(x) ∧ Isnak(x) ∧ Isnak(x) ∧ Isnak(x)",
      "perplexity": 3.5422377586364746
    }
  },
  {
    "id": 7,
    "nl_problem": {
      "context": [
        "Monkeypox is an infectious disease caused by the monkeypox virus.",
        "Monkeypox virus can occur in certain animals, including humans.",
        "Humans are mammals.",
        "Mammals are animals.",
        "Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.",
        "People feel tired when they get a glu."
      ],
      "question": "No one gets flu.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.1830657720565796,
        2.261021375656128
      ]
    }
  },
  {
    "id": 8,
    "nl_problem": {
      "context": [
        "Monkeypox is an infectious disease caused by the monkeypox virus.",
        "Monkeypox virus can occur in certain animals, including humans.",
        "Humans are mammals.",
        "Mammals are animals.",
        "Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.",
        "People feel tired when they get a glu."
      ],
      "question": "Symptons of Monkeypox include coughing.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "Cucumber",
        "Peach",
        "Cucumber",
        "Ppeach",
        "Cucumber",
        "Ppeach",
        "Cucumber",
        "Cucumber",
        "Ppeach",
        "Cucumber",
        "Ppeach"
      ],
      "perplexity": [
        1.2634905576705933,
        3.356273889541626
      ]
    }
  },
  {
    "id": 9,
    "nl_problem": {
      "context": [
        "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould’s wild turkey, Merriam’s wild",
        "turkey, Rio Grande wild turkey, and Ocellated wild turkey.",
        "Tom is not an Eastern wild turkey.",
        "Tom is not an Osceola wild turkey.",
        "Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.",
        "Tom is a wild turkey."
      ],
      "question": "Tom is an Ocellated wild turkey.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "Real, so they are not just a symbol of love.",
      "perplexity": [
        1.1964977979660034,
        3.1991519927978516
      ]
    }
  },
  {
    "id": 10,
    "nl_problem": {
      "context": [
        "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould’s wild turkey, Merriam’s wild",
        "turkey, Rio Grande wild turkey, and Ocellated wild turkey.",
        "Tom is not an Eastern wild turkey.",
        "Tom is not an Osceola wild turkey.",
        "Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.",
        "Tom is a wild turkey."
      ],
      "question": "Tom is an Eastern wild turkey.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "real",
      "perplexity": [
        1.2788527011871338,
        6.025155067443848
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Nautical(x)",
        "Nautical(n)",
        "Nautical(n)",
        "Nautical(n)",
        "Nautical(n)"
      ],
      "fol_consts": [
        "nautical",
        "nautical",
        "nautical",
        "nautical",
        "nautical",
        "nautical",
        "nautical"
      ],
      "fol_rules": [
        "(Nautical(x)) ∧ (Nautical(n) ∧ Nautical(n) ∧ Nautical(n) ∧ Nautical(n) ∧ Nautical(n) ∧ Nautical(n))"
      ],
      "fol_conc": "Tomisanatrut(n) ∧ Nautical(n) ∧ Nautical(n) ∧ Nautical(n) ∧ Nautical(n) ∧ Nautical(n)",
      "perplexity": 3.807342290878296
    }
  },
  {
    "id": 11,
    "nl_problem": {
      "context": [
        "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould’s wild turkey, Merriam’s wild",
        "turkey, Rio Grande wild turkey, and Ocellated wild turkey.",
        "Tom is not an Eastern wild turkey.",
        "Tom is not an Osceola wild turkey.",
        "Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.",
        "Tom is a wild turkey."
      ],
      "question": "Joey is a wild turkey.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "problem": [
        "problem",
        "problem",
        "problem",
        "problem",
        "problem"
      ],
      "perplexity": [
        1.1193783283233643,
        2.9718515872955322
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Novaueein(x)",
        "Novaueein(x)",
        "Novaueein(x)",
        "Novaueein(x)",
        "Novaueein(x)"
      ],
      "fol_consts": [
        "novaueein",
        "novaueein",
        "novaueein",
        "novaueein",
        "novaueein"
      ],
      "fol_rules": [
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "(Novaueein(x) ∧ ¬Isnout(x))",
        "Nonexion(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x)"
      ],
      "fol_conc": "Novaueein(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x) ∧ ¬Isnout(x)",
      "perplexity": 2.765815258026123
    }
  },
  {
    "id": 12,
    "nl_problem": {
      "context": [
        "A Japanese game company created the game the Legend of Zelda.",
        "All games in the Top 10 list are made by Japanese game companies.",
        "[BG] If a game sells more than one million copies, then it will be selected into the Top 10 list.",
        "The Legend of Zelda sold more than one million copies."
      ],
      "question": "The Legend of Zelda is in the Top 10 list.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "The Legend of Zelda is released in the Top 10 list.",
      "perplexity": [
        1.2039642333984375,
        3.92067289352417
      ]
    }
  },
  {
    "id": 13,
    "nl_problem": {
      "context": [
        "A Japanese game company created the game the Legend of Zelda.",
        "All games in the Top 10 list are made by Japanese game companies.",
        "[BG] If a game sells more than one million copies, then it will be selected into the Top 10 list.",
        "The Legend of Zelda sold more than one million copies."
      ],
      "question": "FIFA 22 is made by a Japanese video game company.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "total_elements": 4,
      "elements": [
        "apple",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi"
      ],
      "perplexity": [
        1.1764322519302368,
        4.473402500152588
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Figaueein(x)",
        "Gigaueein(x)",
        "Gigaueein(x)",
        "Celebrate(x)"
      ],
      "fol_consts": [
        "iolioli",
        "iolioli",
        "iolioli",
        "iolioli",
        "iolioli"
      ],
      "fol_rules": [
        "(Skaueein(x) ∧ ¬Be(x, true))",
        "(Skaueein(x) ∧ ¬Be(x, true))",
        "(Iolioli(x) ∧ ¬Be(x, true))",
        "(Iolioli(x) ∧ ¬Be(x, true))",
        "(Iolioli(x) ∧ ¬Be(x, true))"
      ],
      "fol_conc": "Iolioli(x) ∧ ¬Be(x, true) → ∀x (Skaueein(x) ∧ ¬Be(x, true))",
      "perplexity": 3.5110087394714355
    }
  },
  {
    "id": 14,
    "nl_problem": {
      "context": [
        "A Japanese game company created the game the Legend of Zelda.",
        "All games in the Top 10 list are made by Japanese game companies.",
        "[BG] If a game sells more than one million copies, then it will be selected into the Top 10 list.",
        "The Legend of Zelda sold more than one million copies."
      ],
      "question": "The Legend of Zelda is not in the Top 10 list.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "examples": [
        "Cube: 123",
        "Cube: 123",
        "Cube: 123",
        "Cube: 123",
        "Cube: 123",
        "Cube: 123",
        "Cube: 123",
        "Cube: 123",
        "Cube: 123",
        "Cube: 123"
      ],
      "perplexity": [
        1.1457456350326538,
        1.8803343772888184
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Coldennaye(x)",
        "Coldennaye(x)",
        "Coldennaye(x)",
        "Coldennaye(x)",
        "Coldennaye(x)"
      ],
      "fol_consts": [
        "coldennaye",
        "softennaye",
        "softennaye",
        "softennaye",
        "softennaye"
      ],
      "fol_rules": [
        "Coldennaye(x) ∧ Coldennaye(x) ∧ Coldennaye(x)"
      ],
      "fol_conc": "Coldennaye(x) ∧ Coldennaye(x) ∧ Coldennaye(x)",
      "perplexity": 3.1281065940856934
    }
  },
  {
    "id": 15,
    "nl_problem": {
      "context": [
        "All squares have four sides.",
        "All four-sided things are shapes. "
      ],
      "question": "All squares are shapes.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "Caffe",
        "Caffe",
        "Caffe",
        "Caffe",
        "Caffe",
        "Caffe",
        "Caffe",
        "Caffe",
        "Caffe"
      ],
      "perplexity": [
        1.1878480911254883,
        2.569781541824341
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Square(x)",
        "Square(y)",
        "Square(z)",
        "Square(z)"
      ],
      "fol_consts": [
        "x1",
        "y1",
        "z1",
        "z2",
        "z3",
        "z4",
        "z5"
      ],
      "fol_rules": [
        "(Square(x) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic))"
      ],
      "fol_conc": "(Square(x) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic) ∧ ¬Is(x, elliptic))",
      "perplexity": 3.0832669734954834
    }
  },
  {
    "id": 16,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "Rock is a turtle.",
      "options": []
    },
    "answer": "C",
    "logic_problem_gcd": {
      "fol_preds": [
        "Rrock(x)",
        "Rout(x)",
        "Rout(x)"
      ],
      "fol_consts": [
        "rrock",
        "rout",
        "rout",
        "rout",
        "rout",
        "rout",
        "rout",
        "rout",
        "rout",
        "rout"
      ],
      "fol_rules": [
        "(Rrock(x)) ∧ (Rout(x)) ∧ (Rout(x) ∧ Rout(x))"
      ],
      "fol_conc": "Rrock(x) ∧ Rout(x) ∧ Rout(x) ∧ Rout(x) ∧ Rout(x) ∧ Rout(x)",
      "perplexity": 3.727752447128296
    }
  },
  {
    "id": 17,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "Rock is not a turtle.",
      "options": []
    },
    "answer": "C"
  },
  {
    "id": 18,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "Rock is a turtle or cute.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 19,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "If Rock is not both a turtle and a squirrel, then Rock is either cute or skittish.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "Cubes are a type of geometric shape and are used in geometry and engineering. Cubes are a geometric pattern that can be used to create larger, more complex structures. Cubes are a geometric pattern that can be used to create larger, more complex structures.",
      "perplexity": [
        1.1422138214111328,
        3.664803981781006
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Ruby(x)"
      ],
      "fol_consts": [
        "ruby",
        "squirrel",
        "rock"
      ],
      "fol_rules": [
        "(Ruby(x) ∧ ¬Ruby(x))",
        "(Ruby(x) → ¬Ruby(x))",
        "Crock(x) → ¬Crock(x)"
      ],
      "fol_conc": "Crock(x) → ¬Crock(x)",
      "perplexity": 3.4071061611175537
    }
  },
  {
    "id": 20,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "If Rock is cute and still, then Rock is a turtle and skittish.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.0467369556427002,
        1.2770713567733765
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Rina(x)",
        "Rina(x)",
        "Rina(x)"
      ],
      "fol_consts": [
        "rina",
        "rina",
        "rina"
      ],
      "fol_rules": [
        "(Rina(x) ∧ ¬Rina(x)) ∧ (Rina(x) ∧ ¬Rina(x))"
      ],
      "fol_conc": "Rina(x) ∧ (Rina(x) ∧ ¬Rina(x))",
      "perplexity": 3.730426788330078
    }
  },
  {
    "id": 21,
    "nl_problem": {
      "context": [
        "\"Stranger Things\" is a popular Netflix show.",
        "If a Netflix show is popular, Karen will binge-watch it.",
        "If and only if Karen binge-watches a Netflix show, she will download it.",
        "Karen does not download \"Black Mirror\".",
        "\"Black Mirror\" is a Netflix show.",
        "If Karen binge-watches a Netflix show, she will share it to Lisa."
      ],
      "question": "Karen will share \"Stranger Things\" to Lisa.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "Celebration",
        "Celebration",
        "Celebration",
        "Celebration",
        "Celebration",
        "Celebration",
        "Celebration",
        "Celebration",
        "Celebration"
      ],
      "perplexity": [
        1.106801152229309,
        2.679151773452759
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)"
      ],
      "fol_consts": [
        "trustworthy1",
        "trustworthy2",
        "trustworthy3",
        "trustworthy4",
        "trustworthy5",
        "trustworthy6",
        "trustworthy7",
        "trustworthy8",
        "trustworthy9"
      ],
      "fol_rules": [
        "(Trustworthy(x) ∧ Trustworthy(x)) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x)"
      ],
      "fol_conc": "Cosntivous(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x)",
      "perplexity": 3.5156843662261963
    }
  },
  {
    "id": 22,
    "nl_problem": {
      "context": [
        "\"Stranger Things\" is a popular Netflix show.",
        "If a Netflix show is popular, Karen will binge-watch it.",
        "If and only if Karen binge-watches a Netflix show, she will download it.",
        "Karen does not download \"Black Mirror\".",
        "\"Black Mirror\" is a Netflix show.",
        "If Karen binge-watches a Netflix show, she will share it to Lisa."
      ],
      "question": "\"Black Mirror\" is popular.",
      "options": []
    },
    "answer": "B",
    "logic_problem_gcd": {
      "fol_preds": [
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)"
      ],
      "fol_consts": [
        "trustworthy",
        "trustworthy",
        "trustworthy",
        "trustworthy",
        "trustworthy"
      ],
      "fol_rules": [
        "(Trustworthy(x) ∧ Trustworthy(x))",
        "Trustworthy(x) → ∀x (Trustworthy(x) ∧ Trustworthy(x))",
        "Trustworthy(x) → ∀x (Trustworthy(x) ∧ Trustworthy(x))",
        "Trustworthy(x) → ∀x (Trustworthy(x) ∧ Trustworthy(x))",
        "Trustworthy(x) → ∀x (Trustworthy(x) ∧ Trustworthy(x))",
        "Trustworthy(x) → ∀x (Trustworthy(x) ∧ Trustworthy(x))"
      ],
      "fol_conc": "Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x)",
      "perplexity": 2.8548357486724854
    }
  },
  {
    "id": 23,
    "nl_problem": {
      "context": [
        "\"Stranger Things\" is a popular Netflix show.",
        "If a Netflix show is popular, Karen will binge-watch it.",
        "If and only if Karen binge-watches a Netflix show, she will download it.",
        "Karen does not download \"Black Mirror\".",
        "\"Black Mirror\" is a Netflix show.",
        "If Karen binge-watches a Netflix show, she will share it to Lisa."
      ],
      "question": "Karen will share \"Black Mirror\" to Lisa.",
      "options": []
    },
    "answer": "C",
    "logic_problem_gcd": {
      "fol_preds": [
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)",
        "Trustworthy(x)"
      ],
      "fol_consts": [
        "trustworthy1",
        "trustworthy2",
        "trustworthy3",
        "trustworthy4",
        "trustworthy5",
        "trustworthy6",
        "trustworthy7",
        "trustworthy8",
        "trustworthy9"
      ],
      "fol_rules": [
        "(Trustworthy(x) ∧ Trustworthy(x)) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x)"
      ],
      "fol_conc": "Cosntivous(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x) ∧ Trustworthy(x)",
      "perplexity": 3.5302317142486572
    }
  },
  {
    "id": 24,
    "nl_problem": {
      "context": [
        "Beijing is the capital of the People's Republic of China. ",
        "Beijing is the world's most populous national capital city.",
        "Beijing is located in Northern China.",
        "Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.",
        "Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics",
        "Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world."
      ],
      "question": "Beijing has hosted both the 2008 Summer Olympics and a winter olympics.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "The Beatles",
      "year": 1962,
      "genre": "The Beatles",
      "perplexity": [
        1.1374400854110718,
        3.50932240486145
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Beaten(x)",
        "Beauty(x)",
        "Beauty(x)",
        "Beauty(x)"
      ],
      "fol_consts": [
        "city",
        "city",
        "city",
        "city",
        "city",
        "city",
        "city"
      ],
      "fol_rules": [
        "(Beauty(x) ∧ ¬Beauty(x))",
        "(Beauty(x) ∧ ¬Beauty(x))",
        "(Beauty(x) ∧ ¬Beauty(x))",
        "(Beauty(x) ∧ ¬Beauty(x))",
        "(Beauty(x) ∧ ¬Beauty(x))"
      ],
      "fol_conc": "Beauty(x) ∧ Beauty(x) ∧ Beauty(x) ∧ Beauty(x) ∧ Beauty(x) ∧ Beauty(x)",
      "perplexity": 3.2083094120025635
    }
  },
  {
    "id": 25,
    "nl_problem": {
      "context": [
        "Beijing is the capital of the People's Republic of China. ",
        "Beijing is the world's most populous national capital city.",
        "Beijing is located in Northern China.",
        "Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.",
        "Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics",
        "Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world."
      ],
      "question": "Beijing is located in southern China.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain"
      ],
      "perplexity": [
        1.516135334968567,
        4.17343282699585
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Beaten(x)",
        "Beauty(x)",
        "Beauty(x)",
        "Beauty(x)",
        "Beauty(x)"
      ],
      "fol_consts": [
        "city",
        "city",
        "city",
        "city",
        "city",
        "city",
        "city"
      ],
      "fol_rules": [
        "(Beauty(x) ∧ ¬Beauty(x))",
        "(Beauty(x) ∧ ¬Beauty(x))",
        "(Beauty(x) ∧ ¬Beauty(x))",
        "(Beauty(x) ∧ ¬Beauty(x))",
        "None(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x)"
      ],
      "fol_conc": "Beauty(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x) ∧ ¬Beauty(x)",
      "perplexity": 3.231947898864746
    }
  },
  {
    "id": 26,
    "nl_problem": {
      "context": [
        "Beijing is the capital of the People's Republic of China. ",
        "Beijing is the world's most populous national capital city.",
        "Beijing is located in Northern China.",
        "Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.",
        "Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics",
        "Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world."
      ],
      "question": "Beijing is the second largest Chinese city by urban population.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain"
      ],
      "perplexity": [
        1.2037198543548584,
        3.9877963066101074
      ]
    }
  },
  {
    "id": 27,
    "nl_problem": {
      "context": [
        "All aliens are extraterrestrial.",
        "If someone is from Mars, then they are aliens.",
        "No extraterrestrial is human.",
        "Everyone from Earth is a human.",
        "Marvin cannot be from Earth and from Mars.",
        "If Marvin is not from Earth, then Marvin is an extraterrestrial."
      ],
      "question": "Marvin is an alien.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "Catcher in the Rye"
      ],
      "examples": [
        "The Catcher in the Rye",
        "The Catcher in the Rye",
        "The Catcher in the Rye",
        "The Catcher in the Rye",
        "The Catcher in the Rye"
      ],
      "perplexity": [
        1.3466068506240845,
        2.2697598934173584
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Alien(x)",
        "Alien(y)",
        "Alien(z)",
        "Alien(z)"
      ],
      "fol_consts": [
        "eatable",
        "eatable",
        "eatable",
        "eatable",
        "eatable",
        "eatable",
        "eatable",
        "eatable",
        "eatable",
        "eatable"
      ],
      "fol_rules": [
        "(Alien(x) ∧ ¬Isaltee(x))",
        "(Alien(y) ∧ ¬Isaltee(y))",
        "(Alien(z) ∧ ¬Isaltee(z))",
        "(Alien(z) ∧ ¬Isaltee(z))",
        "(Alien(z) ∧ ¬Isaltee(z))"
      ],
      "fol_conc": "Items(z) ∧ ¬Isaltee(z) ∧ ¬Isaltee(z) ∧ ¬Isaltee(z) ∧ ¬Isaltee(z) ∧ ¬Isaltee(z)",
      "perplexity": 3.3132848739624023
    }
  },
  {
    "id": 28,
    "nl_problem": {
      "context": [
        "All aliens are extraterrestrial.",
        "If someone is from Mars, then they are aliens.",
        "No extraterrestrial is human.",
        "Everyone from Earth is a human.",
        "Marvin cannot be from Earth and from Mars.",
        "If Marvin is not from Earth, then Marvin is an extraterrestrial."
      ],
      "question": "Marvin is neither a human nor from Mars.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "title": "Cassandra's Catch in the Rhyme",
      "director": "James Cameron",
      "director_who": "Christopher Nolan",
      "director_who_directed": "Cassandra's Catch in the Rhyme",
      "perplexity": [
        1.2328320741653442,
        2.852264404296875
      ]
    }
  },
  {
    "id": 29,
    "nl_problem": {
      "context": [
        "All aliens are extraterrestrial.",
        "If someone is from Mars, then they are aliens.",
        "No extraterrestrial is human.",
        "Everyone from Earth is a human.",
        "Marvin cannot be from Earth and from Mars.",
        "If Marvin is not from Earth, then Marvin is an extraterrestrial."
      ],
      "question": "If Marvin is not from Mars, then Marvin is a human.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "total": 1,
      "perplexity": [
        1.269138216972351,
        3.0672242641448975
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Alien(x)",
        "Alien(y)",
        "Alien(z)",
        "Alien(z)"
      ],
      "fol_consts": [
        "frome",
        "frome",
        "frome",
        "frome"
      ],
      "fol_rules": [
        "(Alien(x) ∧ ¬Isalien(x))",
        "(Alien(y) ∧ ¬Isalien(y))",
        "(Alien(z) ∧ ¬Isalien(z))",
        "(Alien(z) ∧ ¬Isalien(z))"
      ],
      "fol_conc": "Items(z) ∧ Isalien(z) ∧ Isalien(z) ∧ Isalien(z) ∧ Isalien(z) ∧ Isalien(z)",
      "perplexity": 3.9647068977355957
    }
  },
  {
    "id": 30,
    "nl_problem": {
      "context": [
        "A person is either a Grand Slam champion or an Oscar-nominated actor.",
        "All people who are Grand Slam champions are professional tennis players.",
        "All Oscar-nominated actors are celebrities.",
        "All professional tennis players are athletes.",
        "If a person is a celebrity then they are well paid.",
        "If a person is an athlete then they are famous.",
        "All well-paid people live in tax havens.",
        "If Djokovic is famous and is an athlete, then Djokovic lives in well paid."
      ],
      "question": "Djokovic is a Grand Slam champion.",
      "options": []
    },
    "answer": "C",
    "logic_problem_gcd": {
      "fol_preds": [
        "Grossing(x)",
        "Caution(x)",
        "Caution(x)",
        "Djovicianalty(x)"
      ],
      "fol_consts": [
        "grossing",
        "caution",
        "caution",
        "djovicianalty"
      ],
      "fol_rules": [
        "(Grossing(x) ∧ Caution(x)) ∧ Caution(x) ∧ Djovicianalty(x) ∧ Caution(x) ∧ Djovicianalty(x) ∧ Djovicianalty(x)",
        "Djovicianalty(x) ∧ Caution(x) ∧ Djovicianalty(x) ∧ Djovicianalty(x) ∧ Djovicianalty(x) ∧ Djovicianalty(x)"
      ],
      "fol_conc": "Djovicianalty(x) ∧ Caution(x) ∧ Djovicianalty(x) ∧ Djovicianalty(x) ∧ Djovicianalty(x) ∧ Djovicianalty(x)",
      "perplexity": 3.167987823486328
    }
  },
  {
    "id": 31,
    "nl_problem": {
      "context": [
        "A person is either a Grand Slam champion or an Oscar-nominated actor.",
        "All people who are Grand Slam champions are professional tennis players.",
        "All Oscar-nominated actors are celebrities.",
        "All professional tennis players are athletes.",
        "If a person is a celebrity then they are well paid.",
        "If a person is an athlete then they are famous.",
        "All well-paid people live in tax havens.",
        "If Djokovic is famous and is an athlete, then Djokovic lives in well paid."
      ],
      "question": "Djokovic lives in a tax haven.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Grossing(x)",
        "Caution(x)",
        "Caution(x)",
        "Djovician(x)"
      ],
      "fol_consts": [
        "caution",
        "djovician",
        "djovician",
        "djovician",
        "djovician",
        "djovician",
        "djovician",
        "djovician",
        "djovician"
      ],
      "fol_rules": [
        "(Grossing(x) ∧ Caution(x)) ∧ (Caution(x) ∧ Djovician(x))"
      ],
      "fol_conc": "Djovician(x) ∧ Djovician(x) ∧ Djovician(x)",
      "perplexity": 3.7135984897613525
    }
  },
  {
    "id": 32,
    "nl_problem": {
      "context": [
        "A person is either a Grand Slam champion or an Oscar-nominated actor.",
        "All people who are Grand Slam champions are professional tennis players.",
        "All Oscar-nominated actors are celebrities.",
        "All professional tennis players are athletes.",
        "If a person is a celebrity then they are well paid.",
        "If a person is an athlete then they are famous.",
        "All well-paid people live in tax havens.",
        "If Djokovic is famous and is an athlete, then Djokovic lives in well paid."
      ],
      "question": "Djokovic does not live in a tax haven.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "name": "The Beatles",
      "company": "The Beatles",
      "perplexity": [
        1.143267273902893,
        6.307462215423584
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Grossing(x)",
        "Caution(x)",
        "Caution(x)",
        "Djovicsaization(x)"
      ],
      "fol_consts": [
        "caution",
        "djovicsaization"
      ],
      "fol_rules": [
        "(Grossing(x) ∧ Caution(x)) ∧ Caution(x) ∧ Djovicsaization(x) ∧ Djovicsaization(x) ∧ Djovicsaization(x) ∧ Djovicsaization(x)"
      ],
      "fol_conc": "Djovicsaization(x) ∧ Caution(x) ∧ Djovicsaization(x) ∧ Djovicsaization(x) ∧ Djovicsaization(x) ∧ Djovicsaization(x)",
      "perplexity": 3.5798511505126953
    }
  },
  {
    "id": 33,
    "nl_problem": {
      "context": [
        "Diamond Mine is a professional wrestling stable, formed in WWE.",
        "Roderick Strong leads Diamond Mine.",
        "Diamond Mine includes the Creed Brothers, and Ivy Nile.",
        "Imperium has a feud with Diamond Mine."
      ],
      "question": "Roderick strong leads a professional wrestling stable.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Diamondmine(x)",
        "Diamondwinn(x)",
        "Diamondwinn(x)"
      ],
      "fol_consts": [
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn"
      ],
      "fol_rules": [
        "∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x))"
      ],
      "fol_conc": "Diamonds(x) ∧ Diamondfinn(x) ∧ Diamondfinn(x) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x))",
      "perplexity": 2.9750657081604004
    }
  },
  {
    "id": 34,
    "nl_problem": {
      "context": [
        "Diamond Mine is a professional wrestling stable, formed in WWE.",
        "Roderick Strong leads Diamond Mine.",
        "Diamond Mine includes the Creed Brothers, and Ivy Nile.",
        "Imperium has a feud with Diamond Mine."
      ],
      "question": "Roderick strong leads the Creed Brothers.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "profiles": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.122471809387207,
        1.374218225479126
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Diamondmine(x)",
        "Diamondwinn(x)",
        "Diamondwinn(x)"
      ],
      "fol_consts": [
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn",
        "diamondfinn"
      ],
      "fol_rules": [
        "∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x))"
      ],
      "fol_conc": "Diamonds(x) ∧ Diamondfinn(x) ∧ Diamondfinn(x) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x)) ∧ ∀x (Diamondfinn(x))",
      "perplexity": 3.1243584156036377
    }
  },
  {
    "id": 35,
    "nl_problem": {
      "context": [
        "Diamond Mine is a professional wrestling stable, formed in WWE.",
        "Roderick Strong leads Diamond Mine.",
        "Diamond Mine includes the Creed Brothers, and Ivy Nile.",
        "Imperium has a feud with Diamond Mine."
      ],
      "question": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "The Catcher in the Rhone",
      "perplexity": [
        1.2453649044036865,
        6.118738174438477
      ]
    }
  },
  {
    "id": 36,
    "nl_problem": {
      "context": [
        "Symphony No. 9 is a music piece.",
        "Composers write music pieces.",
        "Beethoven wrote Symphony No. 9.",
        "Vienna Music Society premiered Symphony No. 9.",
        "Vienna Music Society is an orchestra.",
        "Beethoven leads the Vienna Music Society.",
        "Orchestras are led by conductors."
      ],
      "question": "Beethoven is a composer.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Parisian(x)",
        "Newtian(x)",
        "Newtian(x)"
      ],
      "fol_consts": [
        "name",
        "name",
        "name",
        "name",
        "name",
        "name",
        "name",
        "name",
        "name",
        "name"
      ],
      "fol_rules": [
        "(Parisian(x)) ∧ (Newtian(x)) ∧ (Newtian(x) ∧ ¬Beethoven(x))"
      ],
      "fol_conc": "This(s) ∧ ∃x (Parisian(x)) ∧ ∃x (Newtian(x)) ∧ ∃x (Newtian(x) ∧ ¬Beethoven(x))",
      "perplexity": 4.018858432769775
    }
  },
  {
    "id": 37,
    "nl_problem": {
      "context": [
        "Symphony No. 9 is a music piece.",
        "Composers write music pieces.",
        "Beethoven wrote Symphony No. 9.",
        "Vienna Music Society premiered Symphony No. 9.",
        "Vienna Music Society is an orchestra.",
        "Beethoven leads the Vienna Music Society.",
        "Orchestras are led by conductors."
      ],
      "question": "Some orchestras premiered music pieces.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "The painting ",
      "The Starry Night": "The Starry Night is a painting.",
      "The Starry Night is a painting.": "The Starry Night is a painting.",
      "perplexity": [
        1.259440302848816,
        1.856911063194275
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Music1(x)",
        "Music2(x)",
        "Music3(x)",
        "Music4(x)"
      ],
      "fol_consts": [
        "mnn",
        "nnn",
        "nnn",
        "nnn",
        "nnn",
        "nnn",
        "nnn",
        "nnn",
        "nnn"
      ],
      "fol_rules": [
        "(Music1(x)) ∧ (Music2(x)) ∧ (Music3(x)) ∧ (Music4(x)) ∧ (Music1(x)) ∧ (Music2(x))"
      ],
      "fol_conc": "Music1(x) ∧ Music2(x) ∧ Music3(x) ∧ Music4(x) ∧ (Music1(x) ∧ Music2(x) ∧ Music3(x) ∧ Music4(x))",
      "perplexity": 3.559659242630005
    }
  },
  {
    "id": 38,
    "nl_problem": {
      "context": [
        "Symphony No. 9 is a music piece.",
        "Composers write music pieces.",
        "Beethoven wrote Symphony No. 9.",
        "Vienna Music Society premiered Symphony No. 9.",
        "Vienna Music Society is an orchestra.",
        "Beethoven leads the Vienna Music Society.",
        "Orchestras are led by conductors."
      ],
      "question": "Beethoven is not a conductor.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.2714972496032715,
        8.355152130126953
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Parisian(x)",
        "Parisian(y)",
        "Parisian(z)",
        "Parisian(z)",
        "Parisian(z)"
      ],
      "fol_consts": [
        "city",
        "city",
        "city",
        "city",
        "city",
        "city",
        "city"
      ],
      "fol_rules": [
        "(Parisian(x) ∧ ¬Be(x, sound))",
        "∀x (Parisian(x) → ¬Be(x, sound))",
        "∀x (Parisian(x) → ¬Be(x, sound))",
        "∀x (Parisian(x) → ¬Be(x, sound))",
        "∀x (Parisian(x) → ¬Be(x, sound))",
        "∀x (Parisian(x) → ¬Be(x, sound))"
      ],
      "fol_conc": "Parisian(x) ∧ ¬Be(x, sound) ∧ ¬Be(x, sound) ∧ ¬Be(x, sound) ∧ ¬Be(x, sound) ∧ ¬Be(x, sound)",
      "perplexity": 2.76175594329834
    }
  },
  {
    "id": 39,
    "nl_problem": {
      "context": [
        "All of Zaha Hadid's design styles are timeless.",
        "No mass product design is timeless.",
        "Either Zaha Hadid's design style or Kelly Wearstler's design style. ",
        "All of Kelly Wearstler's design styles are evocative.",
        "All of Kelly Wearstler's design styles are dreamy.",
        "If a design by Max is timeless, then a design by Max is a mass product design and evocative."
      ],
      "question": "A design by Max is a mass product design.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "examples": [
        "Cube",
        "Cube",
        "Cube",
        "Cubes",
        "Cubes",
        "Cubes",
        "Cubes",
        "Cubes",
        "Cubes",
        "Cubes"
      ],
      "perplexity": [
        1.1591116189956665,
        1.730851411819458
      ]
    }
  },
  {
    "id": 40,
    "nl_problem": {
      "context": [
        "All of Zaha Hadid's design styles are timeless.",
        "No mass product design is timeless.",
        "Either Zaha Hadid's design style or Kelly Wearstler's design style. ",
        "All of Kelly Wearstler's design styles are evocative.",
        "All of Kelly Wearstler's design styles are dreamy.",
        "If a design by Max is timeless, then a design by Max is a mass product design and evocative."
      ],
      "question": "A design by Max is evocative and dreamy.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "complexity": "1000",
      "credits": [
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000"
      ],
      "perplexity": [
        1.4273943901062012,
        2.486199140548706
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Alien(x)",
        "Nutty(x)",
        "Nutty(x)"
      ],
      "fol_consts": [
        "zara",
        "zolka",
        "zolka",
        "zolka",
        "zolka",
        "zolka",
        "zolka"
      ],
      "fol_rules": [
        "∀x (Alien(x)) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x))"
      ],
      "fol_conc": "Itsname(zolka) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x)) ∧ ∀x (Zolka(x))",
      "perplexity": 3.2948248386383057
    }
  },
  {
    "id": 41,
    "nl_problem": {
      "context": [
        "All of Zaha Hadid's design styles are timeless.",
        "No mass product design is timeless.",
        "Either Zaha Hadid's design style or Kelly Wearstler's design style. ",
        "All of Kelly Wearstler's design styles are evocative.",
        "All of Kelly Wearstler's design styles are dreamy.",
        "If a design by Max is timeless, then a design by Max is a mass product design and evocative."
      ],
      "question": "A design by Max is either evocative or dreamy.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "complexity": "1000",
      "credits": [
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000",
        "1000"
      ],
      "perplexity": [
        1.425868272781372,
        2.486199140548706
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Alien(x)",
        "Nibtionist(x)",
        "Nibtionist(x)"
      ],
      "fol_consts": [
        "fromzal",
        "fromk",
        "fromk",
        "fromk",
        "fromk",
        "fromk",
        "fromk"
      ],
      "fol_rules": [
        "(Alien(x)) ∧ (Nibtionist(x)) ∧ (Nibtionist(x) ∧ Unauthentically(x))",
        "Untouched(x) ∧ Unauthentically(x) ∧ Unauthentically(x) ∧ Unauthentically(x) ∧ Unauthentically(x) ∧ Unauthentically(x)"
      ],
      "fol_conc": "Alien(x) ∧ Nibtionist(x) ∧ (Nibtionist(x) ∧ Unauthentically(x))",
      "perplexity": 4.35154914855957
    }
  },
  {
    "id": 42,
    "nl_problem": {
      "context": [
        "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. ",
        "Everyone who lost to Iga Swiatek is ranked highly by the Women's Tennis Association.",
        "All female tennis players at Roland Garros 2022 lost to Iga Swiatek.",
        "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. ",
        "All male tennis players at Roland Garros 2022 lost to Rafael Nadal.",
        "If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022."
      ],
      "question": "Coco Gauff is among the most active players in major tennis.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 43,
    "nl_problem": {
      "context": [
        "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. ",
        "Everyone who lost to Iga Swiatek is ranked highly by the Women's Tennis Association.",
        "All female tennis players at Roland Garros 2022 lost to Iga Swiatek.",
        "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. ",
        "All male tennis players at Roland Garros 2022 lost to Rafael Nadal.",
        "If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022."
      ],
      "question": "Coco Gauff has lost to Rafael Nadal.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.1246074438095093,
        1.2837450504302979
      ]
    }
  },
  {
    "id": 44,
    "nl_problem": {
      "context": [
        "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. ",
        "Everyone who lost to Iga Swiatek is ranked highly by the Women's Tennis Association.",
        "All female tennis players at Roland Garros 2022 lost to Iga Swiatek.",
        "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. ",
        "All male tennis players at Roland Garros 2022 lost to Rafael Nadal.",
        "If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022."
      ],
      "question": "Coco Gauff is not a player who lost to Iga Swiatek or one of the most active players in major tennis.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "The Great Ocean, the world's largest ocean, is located in the North Atlantic Ocean. It's a region of the ocean where the ocean currents are strong and the ocean currents are less active.",
      "perplexity": [
        1.2419219017028809,
        2.658396005630493
      ]
    }
  },
  {
    "id": 45,
    "nl_problem": {
      "context": [
        "All cats are mammals.",
        "Some pets are not mammals."
      ],
      "question": "No pets are cats.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "examples": [
        "What is the difference between a cube and a cube?"
      ],
      "exclude": [
        "1. The original sentence is a valid one, but it's written in first-order lingunt"
      ],
      "perplexity": [
        1.2227213382720947,
        2.0976195335388184
      ]
    }
  },
  {
    "id": 46,
    "nl_problem": {
      "context": [
        "There are four seasons in a year: Spring, Summer, Fall, and Winter.",
        "All students who want to have a long vacation love summer the most.",
        "Emma's favorite season is summer.",
        "Mia's favorite season is not the same as Emma's. ",
        "James wants to have a long vacation."
      ],
      "question": "James's favorite season is summer.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "elements": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "concept": "Realms are a type of reality.",
      "perplexity": [
        1.1420873403549194,
        3.034956455230713
      ]
    }
  },
  {
    "id": 47,
    "nl_problem": {
      "context": [
        "There are four seasons in a year: Spring, Summer, Fall, and Winter.",
        "All students who want to have a long vacation love summer the most.",
        "Emma's favorite season is summer.",
        "Mia's favorite season is not the same as Emma's. ",
        "James wants to have a long vacation."
      ],
      "question": "James's favorite season is fall.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "Emma's favorite season is summer.",
      "perplexity": [
        1.2384532690048218,
        5.063168525695801
      ]
    }
  },
  {
    "id": 48,
    "nl_problem": {
      "context": [
        "There are four seasons in a year: Spring, Summer, Fall, and Winter.",
        "All students who want to have a long vacation love summer the most.",
        "Emma's favorite season is summer.",
        "Mia's favorite season is not the same as Emma's. ",
        "James wants to have a long vacation."
      ],
      "question": "Mia's favorite season is spring.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "examples": [
        "I am not a person who like to have a long vacation.",
        "I am not a person who doesn't like any particular thing.",
        "I am not a person who doesn't like any particular thing.",
        "I am not a person who doesn't like any particular thing.",
        "I am not a person who doesn't like any particular thing.",
        "I am not a person who doesn't like any particular thing.",
        "I am not a person who doesn't like any particular thing.",
        "I am not a person who doesn't like any particular thing.",
        "I am not a person who doesn't like any particular thing."
      ],
      "perplexity": [
        1.228405475616455,
        1.5450098514556885
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Mia(n)",
        "Mia(s)",
        "Mia(s)",
        "Mia(s)"
      ],
      "fol_consts": [
        "mia",
        "mia",
        "mia",
        "mia"
      ],
      "fol_rules": [
        "(Mia(n) ∧ ¬Mia(s)) ∧ (Mia(s) ∧ ¬Mia(s))"
      ],
      "fol_conc": "Mia(s) ∧ ¬Mia(s) ∧ ¬Mia(s) ∧ ∃x (Say(x) ∧ ¬(Xerox(x) ∧ ¬Mia(x)))",
      "perplexity": 5.174516677856445
    }
  },
  {
    "id": 49,
    "nl_problem": {
      "context": [
        "No digital media are analog.",
        "Every printed text is analog.",
        "All streaming services are digital.",
        "If an object is a hardcover book then it is printed text.",
        "If 1984 is a streaming service, then 1984 is a hardcover book."
      ],
      "question": "1984 is printed text.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "This is a valid interpretation of the given input. The final answer is that the text is written in the format ",
      "perplexity": [
        1.204210877418518,
        5.275669574737549
      ]
    }
  },
  {
    "id": 50,
    "nl_problem": {
      "context": [
        "No digital media are analog.",
        "Every printed text is analog.",
        "All streaming services are digital.",
        "If an object is a hardcover book then it is printed text.",
        "If 1984 is a streaming service, then 1984 is a hardcover book."
      ],
      "question": "1984 is a streaming service.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "Dogs are not a type.",
      "perplexity": [
        1.0971578359603882,
        5.757415294647217
      ]
    }
  },
  {
    "id": 51,
    "nl_problem": {
      "context": [
        "No digital media are analog.",
        "Every printed text is analog.",
        "All streaming services are digital.",
        "If an object is a hardcover book then it is printed text.",
        "If 1984 is a streaming service, then 1984 is a hardcover book."
      ],
      "question": "1984 is not a streaming service.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms"
      ],
      "entities": [
        "realms",
        "realms",
        "realms"
      ],
      "operator": [
        "operator"
      ],
      "operator_operator": [
        "operator_operator"
      ],
      "perplexity": [
        1.4618324041366577,
        2.3529744148254395
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Colden(x)",
        "Colden(x, y)",
        "Colden(x, z)",
        "Colden(x, y, z)",
        "Colden(x, y, z)",
        "Colden(x, y, z)",
        "Colden(x, y, z)",
        "Colden(x, y, z)",
        "Colden(x, y, z)"
      ],
      "fol_consts": [
        "colden",
        "colden",
        "colden",
        "colden",
        "colden",
        "colden",
        "colden",
        "colden",
        "colden"
      ],
      "fol_rules": [
        "(Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x))"
      ],
      "fol_conc": "Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x) ∧ ¬Colden(x)",
      "perplexity": 2.924942970275879
    }
  },
  {
    "id": 52,
    "nl_problem": {
      "context": [
        "All Romance languages are Indo-European languages.",
        "The Romance languages are a language family.",
        "All languages within a language family are related to each other.",
        "French and Spanish are both Romance languages.",
        "German is related to Spanish.",
        "Basque is not related to any other language."
      ],
      "question": "Basque is a Romance language.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "The linguistic linguistics of the Romans are native speakers of Freccy.",
      "perplexity": [
        1.2950388193130493,
        7.08919095993042
      ]
    }
  },
  {
    "id": 53,
    "nl_problem": {
      "context": [
        "All Romance languages are Indo-European languages.",
        "The Romance languages are a language family.",
        "All languages within a language family are related to each other.",
        "French and Spanish are both Romance languages.",
        "German is related to Spanish.",
        "Basque is not related to any other language."
      ],
      "question": "German is a Romance language.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "The linguistics of the Romanses languares linguistics are native speakers of the native languages.",
      "perplexity": [
        1.190485954284668,
        2.89253568649292
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Cromanic(x)",
        "Ronic(x)",
        "Ronic(x)"
      ],
      "fol_consts": [
        "cromanic1",
        "romanic1",
        "romanic2",
        "romanic3",
        "romanic4",
        "romanic5",
        "romanic6",
        "romanic7",
        "romanic8"
      ],
      "fol_rules": [
        "(Cromanic(x)) ∧ (Cromanic(x) ∧ Cromanic(x))",
        "Cromanic(x) ∧ Cromanic(x) ∧ Cromanic(x) ∧ Cromanic(x) ∧ Cromanic(x) ∧ Cromanic(x)"
      ],
      "fol_conc": "Cromanic1(x) ∧ Cromanic1(x) ∧ Cromanic1(x) ∧ Cromanic1(x) ∧ Cromanic1(x) ∧ Cromanic1(x)",
      "perplexity": 3.226422071456909
    }
  },
  {
    "id": 54,
    "nl_problem": {
      "context": [
        "All Romance languages are Indo-European languages.",
        "The Romance languages are a language family.",
        "All languages within a language family are related to each other.",
        "French and Spanish are both Romance languages.",
        "German is related to Spanish.",
        "Basque is not related to any other language."
      ],
      "question": "French is an Indo-European language.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "1. Indo-European languares",
        "2. Indo-Ecuntal linguistics",
        "3. Indo-Ecuntal linguistics",
        "4. Indo-Ecuntal linguistics",
        "5. Indo-Ecuntal linguistics",
        "6. Indo-Ecuntal linguistics",
        "7. Indo-Ecuntal linguistics",
        "8. Indo-Ecuntal linguistics",
        "9. Indo-Ecuntal linguistics",
        "10. Indo-Ecuntal linguistics"
      ],
      "perplexity": [
        1.174753189086914,
        2.3226072788238525
      ]
    }
  },
  {
    "id": 55,
    "nl_problem": {
      "context": [
        "Robert Lewandowski is a striker.",
        "[BG] Strikers are soccer players.",
        "Robert Lewandowski left Bayern Munchen.",
        "[BG] If a player left a team they no longer play for that team."
      ],
      "question": "Robert Lewandowski is a soccer player.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "Cucumber is a type of fruit and it is made from the fruits of cucumber.",
      "perplexity": [
        1.2018858194351196,
        3.5264387130737305
      ]
    }
  },
  {
    "id": 56,
    "nl_problem": {
      "context": [
        "Robert Lewandowski is a striker.",
        "[BG] Strikers are soccer players.",
        "Robert Lewandowski left Bayern Munchen.",
        "[BG] If a player left a team they no longer play for that team."
      ],
      "question": "Robert Lewandowski plays for Bayern Munchen.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 57,
    "nl_problem": {
      "context": [
        "Robert Lewandowski is a striker.",
        "[BG] Strikers are soccer players.",
        "Robert Lewandowski left Bayern Munchen.",
        "[BG] If a player left a team they no longer play for that team."
      ],
      "question": "Robert Lewandowski is a star.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "Realm of the World",
        "Realm of the World",
        "Realm of the World",
        "Realm of the World",
        "Realm of the World"
      ],
      "software": [
        "software1",
        "software2",
        "software3",
        "software4",
        "software5"
      ],
      "perplexity": [
        1.2095608711242676,
        2.1041412353515625
      ]
    }
  },
  {
    "id": 58,
    "nl_problem": {
      "context": [
        "Billings is a city in Montana.",
        "Montana includes the cities of Butte, Helena, and Missoula.",
        "White Sulphur Springs and Butte are cities in the same state.",
        "The city of Pierre is not in Montana.",
        "Any city in Butte is not in Pierre."
      ],
      "question": "Butte and Pierre are in the same state.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 59,
    "nl_problem": {
      "context": [
        "Billings is a city in Montana.",
        "Montana includes the cities of Butte, Helena, and Missoula.",
        "White Sulphur Springs and Butte are cities in the same state.",
        "The city of Pierre is not in Montana.",
        "Any city in Butte is not in Pierre."
      ],
      "question": "Pierre and Bismarck are in the same state.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "Realms of fantasy",
        "Realms of reality"
      ],
      "perplexity": [
        1.2124154567718506,
        6.038631916046143
      ]
    }
  },
  {
    "id": 60,
    "nl_problem": {
      "context": [
        "Billings is a city in Montana.",
        "Montana includes the cities of Butte, Helena, and Missoula.",
        "White Sulphur Springs and Butte are cities in the same state.",
        "The city of Pierre is not in Montana.",
        "Any city in Butte is not in Pierre."
      ],
      "question": "Montana is home to the city of Missoula.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Billings(x)"
      ],
      "fol_consts": [
        "pissol",
        "unicorn",
        "unicorn",
        "unicorn",
        "unicorn",
        "unicorn",
        "unicorn"
      ],
      "fol_rules": [
        "(Pixy(x) ∧ ¬Is(x) ∧ ¬Is(x, a) ∧ ¬Is(x, a) ∧ ¬Is(x, a) ∧ ¬Is(x, a))",
        "Urnt(x) ∧ ¬Is(x) ∧ ¬Is(x, a) ∧ ¬Is(x, a) ∧ ¬Is(x, a) ∧ ¬Is(x, a)"
      ],
      "fol_conc": "Urnt(x) ∧ ¬Is(x) ∧ ¬Is(x, a) ∧ ¬Is(x, a) ∧ ¬Is(x, a) ∧ ¬Is(x, a)",
      "perplexity": 3.9275712966918945
    }
  },
  {
    "id": 61,
    "nl_problem": {
      "context": [
        "International students in US have either an F1 visa or a J1 visa.",
        "An international student in US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.",
        "Mike is an international student.",
        "Mike needs to apply for CPT if he wants to work in the US."
      ],
      "question": "Mike has an F1 visa.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "context": "Alice is a foreign citizen.",
      "perplexity": [
        1.2282007932662964,
        10.096304893493652
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "International(x)",
        "F1ixton(x)",
        "J1ixton(x)"
      ],
      "fol_consts": [
        "https1ixton",
        "https2ixton",
        "https3ixton"
      ],
      "fol_rules": [
        "(F1ixton(x)) ∧ (J1ixton(x)) ∧ (Potential(x) ∧ Potential(x))"
      ],
      "fol_conc": "Mikehasanf1ixton(x) ∧ ∃x (Potential(x) ∧ Potential(x))",
      "perplexity": 4.926159381866455
    }
  },
  {
    "id": 62,
    "nl_problem": {
      "context": [
        "International students in US have either an F1 visa or a J1 visa.",
        "An international student in US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.",
        "Mike is an international student.",
        "Mike needs to apply for CPT if he wants to work in the US."
      ],
      "question": "Mike has a J1 visa.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "description": "The person who is born in the United States is a foreign immigrant.",
      "perplexity": [
        1.275025725364685,
        3.9514784812927246
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "International(x)",
        "International(y)",
        "International(z)",
        "International(z, y)",
        "International(z, z)"
      ],
      "fol_consts": [
        "https1",
        "https2",
        "https3",
        "https4",
        "https5",
        "https6",
        "https7",
        "https8",
        "https9"
      ],
      "fol_rules": [
        "(Noun(x) ∧ ¬Is(x) ∧ ¬Is(n1) ∧ ¬Is(n2) ∧ ¬Is(n3) ∧ ¬Is(n4))",
        "Noun(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x)"
      ],
      "fol_conc": "Noun(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x)",
      "perplexity": 4.158568382263184
    }
  },
  {
    "id": 63,
    "nl_problem": {
      "context": [
        "All cows are bovines.",
        "Some pets are cows.",
        "If something is a bovine, then it is domesticated.",
        "No domesticated animals are alligators.",
        "Ted is an aligator."
      ],
      "question": "Ted is a pet.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "description": "The dog is a dog, a cat is a cat, and a dog is a dog.",
      "perplexity": [
        1.2009565830230713,
        3.11651873588562
      ]
    }
  },
  {
    "id": 64,
    "nl_problem": {
      "context": [
        "All cows are bovines.",
        "Some pets are cows.",
        "If something is a bovine, then it is domesticated.",
        "No domesticated animals are alligators.",
        "Ted is an aligator."
      ],
      "question": "Ted is a pet and a cow.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "answer": "Dog",
      "perplexity": [
        1.2247977256774902,
        10.164018630981445
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Cool(x)"
      ],
      "fol_consts": [
        "cool",
        "cool",
        "cool",
        "cool",
        "cool",
        "cool",
        "cool"
      ],
      "fol_rules": [
        "(Cool(x) ∧ Cool(x))",
        "Cool(x) → Cool(x) ∧ Cool(x) ∧ Cool(x) ∧ Cool(x) ∧ Cool(x)"
      ],
      "fol_conc": "Cool(x) ∧ Cock(x) ∧ Cock(x) ∧ Cock(x) ∧ Cock(x) ∧ Cock(x)",
      "perplexity": 3.8995120525360107
    }
  },
  {
    "id": 65,
    "nl_problem": {
      "context": [
        "All cows are bovines.",
        "Some pets are cows.",
        "If something is a bovine, then it is domesticated.",
        "No domesticated animals are alligators.",
        "Ted is an aligator."
      ],
      "question": "If Ted is a cow, then Ted is not a pet.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real-world examples": [
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos"
      ],
      "perplexity": [
        1.2957849502563477,
        3.0091097354888916
      ]
    }
  },
  {
    "id": 66,
    "nl_problem": {
      "context": [
        "Yale University is a private Ivy League research university.",
        "Yale University moved to New Haven in 1716.",
        "Yale university's endowment was valued at $42.3 billion.",
        "Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools.",
        "A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College."
      ],
      "question": "A private Ivy League research university moved to New Haven.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 67,
    "nl_problem": {
      "context": [
        "Yale University is a private Ivy League research university.",
        "Yale University moved to New Haven in 1716.",
        "Yale university's endowment was valued at $42.3 billion.",
        "Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools.",
        "A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College."
      ],
      "question": "Yale University has the largest university endowment of any educational institution.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "problem": "What is the name of the realms where realms are used?",
      "examples": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "explanation": "Realms are used by realms to perform various operations.",
      "perplexity": [
        1.0620936155319214,
        2.635310649871826
      ]
    }
  },
  {
    "id": 68,
    "nl_problem": {
      "context": [
        "Yale University is a private Ivy League research university.",
        "Yale University moved to New Haven in 1716.",
        "Yale university's endowment was valued at $42.3 billion.",
        "Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools.",
        "A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College."
      ],
      "question": "Pierson College is a residential college at Yale.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Nayalvyndon(x)",
        "Nayalcynton(x)",
        "Nayalcynton(x)"
      ],
      "fol_consts": [
        "nayalcynton",
        "nayalcynton",
        "nayalcynton"
      ],
      "fol_rules": [
        "(Nayalcynton(x) ∧ ¬Isnayalcynton(x))",
        "Nayalcynton(x) ∧ ¬Isnayalcynton(x) ∧ ∃x (Nayalcynton(x) ∧ ¬Isnayalcynton(x))"
      ],
      "fol_conc": "Nayalcynton(x) ∧ ¬Isnayalcynton(x) ∧ ∃x (Nayalcynton(x) ∧ ¬Isnayalcynton(x))",
      "perplexity": 3.1113157272338867
    }
  },
  {
    "id": 69,
    "nl_problem": {
      "context": [
        "Badults is a British Sitcom series, starring members of Pappy's.",
        "Badults piloted in July 2013 on BBC Three.",
        "The Working title \"The Secret Dude Society\" was used for Badults.",
        "Andrew Collins was the script editor for Badults"
      ],
      "question": "Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Badults(x)"
      ],
      "fol_consts": [
        "badults",
        "secret",
        "secret",
        "secret",
        "secret",
        "secret",
        "secret",
        "secret",
        "secret",
        "secret"
      ],
      "fol_rules": [
        "(Defnts(x) ∧ ¬Be(x, perfect))",
        "Untouched(x) ∧ ¬Be(x, perfect)",
        "Unseen(x) ∧ ¬Isnak(x)",
        "Unseen(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x)",
        "Unseen(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x)"
      ],
      "fol_conc": "Douke(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x) ∧ ¬Isnak(x)",
      "perplexity": 4.037106037139893
    }
  },
  {
    "id": 70,
    "nl_problem": {
      "context": [
        "Badults is a British Sitcom series, starring members of Pappy's.",
        "Badults piloted in July 2013 on BBC Three.",
        "The Working title \"The Secret Dude Society\" was used for Badults.",
        "Andrew Collins was the script editor for Badults"
      ],
      "question": "No members of Pappy's have starred for a show piloting on BBC Two or BBC Three.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "name": "The Catcher in the Rye",
      "director": "Jane Austen",
      "director_director": "Jane Austen",
      "director_director_director": "Jane Austen",
      "perplexity": [
        1.299893856048584,
        1.9087414741516113
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Badults(x)"
      ],
      "fol_consts": [
        "badults",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "fol_rules": [
        "(Dolphin(x) ∧ Dolphin(x) ∧ Dolphin(x) ∧ Dolphin(x) ∧ Dolphin(x) ∧ Dolphin(x))",
        "Urnt(x) ∧ Unrealms(x) ∧ Unrealms(x) ∧ Unrealms(x) ∧ Unrealms(x) ∧ Unrealms(x)"
      ],
      "fol_conc": "Dolphin(x) ∧ Dolphin(x) ∧ Dolphin(x) ∧ Unrealms(x) ∧ Unrealms(x) ∧ Unrealms(x)",
      "perplexity": 4.061177730560303
    }
  },
  {
    "id": 71,
    "nl_problem": {
      "context": [
        "All growth stocks of companies are volatile.",
        "If the stock price is volatile, then it is not suitable for a retirement fund.",
        "Some stocks of some companies are growth stocks of companies.",
        "All stocks of mature companies are suitable for a retirement fund.",
        "KO is a stock of a mature company."
      ],
      "question": "KO is a company stock.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "final_answer": "The final answer is ",
      "perplexity": [
        1.1233375072479248,
        5.142179489135742
      ]
    }
  },
  {
    "id": 72,
    "nl_problem": {
      "context": [
        "All growth stocks of companies are volatile.",
        "If the stock price is volatile, then it is not suitable for a retirement fund.",
        "Some stocks of some companies are growth stocks of companies.",
        "All stocks of mature companies are suitable for a retirement fund.",
        "KO is a stock of a mature company."
      ],
      "question": "KO is a company stock and a growth stock of a company.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "Realm of Realm",
        "Realm of Realm",
        "Realm of Realm",
        "Realm of Realm",
        "Realm of Realm",
        "Realm of Realm",
        "Realm of Realm",
        "Realm of Realm",
        "Realm of Realm"
      ],
      "perplexity": [
        1.4145094156265259,
        2.663952350616455
      ]
    }
  },
  {
    "id": 73,
    "nl_problem": {
      "context": [
        "All growth stocks of companies are volatile.",
        "If the stock price is volatile, then it is not suitable for a retirement fund.",
        "Some stocks of some companies are growth stocks of companies.",
        "All stocks of mature companies are suitable for a retirement fund.",
        "KO is a stock of a mature company."
      ],
      "question": "If KO is a growth stock of a company or if its price is volatile, then KO is neither a stock of a company nor is its price volatile.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "examples": [
        "1. Cntnnt(x, y) = x + y"
      ],
      "exclude": [
        "1. Cntnnt(x, y) = x + y"
      ],
      "perplexity": [
        1.1513148546218872,
        2.2164089679718018
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Realm(x)",
        "Realm(y)",
        "Realm(z)",
        "Realm(z)",
        "Realm(z)"
      ],
      "fol_consts": [
        "realm",
        "realm",
        "realm",
        "realm",
        "realm"
      ],
      "fol_rules": [
        "∀x (Realm(x) ∧ Realm(y))",
        "∀x (Realm(x) ∧ Realm(y))",
        "∀x (Realm(x) ∧ Realm(y))",
        "∀x (Realm(x) ∧ Realm(y))",
        "∀x (Realm(x) ∧ Realm(y))"
      ],
      "fol_conc": "Crealm(x) ∧ Realm(y) ∧ Realm(z) ∧ Realm(z) ∧ Realm(z) ∧ Realm(z)",
      "perplexity": 3.273296356201172
    }
  },
  {
    "id": 74,
    "nl_problem": {
      "context": [
        "All vehicle registration plates in Istanbul begin with the number 34.",
        "Plates that do not begin with the number 34 are not from Istanbul. ",
        "Joe's vehicle registration plate is from Istanbul. ",
        "Tom's license plate begins with the number 35. ",
        "[BG] If a license plate begins with the number 35, then it does not begin with the number 34."
      ],
      "question": "Joe's license plate begins with the number 34.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "Softness is a term used to describe a certain degree of resistance to heat, resistance to cold, and resistance to heat and cold. It is a characteristic of materials that are made from materials that are not hot.",
      "perplexity": [
        1.2456907033920288,
        6.011511325836182
      ]
    }
  },
  {
    "id": 75,
    "nl_problem": {
      "context": [
        "All vehicle registration plates in Istanbul begin with the number 34.",
        "Plates that do not begin with the number 34 are not from Istanbul. ",
        "Joe's vehicle registration plate is from Istanbul. ",
        "Tom's license plate begins with the number 35. ",
        "[BG] If a license plate begins with the number 35, then it does not begin with the number 34."
      ],
      "question": "Tom's license plate is from Istanbul.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "Cass",
      "perplexity": [
        1.22403883934021,
        14.757240295410156
      ]
    }
  },
  {
    "id": 76,
    "nl_problem": {
      "context": [
        "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.",
        "If people order takeout frequently in college, then they work in student jobs on campus.",
        "People either order takeout frequently in college or enjoy the dining hall meals and recipes.",
        "If people enjoy the dining hall meals and recipes, then they are not picky eaters.",
        "If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.",
        "If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition."
      ],
      "question": "Mary needs to earn money to help pay for her college tuition.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "Cucumber is a type of fruit and does not contain any nutrients.",
      "perplexity": [
        1.139380931854248,
        5.782515525817871
      ]
    }
  },
  {
    "id": 77,
    "nl_problem": {
      "context": [
        "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.",
        "If people order takeout frequently in college, then they work in student jobs on campus.",
        "People either order takeout frequently in college or enjoy the dining hall meals and recipes.",
        "If people enjoy the dining hall meals and recipes, then they are not picky eaters.",
        "If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.",
        "If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition."
      ],
      "question": "Mary is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "examples": [
        "Cucumber",
        "peach",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi"
      ],
      "perplexity": [
        1.1240547895431519,
        2.78814697265625
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Aliceeinnion(x)"
      ],
      "fol_consts": [
        "eaters",
        "sayings",
        "sayings",
        "sayings",
        "sayings",
        "sayings",
        "sayings"
      ],
      "fol_rules": [
        "(Aliceeinnion(x) ∧ ¬Aliceeinnion(x))",
        "(Aliceeinnion(x) ∧ ¬Aliceeinnion(x)) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x)"
      ],
      "fol_conc": "Aliceeinnion(x) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x) ∧ ¬Aliceeinnion(x)",
      "perplexity": 3.2620129585266113
    }
  },
  {
    "id": 78,
    "nl_problem": {
      "context": [
        "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.",
        "If people order takeout frequently in college, then they work in student jobs on campus.",
        "People either order takeout frequently in college or enjoy the dining hall meals and recipes.",
        "If people enjoy the dining hall meals and recipes, then they are not picky eaters.",
        "If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.",
        "If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition."
      ],
      "question": "Mary either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "Caffeine",
        "Cafee",
        "Cafee",
        "Cafee",
        "Cafee",
        "Cafee",
        "Cafee",
        "Cafee",
        "Cafee"
      ],
      "perplexity": [
        1.428352952003479,
        3.251476287841797
      ]
    }
  },
  {
    "id": 79,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are a product of Baked by Melissa.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "answer": "Beoezy",
      "description": "Beoezy is a name of a dog.",
      "perplexity": [
        1.2242827415466309,
        3.6408536434173584
      ]
    }
  },
  {
    "id": 80,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are not a product of Baked by Melissa.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "I can't go to the store or get coffee.",
      "perplexity": [
        1.31409752368927,
        7.916316986083984
      ]
    }
  },
  {
    "id": 81,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are a hotpot.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "The Starry Night",
      "perplexity": [
        1.2557238340377808,
        14.837784767150879
      ]
    }
  },
  {
    "id": 82,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are neither a product of Baked by Melissa nor a bakery.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 83,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are cupcakes and a product of Baked by Melissa.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "examples": [
        "Cucumber",
        "peach",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi"
      ],
      "perplexity": [
        1.2266536951065063,
        3.090054750442505
      ]
    }
  },
  {
    "id": 84,
    "nl_problem": {
      "context": [
        "If the restaurant is listed in Yelp’s recommendations, then the restaurant does not receive many negative reviews.",
        "All restaurants with a rating greater than 9 are listed in Yelp’s recommendations.",
        "Some restaurants that do not provide take-out service receive many negative reviews.",
        "All restaurants that are popular among local residents have ratings greater than 9.",
        "Subway has a rating greater than 9 or is popular among local residents."
      ],
      "question": "If Subway provides take-out service and receives many negative reviews, then its rating is greater than 9 and it does not provide take-out service.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "examples": [
        "CityName",
        "cityName",
        "cityName",
        "cityName",
        "cityName",
        "cityName",
        "cityName",
        "cityName",
        "cityName",
        "cityName"
      ],
      "perplexity": [
        1.2263723611831665,
        2.4486186504364014
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Customers(x)",
        "Customers(x)",
        "Customers(x)",
        "Customers(x)",
        "Customers(x)",
        "Customers(x)",
        "Customers(x)",
        "Customers(x)",
        "Customers(x)"
      ],
      "fol_consts": [
        "customers",
        "customers",
        "customers",
        "customers",
        "customers",
        "customers",
        "customers",
        "customers",
        "customers",
        "customers"
      ],
      "fol_rules": [
        "(Customers(x) ∧ ¬Customers(x)) ∧ ¬Customers(x) ∧ ¬Customers(x) ∧ ¬Customers(x) ∧ ¬Customers(x) ∧ ¬Customers(x)"
      ],
      "fol_conc": "Customers(x) ∧ ¬Customers(x) ∧ ¬Customers(x) ∧ ¬Customers(x) ∧ ¬Customers(x) ∧ ¬Customers(x)",
      "perplexity": 2.954071521759033
    }
  },
  {
    "id": 85,
    "nl_problem": {
      "context": [
        "If the restaurant is listed in Yelp’s recommendations, then the restaurant does not receive many negative reviews.",
        "All restaurants with a rating greater than 9 are listed in Yelp’s recommendations.",
        "Some restaurants that do not provide take-out service receive many negative reviews.",
        "All restaurants that are popular among local residents have ratings greater than 9.",
        "Subway has a rating greater than 9 or is popular among local residents."
      ],
      "question": "Subway provides take-out service and does not receive many negative reviews.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain"
      ],
      "perplexity": [
        1.1747260093688965,
        3.8351521492004395
      ]
    }
  },
  {
    "id": 86,
    "nl_problem": {
      "context": [
        "If the restaurant is listed in Yelp’s recommendations, then the restaurant does not receive many negative reviews.",
        "All restaurants with a rating greater than 9 are listed in Yelp’s recommendations.",
        "Some restaurants that do not provide take-out service receive many negative reviews.",
        "All restaurants that are popular among local residents have ratings greater than 9.",
        "Subway has a rating greater than 9 or is popular among local residents."
      ],
      "question": "Subway does not provide take-out service.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "The Mona Lisa",
      "artist": "Leonardo da Vinci",
      "subject": "The Mona Lisa",
      "time": "1503-1506",
      "is_a_ masterpiece": "The Mona Lisa is a masterpiece of the Impressionist style.",
      "perplexity": [
        1.2899994850158691,
        1.7975826263427734
      ]
    }
  },
  {
    "id": 87,
    "nl_problem": {
      "context": [
        "In superhero movies, the good guys always win.",
        "The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.",
        "Good guys fight bad guys and vice versa.",
        "Sir Digby fights his nemesis.",
        "If a superhero movie is named after a character, that character is a good guy.",
        "The Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.",
        "If somebody wins a fight, the person they are fighting loses.",
        "If a superhero movie is named after a character, that character appears in the movie."
      ],
      "question": "Sir Digby’s nemesis loses.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.1293104887008667,
        2.107353687286377
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Realm(x)",
        "Realm(y)",
        "Realm(z)"
      ],
      "fol_consts": [
        "realm1",
        "realm2",
        "realm3",
        "realm4",
        "realm5",
        "realm6",
        "realm7",
        "realm8",
        "realm9"
      ],
      "fol_rules": [
        "(Realm(x) ∧ Realm(y) ∧ Realm(z))",
        "Realm(x) ∧ Realm(y) ∧ Realm(z) ∧ Realm(z) ∧ Realm(z) ∧ Realm(z)"
      ],
      "fol_conc": "Realm(x) ∧ Realm(y) ∧ Realm(z) ∧ Realm(z) ∧ Realm(z) ∧ Realm(z)",
      "perplexity": 3.6646509170532227
    }
  },
  {
    "id": 88,
    "nl_problem": {
      "context": [
        "[BG] Books contain tons of knowledge.",
        "[BG] When a person reads a book, that person gains knowledge. ",
        "[BG] If a person gains knowledge, they become smarter.",
        "Harry read the book “Walden” by Henry Thoreau."
      ],
      "question": "Walden contains knowledge.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Growth(x)",
        "Growth(y)",
        "Growth(z)",
        "Growth(z)",
        "Growth(z)"
      ],
      "fol_consts": [
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie"
      ],
      "fol_rules": [
        "∀x (Growth(x) ∧ ¬Be(x, master))",
        "∀x (Growth(x) ∧ ¬Be(x, master))",
        "∀x (Growth(x) ∧ ¬Be(x, master))",
        "∀x (Growth(x) ∧ ¬Be(x, master))",
        "∀x (Growth(x) ∧ ¬Be(x, master))"
      ],
      "fol_conc": "Cookies(x) ∧ Cookies(y) ∧ Cookies(z) ∧ Cookies(z) ∧ Cookies(z) ∧ Cookies(z)",
      "perplexity": 3.051377058029175
    }
  },
  {
    "id": 89,
    "nl_problem": {
      "context": [
        "[BG] Books contain tons of knowledge.",
        "[BG] When a person reads a book, that person gains knowledge. ",
        "[BG] If a person gains knowledge, they become smarter.",
        "Harry read the book “Walden” by Henry Thoreau."
      ],
      "question": "Harry is smarter than before.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "The difference between a good friend and a bad friend is: 1. **Friend**: A good friend knows you better. 2. **Friend**: A bad friend doesn't evolve.",
      "perplexity": [
        1.1353741884231567,
        2.088026285171509
      ]
    }
  },
  {
    "id": 90,
    "nl_problem": {
      "context": [
        "[BG] Books contain tons of knowledge.",
        "[BG] When a person reads a book, that person gains knowledge. ",
        "[BG] If a person gains knowledge, they become smarter.",
        "Harry read the book “Walden” by Henry Thoreau."
      ],
      "question": "A person who is smarter has gained knowledge.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "name": "The Beatles",
      "year": 1960,
      "genre": "The Beatles",
      "perplexity": [
        1.1676276922225952,
        3.3206636905670166
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Growth(x)",
        "Growth(y)",
        "Growth(z)",
        "Growth(z)",
        "Growth(z)"
      ],
      "fol_consts": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "fol_rules": [
        "(Growth(x) ∧ ¬Be(x, perfect))",
        "(Growth(y) ∧ ¬Be(y, perfect))",
        "(Growth(z) ∧ ¬Be(z, perfect))",
        "(Growth(z) ∧ ¬Be(z, perfect))",
        "(Growth(z) ∧ ¬Be(z, perfect))"
      ],
      "fol_conc": "Urnts(z) ∧ ¬Be(z, perfect) → ∀x (Growth(z) ∧ ¬Be(z, perfect))",
      "perplexity": 3.30644154548645
    }
  },
  {
    "id": 91,
    "nl_problem": {
      "context": [
        "Natural language processing tasks can be categorized as either language generation task or language understanding task.",
        "If the output of a natural language processing task is a text sequence, then it is a language generation task.",
        "Machine translation is a natural language processing task.",
        "The output of machine translation is a text sequence."
      ],
      "question": "Machine translation is a language generation task.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "final_answer": "The final answer is that the final answer is a linguinguistically correct grammatical correctness.",
      "perplexity": [
        1.1874488592147827,
        3.149127721786499
      ]
    }
  },
  {
    "id": 92,
    "nl_problem": {
      "context": [
        "Natural language processing tasks can be categorized as either language generation task or language understanding task.",
        "If the output of a natural language processing task is a text sequence, then it is a language generation task.",
        "Machine translation is a natural language processing task.",
        "The output of machine translation is a text sequence."
      ],
      "question": "Machine translation is a language understanding task.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "function": "convert_to_csv",
      "input": "tucnt",
      "output": "tucnt",
      "perplexity": [
        1.2460294961929321,
        3.9673759937286377
      ]
    }
  },
  {
    "id": 93,
    "nl_problem": {
      "context": [
        "Pets are allowed in some managed buildings.",
        "[BG] A deposit is required to rent an apartment in a managed building.",
        "The security deposit can be either equal to one month's rent or more.",
        "Fluffy is Tom's cat.",
        "Cats are pets.",
        "The Olive Garden is a managed building.",
        "The monthly rent at the Olive Garden is $2000.",
        "Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.",
        "2000$ is more than $1500."
      ],
      "question": "Tom will rent an apartment in The Olive Garden.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "title": "The Wild Wild West",
      "director": "James Cameron",
      "director_who": "Williamson F. Scott",
      "perplexity": [
        1.1643139123916626,
        3.2525150775909424
      ]
    }
  },
  {
    "id": 94,
    "nl_problem": {
      "context": [
        "Pets are allowed in some managed buildings.",
        "[BG] A deposit is required to rent an apartment in a managed building.",
        "The security deposit can be either equal to one month's rent or more.",
        "Fluffy is Tom's cat.",
        "Cats are pets.",
        "The Olive Garden is a managed building.",
        "The monthly rent at the Olive Garden is $2000.",
        "Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.",
        "2000$ is more than $1500."
      ],
      "question": "Tom is allowed to move in an apartment in The Olive Garden with Fluffy.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "complex": "Cucucucucucucub",
      "perplexity": [
        1.1109009981155396,
        5.576848983764648
      ]
    }
  },
  {
    "id": 95,
    "nl_problem": {
      "context": [
        "Pets are allowed in some managed buildings.",
        "[BG] A deposit is required to rent an apartment in a managed building.",
        "The security deposit can be either equal to one month's rent or more.",
        "Fluffy is Tom's cat.",
        "Cats are pets.",
        "The Olive Garden is a managed building.",
        "The monthly rent at the Olive Garden is $2000.",
        "Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.",
        "2000$ is more than $1500."
      ],
      "question": "The security deposit at the Olive Garden is either $2000 or more.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "Cube is a type of solid material that can be used for various purposes, such as building buildings, furniture, or toys.",
      "perplexity": [
        1.2190479040145874,
        1.9727466106414795
      ]
    }
  },
  {
    "id": 96,
    "nl_problem": {
      "context": [
        "If animals are loved by tourists, then they are Max's favorite animals. ",
        "All animals from Australia are loved by tourists. ",
        "All quokka are animals from Australia. ",
        "All of Max's favorite animals are very fluffy.",
        "All of Max's favorite animals love to sleep. ",
        "If a koala is very fluffy, then the koala is not a quokka."
      ],
      "question": "Koalas love to sleep.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "Cucucucucucucucub",
      "perplexity": [
        1.1526604890823364,
        8.50322151184082
      ]
    }
  },
  {
    "id": 97,
    "nl_problem": {
      "context": [
        "If animals are loved by tourists, then they are Max's favorite animals. ",
        "All animals from Australia are loved by tourists. ",
        "All quokka are animals from Australia. ",
        "All of Max's favorite animals are very fluffy.",
        "All of Max's favorite animals love to sleep. ",
        "If a koala is very fluffy, then the koala is not a quokka."
      ],
      "question": "Koalas love to sleep and are quokka.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.0859700441360474,
        4.816178798675537
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Celebrate(x)",
        "Celebrate(x, y)",
        "Celebrate(x, z)",
        "Celebrate(x, z)",
        "Celebrate(x, z)",
        "Celebrate(x, z)",
        "Celebrate(x, z)",
        "Celebrate(x, z)",
        "Celebrate(x, z)"
      ],
      "fol_consts": [
        "celebrate",
        "celebrate",
        "celebrate",
        "celebrate",
        "celebrate",
        "celebrate",
        "celebrate",
        "celebrate",
        "celebrate"
      ],
      "fol_rules": [
        "(Celebrate(x) ∧ ¬Celebrate(x, y))",
        "Celebrate(x) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y)",
        "Celebrate(x) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y)"
      ],
      "fol_conc": "Celebrate(x) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y) ∧ ¬Celebrate(x, y)",
      "perplexity": 2.4336042404174805
    }
  },
  {
    "id": 98,
    "nl_problem": {
      "context": [
        "If animals are loved by tourists, then they are Max's favorite animals. ",
        "All animals from Australia are loved by tourists. ",
        "All quokka are animals from Australia. ",
        "All of Max's favorite animals are very fluffy.",
        "All of Max's favorite animals love to sleep. ",
        "If a koala is very fluffy, then the koala is not a quokka."
      ],
      "question": "If a koala is a quokka, then the koala either loves to sleep or is very fluffy.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "Cucucut",
        "Cucucut",
        "Cucucut",
        "Cucucut",
        "Cucucut",
        "Cucucut",
        "Cucucut",
        "Cucucut",
        "Cucucut",
        "Cucucut"
      ],
      "perplexity": [
        1.2160863876342773,
        2.840033531188965
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Cooking(x)",
        "Cooking(x)",
        "Cooking(x)",
        "Cooking(x)",
        "Cooking(x)",
        "Cooking(x)",
        "Cooking(x)",
        "Cooking(x)",
        "Cooking(x)"
      ],
      "fol_consts": [
        "chucking",
        "cooking",
        "cooking",
        "cooking",
        "cooking",
        "cooking",
        "cooking",
        "cooking",
        "cooking",
        "cooking"
      ],
      "fol_rules": [
        "Cooking(x) ∧ Cooking(x) ∧ Cooking(x) ∧ Cooking(x) ∧ Cooking(x) ∧ Cooking(x)"
      ],
      "fol_conc": "Cooking(x) ∧ Cooking(x) ∧ Cooking(x) ∧ Cooking(x) ∧ Cooking(x) ∧ Cooking(x)",
      "perplexity": 2.8235650062561035
    }
  },
  {
    "id": 99,
    "nl_problem": {
      "context": [
        "A man is either kind or evil.",
        "No ugly person is handsome.",
        "All evil people are ugly.",
        "All gentlemen are handsome.",
        "All CEOs are gentlemen.",
        "Harry is a gentleman."
      ],
      "question": "Harry is a CEO.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "elements": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "concepts": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "examples": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "explanations": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.195946455001831,
        1.7838996648788452
      ]
    }
  },
  {
    "id": 100,
    "nl_problem": {
      "context": [
        "A man is either kind or evil.",
        "No ugly person is handsome.",
        "All evil people are ugly.",
        "All gentlemen are handsome.",
        "All CEOs are gentlemen.",
        "Harry is a gentleman."
      ],
      "question": "Harry is kind or a CEO.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "examples": [
        "apple",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi",
        "kiwi"
      ],
      "perplexity": [
        1.1816097497940063,
        3.400423288345337
      ]
    }
  },
  {
    "id": 101,
    "nl_problem": {
      "context": [
        "A man is either kind or evil.",
        "No ugly person is handsome.",
        "All evil people are ugly.",
        "All gentlemen are handsome.",
        "All CEOs are gentlemen.",
        "Harry is a gentleman."
      ],
      "question": "If Harry is either both evil and ugly, or neither evil nor ugly, then Harry is neither kind nor a CEO.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "entities": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "examples": [
        "apple",
        "orange",
        "kiwi",
        "orange",
        "kiwi",
        "orange",
        "kiwi",
        "orange",
        "kiwi",
        "orange"
      ],
      "perplexity": [
        1.1720528602600098,
        2.0247297286987305
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Alice(x)",
        "Bob(x)",
        "Cobon(x)",
        "Cobomn(x)"
      ],
      "fol_consts": [
        "a1",
        "b1",
        "c1",
        "c2",
        "c3",
        "c4",
        "c5",
        "c6",
        "c7",
        "c8",
        "c9"
      ],
      "fol_rules": [
        "(Alice(x) ∧ Cobomn(x)) ∧ Cobomn(x) ∧ Cobomn(x) ∧ Cobomn(x) ∧ Cobomn(x) ∧ Cobomn(x)"
      ],
      "fol_conc": "Alice(x) ∧ Cobomn(x) ∧ Cobomn(x) ∧ Cobomn(x) ∧ Cobomn(x) ∧ Cobomn(x)",
      "perplexity": 3.355440378189087
    }
  },
  {
    "id": 102,
    "nl_problem": {
      "context": [
        "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.",
        "If people have siblings who are the same age, then they are twins or triplets.",
        "If people complain often about annoying siblings, then they have siblings who are the same age.",
        "If people do not live at home regularly, then they do not develop strong bonds with their family members.",
        "If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly.",
        "Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.   "
      ],
      "question": "Luke spends a lot of time hanging out and playing with his siblings.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "description": "The difference between a cube and a cube is not defined as a logical operator or the same as the same in a logical operator.",
      "perplexity": [
        1.3415565490722656,
        1.7881802320480347
      ]
    }
  },
  {
    "id": 103,
    "nl_problem": {
      "context": [
        "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.",
        "If people have siblings who are the same age, then they are twins or triplets.",
        "If people complain often about annoying siblings, then they have siblings who are the same age.",
        "If people do not live at home regularly, then they do not develop strong bonds with their family members.",
        "If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly.",
        "Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.   "
      ],
      "question": "Luke complains often about annoying siblings.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "dog",
        "cat"
      ],
      "common": [
        "dog",
        "cat"
      ],
      "perplexity": [
        1.221234917640686,
        4.187854766845703
      ]
    }
  },
  {
    "id": 104,
    "nl_problem": {
      "context": [
        "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.",
        "If people have siblings who are the same age, then they are twins or triplets.",
        "If people complain often about annoying siblings, then they have siblings who are the same age.",
        "If people do not live at home regularly, then they do not develop strong bonds with their family members.",
        "If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly.",
        "Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.   "
      ],
      "question": "Luke is neither a twin nor triplet nor complains often about annoying siblings.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "The dog is not a dog.",
      "perplexity": [
        1.4010471105575562,
        9.004887580871582
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Nluke(nluke)"
      ],
      "fol_consts": [
        "nluke"
      ],
      "fol_rules": [
        "(Nluke(nluke) ∧ ¬Isnniue(nluke))",
        "Nluke(nluke) → ∀x (Nluke(nluke) ∧ Isnniue(nluke))",
        "Untouched(nluke) ∧ ¬Isnniue(nluke)",
        "Untouched(nluke) ∧ ¬Isnniue(nluke) ∧ ∃x (Nluke(nluke) ∧ Isnniue(nluke))"
      ],
      "fol_conc": "Nluke(nluke) ∧ Isnniue(nluke) ∧ Isnniue(nluke) ∧ Isnniue(nluke) ∧ Unluke(nluke) ∧ Isnniue(nluke)",
      "perplexity": 3.4284021854400635
    }
  },
  {
    "id": 105,
    "nl_problem": {
      "context": [
        "It costs US $205 to take the GRE test.",
        "ETS provides financial aid to those GRE applicants who prove economic hardship.",
        "Economic hardship refers to difficulty caused by having too little money or too few resources.",
        "Tom lives in a single-parent family.",
        "His dad has been out of work for more than a year."
      ],
      "question": "Tom can apply for financial aid from ETS to take the GRE test.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "examples": [
        "Cube = 3 * 3 * 3",
        "Cube = 3 * 3 * 3",
        "Cube = 3 * 3 * 3",
        "Cube = 3 * 3 * 3",
        "Cube = 3 * 3 * 3"
      ],
      "perplexity": [
        1.2307757139205933,
        2.1135921478271484
      ]
    }
  },
  {
    "id": 106,
    "nl_problem": {
      "context": [
        "It costs US $205 to take the GRE test.",
        "ETS provides financial aid to those GRE applicants who prove economic hardship.",
        "Economic hardship refers to difficulty caused by having too little money or too few resources.",
        "Tom lives in a single-parent family.",
        "His dad has been out of work for more than a year."
      ],
      "question": "It cost below US $300 to take the GRE test.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "problems": [
        "What is the difference between the realms of dreams and reality?"
      ],
      "perplexity": [
        1.1118319034576416,
        3.942412853240967
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Coutt(x)",
        "Coutt(x, y)",
        "Coutt(x, y, y)",
        "Coutt(x, y, y, y)",
        "Coutt(x, y, y, y)"
      ],
      "fol_consts": [
        "ust",
        "snt",
        "snt",
        "snt",
        "snt",
        "snt",
        "snt"
      ],
      "fol_rules": [
        "(Coutt(x) ∧ ¬Coutt(x, y) ∧ ¬Coutt(x, y, y) ∧ ¬Coutt(x, y, y, y) ∧ ¬Coutt(x, y, y, y) ∧ ¬Coutt(x, y, y, y))"
      ],
      "fol_conc": "Coutt(x) ∧ ¬Coutt(x, y) ∧ ¬Coutt(x, y, y, y) ∧ ¬Coutt(x, y, y, y) ∧ ¬Coutt(x, y, y, y) ∧ ¬Coutt(x, y, y, y)",
      "perplexity": 2.864790201187134
    }
  },
  {
    "id": 107,
    "nl_problem": {
      "context": [
        "It costs US $205 to take the GRE test.",
        "ETS provides financial aid to those GRE applicants who prove economic hardship.",
        "Economic hardship refers to difficulty caused by having too little money or too few resources.",
        "Tom lives in a single-parent family.",
        "His dad has been out of work for more than a year."
      ],
      "question": "There is no financial aid available for the GRE test.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "domain",
        "domain",
        "domain",
        "domain",
        "domain"
      ],
      "perplexity": [
        1.1267743110656738,
        5.3534650802612305
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Inequality(x)",
        "Economic(x)",
        "Economic(mn)",
        "Necessary(n)",
        "Necessary(mn)"
      ],
      "fol_consts": [
        "economic",
        "necessary"
      ],
      "fol_rules": [
        "(Necessary(x) ∧ ¬Economic(x))",
        "Necessary(n) ∧ ¬Economic(n) ∧ ∃n ∃n ∃n ∃n (Necessary(n) ∧ ¬Economic(n))"
      ],
      "fol_conc": "Itcosts(x) ∧ ∃n ∃n ∃n ∃n (Necessary(n) ∧ ¬Economic(n))",
      "perplexity": 4.466979503631592
    }
  },
  {
    "id": 108,
    "nl_problem": {
      "context": [
        "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.",
        "All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.",
        "If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.",
        "If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.",
        "All households with a high net income have people who have parents who are very busy with their regular jobs.",
        "Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings. "
      ],
      "question": "Peter tidies his space consistently and enjoys the process of cleaning.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "total": "Cool, I know you know what you're talking about.",
      "perplexity": [
        1.217309594154358,
        10.196167945861816
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Potential(x)",
        "Potential(x)"
      ],
      "fol_consts": [
        "eat",
        "say",
        "say",
        "say",
        "say",
        "say",
        "say"
      ],
      "fol_rules": [
        "(Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x))"
      ],
      "fol_conc": "Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x)",
      "perplexity": 4.2694196701049805
    }
  },
  {
    "id": 109,
    "nl_problem": {
      "context": [
        "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.",
        "All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.",
        "If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.",
        "If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.",
        "All households with a high net income have people who have parents who are very busy with their regular jobs.",
        "Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings. "
      ],
      "question": "Peter is either a foodie who goes out frequently to find new food restaurants to try or belongs to a household with a high net income.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "Person X is an individual who has a family with a high net income.",
      "perplexity": [
        1.1470141410827637,
        5.617968559265137
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Potential(x)",
        "Potential(x)"
      ],
      "fol_consts": [
        "tomorrow",
        "tomorrow",
        "tomorrow"
      ],
      "fol_rules": [
        "(Potential(x) ∧ Potential(x)) ∧ (Potential(x) ∧ Potential(x))"
      ],
      "fol_conc": "Tomorrow(x) ∧ Potential(x) ∧ Potential(x) ∧ Tomorrow(x) ∧ Tomorrow(x) ∧ Tomorrow(x)",
      "perplexity": 4.625572681427002
    }
  },
  {
    "id": 110,
    "nl_problem": {
      "context": [
        "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.",
        "All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.",
        "If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.",
        "If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.",
        "All households with a high net income have people who have parents who are very busy with their regular jobs.",
        "Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings. "
      ],
      "question": "Peter is either a foodie who goes out frequently to find new food restaurants to try and belong to a household with a high net income or he is a foodie who goes out frequently to find new food restaurants to try nor belongs to a household with a high net income.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 111,
    "nl_problem": {
      "context": [
        "All fir trees are evergreens.",
        "Some objects of worship are fir trees."
      ],
      "question": "Some evergreens are not objects of worship.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.216917634010315,
        1.1188455820083618
      ]
    }
  },
  {
    "id": 112,
    "nl_problem": {
      "context": [
        "The Picuris Mountains are a mountain range in New Mexico or Texas.",
        "Juan de Onate visited the Picuris Mountains.",
        "The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.",
        "There are no mountain ranges in texas that have mines which have been donated."
      ],
      "question": "Juan de Onate visited a mountain range in New Mexico.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "problem": "What is the realms of realms?",
      "perplexity": [
        1.052505373954773,
        4.328008651733398
      ]
    }
  },
  {
    "id": 113,
    "nl_problem": {
      "context": [
        "The Picuris Mountains are a mountain range in New Mexico or Texas.",
        "Juan de Onate visited the Picuris Mountains.",
        "The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.",
        "There are no mountain ranges in texas that have mines which have been donated."
      ],
      "question": "Juan de Onate visited a mountain range in Texas.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "problem": "What is the name of the realms where the realms of realms are used?",
      "perplexity": [
        1.05097234249115,
        4.195374011993408
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Cosmic(x)"
      ],
      "fol_consts": [
        "cosmic",
        "osmic",
        "osmic",
        "osmic",
        "osmic",
        "osmic",
        "osmic"
      ],
      "fol_rules": [
        "(Cosmos(x) ∧ Cosmos(x))",
        "Cosmos(x) → Cosmos(x) ∧ Cosmos(x) ∧ Cosmos(x) ∧ Cosmos(x) ∧ Cosmos(x)"
      ],
      "fol_conc": "Cosmos(x) ∧ Cosmos(x) ∧ Cosmos(x) ∧ Cosmos(x) ∧ Cosmos(x) ∧ Cosmos(x)",
      "perplexity": 3.6623756885528564
    }
  },
  {
    "id": 114,
    "nl_problem": {
      "context": [
        "The Picuris Mountains are a mountain range in New Mexico or Texas.",
        "Juan de Onate visited the Picuris Mountains.",
        "The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.",
        "There are no mountain ranges in texas that have mines which have been donated."
      ],
      "question": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
      "options": []
    },
    "answer": "B",
    "logic_problem_gcd": {
      "fol_preds": [
        "Cosntion(x)",
        "Cosntion(y)",
        "Cosntion(z)",
        "Cosntion(z, y)",
        "Cosntion(z, z)"
      ],
      "fol_consts": [
        "cosntion1",
        "cosntion2",
        "cosntion3",
        "cosntion4",
        "cosntion5",
        "cosntion6",
        "cosntion7",
        "cosntion8",
        "cosntion9"
      ],
      "fol_rules": [
        "(Cosntion(x) ∧ Cosntion(y))",
        "Cosntion(x, y) → ∀x (Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y))",
        "Cosntion(x) ∧ Cosntion(y) ∧ Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y)"
      ],
      "fol_conc": "Cosntion(x) ∧ Cosntion(y) ∧ Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y) ∧ Cosntion(x, y)",
      "perplexity": 2.6634185314178467
    }
  },
  {
    "id": 115,
    "nl_problem": {
      "context": [
        "If a man is taller than another man, the taller one can block the other's shooting.",
        "Michael is a man who is taller than everyone else in his class.",
        "If person x is taller than person y, and person y is taller than person z, than x is taller than z",
        "Peter is a man who is taller than Michael.",
        "Michael can block any shooting from a person as long as the person does not jump when shooting.",
        "Michael cannot block Windy's shooting.",
        "Every shooter who can jump when shooting is a great shooter."
      ],
      "question": "Peter is shorter than a man in Michael's class.",
      "options": []
    },
    "answer": "B",
    "logic_problem_gcd": {
      "fol_preds": [
        "Person1(x)",
        "Person2(x)",
        "Person3(x)"
      ],
      "fol_consts": [
        "person11",
        "person21",
        "person31"
      ],
      "fol_rules": [
        "(Person1(x) ∧ Person2(x) ∧ Person3(x)) ∧ (Person11(x) ∧ Person21(x) ∧ Person31(x))"
      ],
      "fol_conc": "Person11(x) ∧ Person21(x) ∧ Person31(x) ∧ Person11(x) ∧ Person21(x) ∧ Person31(x)",
      "perplexity": 3.8050763607025146
    }
  },
  {
    "id": 116,
    "nl_problem": {
      "context": [
        "If a man is taller than another man, the taller one can block the other's shooting.",
        "Michael is a man who is taller than everyone else in his class.",
        "If person x is taller than person y, and person y is taller than person z, than x is taller than z",
        "Peter is a man who is taller than Michael.",
        "Michael can block any shooting from a person as long as the person does not jump when shooting.",
        "Michael cannot block Windy's shooting.",
        "Every shooter who can jump when shooting is a great shooter."
      ],
      "question": "Windy is a great shooter.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "Alice is taller than all men in her class.",
      "perplexity": [
        1.1685168743133545,
        2.588484525680542
      ]
    }
  },
  {
    "id": 117,
    "nl_problem": {
      "context": [
        "If a man is taller than another man, the taller one can block the other's shooting.",
        "Michael is a man who is taller than everyone else in his class.",
        "If person x is taller than person y, and person y is taller than person z, than x is taller than z",
        "Peter is a man who is taller than Michael.",
        "Michael can block any shooting from a person as long as the person does not jump when shooting.",
        "Michael cannot block Windy's shooting.",
        "Every shooter who can jump when shooting is a great shooter."
      ],
      "question": "Peter can block Windy's shooting.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "description": "Alice is taller than any person.",
      "perplexity": [
        1.1585562229156494,
        7.59213399887085
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person1(x)",
        "Person2(x)",
        "Person3(x)"
      ],
      "fol_consts": [
        "person11",
        "person21",
        "person31"
      ],
      "fol_rules": [
        "(Person1(x) ∧ Person2(x) ∧ Person3(x)) ∧ (Person11(x) ∧ Person21(x) ∧ Person31(x))"
      ],
      "fol_conc": "Person11(x) ∧ Person21(x) ∧ Person31(x) ∧ Person11(x) ∧ Person21(x) ∧ Person31(x)",
      "perplexity": 3.876147747039795
    }
  },
  {
    "id": 118,
    "nl_problem": {
      "context": [
        "Barutin Cove is named after the Bulgarian settlement of Barutin.",
        "Barutin Cove is on the southwest coast of Snow Island.",
        "The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island.",
        "The South Shetland Islands are considered part of Antarctica.",
        "If A is located in B and B is located in C, then A is located in C."
      ],
      "question": "Barutin is named after all islands in Antarctica.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.155007004737854,
        1.1232167482376099
      ]
    }
  },
  {
    "id": 119,
    "nl_problem": {
      "context": [
        "Barutin Cove is named after the Bulgarian settlement of Barutin.",
        "Barutin Cove is on the southwest coast of Snow Island.",
        "The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island.",
        "The South Shetland Islands are considered part of Antarctica.",
        "If A is located in B and B is located in C, then A is located in C."
      ],
      "question": "There is at least one cove in Antarctica named after a place in Bulgaria.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "The number of people in the world is determined by the number of people in the world.",
      "perplexity": [
        1.2125871181488037,
        4.145140171051025
      ]
    }
  },
  {
    "id": 120,
    "nl_problem": {
      "context": [
        "Barutin Cove is named after the Bulgarian settlement of Barutin.",
        "Barutin Cove is on the southwest coast of Snow Island.",
        "The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island.",
        "The South Shetland Islands are considered part of Antarctica.",
        "If A is located in B and B is located in C, then A is located in C."
      ],
      "question": "Barutin is not located in Antarctica.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "title": "The Shining",
      "director": "Christopher Nolan",
      "director_director": "Christopher Nolan",
      "director_director_director": "Christopher Nolan",
      "perplexity": [
        1.1724460124969482,
        2.5405309200286865
      ]
    }
  },
  {
    "id": 121,
    "nl_problem": {
      "context": [
        "Some affection is love.",
        "Some love is positive."
      ],
      "question": "Some affection is positive.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "real",
      "perplexity": [
        1.1831060647964478,
        5.089012145996094
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Personal(x)",
        "Personal(n)",
        "Personal(n)",
        "Personal(n)",
        "Personal(n)",
        "Personal(n)",
        "Personal(n)",
        "Personal(n)",
        "Personal(n)"
      ],
      "fol_consts": [
        "personal1",
        "personal2",
        "personal3",
        "personal4",
        "personal5",
        "personal6",
        "personal7",
        "personal8",
        "personal9",
        "personal10"
      ],
      "fol_rules": [
        "(Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x))",
        "Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x)"
      ],
      "fol_conc": "Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x) ∧ Personal(x)",
      "perplexity": 3.0910804271698
    }
  },
  {
    "id": 122,
    "nl_problem": {
      "context": [
        "If something can transport multiple passengers, then they are not empty.",
        "All airlines can transport multiple passengers.",
        "All planes are empty.",
        "All Boeing 707s are planes.",
        "If Greyhound is not an airline, then there are no Greyhound planes."
      ],
      "question": "Greyhound is an airline.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "description": "The Catcher in the Rhone",
      "director": "James Cameron",
      "director_director": "James Cameron",
      "director_director_director": "Director",
      "perplexity": [
        1.117619276046753,
        2.0430779457092285
      ]
    }
  },
  {
    "id": 123,
    "nl_problem": {
      "context": [
        "If something can transport multiple passengers, then they are not empty.",
        "All airlines can transport multiple passengers.",
        "All planes are empty.",
        "All Boeing 707s are planes.",
        "If Greyhound is not an airline, then there are no Greyhound planes."
      ],
      "question": "A Greyhound is a Boeing 707.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "complex": "1.2",
      "perplexity": [
        1.1529943943023682,
        9.814037322998047
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Carrot(x)"
      ],
      "fol_consts": [
        "carrot",
        "carrot",
        "carrot",
        "carrot",
        "carrot",
        "carrot",
        "carrot",
        "carrot",
        "carrot",
        "carrot"
      ],
      "fol_rules": [
        "(Carrot(x) ∧ ¬Carrot(x)) ∧ (Carrot(x) ∧ ¬Carrot(x))"
      ],
      "fol_conc": "Carprovee(x) ∧ ¬Carrot(x) ∧ ¬Carrot(x) ∧ ¬Carrot(x) ∧ ¬Carrot(x) ∧ ¬Carrot(x)",
      "perplexity": 3.7226295471191406
    }
  },
  {
    "id": 124,
    "nl_problem": {
      "context": [
        "If something can transport multiple passengers, then they are not empty.",
        "All airlines can transport multiple passengers.",
        "All planes are empty.",
        "All Boeing 707s are planes.",
        "If Greyhound is not an airline, then there are no Greyhound planes."
      ],
      "question": "A Greyhound is not a Boeing 707.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "The Beatles",
      "perplexity": [
        1.2069919109344482,
        11.8093900680542
      ]
    }
  },
  {
    "id": 125,
    "nl_problem": {
      "context": [
        "All mammals are animals.",
        "All monkeys are mammals. ",
        "An animal is either a monkey or a bird.",
        "All birds fly.",
        "All animals breathe.",
        "If something can fly, then it has wings.",
        "If Rock is neither a fly nor a bird, then Rock neither flies nor breathes."
      ],
      "question": "Rock is a monkey.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.1919913291931152,
        1.1050173044204712
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Monk(x)",
        "Monk(x, y)",
        "Monk(x, z)",
        "Monk(x, z, y)",
        "Monk(x, z, y, z)"
      ],
      "fol_consts": [
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie"
      ],
      "fol_rules": [
        "(Monk(x) ∧ ¬Is(x) ∧ ¬Is(x, y) ∧ ¬Is(x, z) ∧ ¬Is(x, z, y) ∧ ¬Is(x, z, y, z))",
        "Cousin(x) ∧ Cousin(x, y) ∧ Cousin(x, y, z) ∧ Cousin(x, y, z) ∧ Cousin(x, y, z) ∧ Cousin(x, y, z)"
      ],
      "fol_conc": "Cousin(x) ∧ Cousin(x, y) ∧ Cousin(x, y, z) ∧ Cousin(x, y, z, z) ∧ Cousin(x, y, z, z) ∧ Cousin(x, y, z, z)",
      "perplexity": 3.0088577270507812
    }
  },
  {
    "id": 126,
    "nl_problem": {
      "context": [
        "All mammals are animals.",
        "All monkeys are mammals. ",
        "An animal is either a monkey or a bird.",
        "All birds fly.",
        "All animals breathe.",
        "If something can fly, then it has wings.",
        "If Rock is neither a fly nor a bird, then Rock neither flies nor breathes."
      ],
      "question": "Rock has wings.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "answer": "The name of the 1960s British rock band that released the hit songs ",
      "perplexity": [
        1.2168300151824951,
        3.9857211112976074
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Monkey(x)",
        "Monkey(x, y)",
        "Monkey(x, z)",
        "Monkey(x, z, y)",
        "Monkey(x, z, y, z)"
      ],
      "fol_consts": [
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie",
        "charlie"
      ],
      "fol_rules": [
        "(Monkey(x) ∧ ¬Is(x) ∧ ¬Is(x, y) ∧ ¬Is(x, z) ∧ ¬Is(x, z, y) ∧ ¬Is(x, z, y, z))",
        "Catcher(x) ∧ Catcher(x, y) ∧ Catcher(x, y, z) ∧ Catcher(x, y, z) ∧ Catcher(x, y, z, z) ∧ Catcher(x, y, z, z)"
      ],
      "fol_conc": "Catcher(x) ∧ Catcher(x, y, z) ∧ Catcher(x, y, z, z) ∧ Catcher(x, y, z, z) ∧ Catcher(x, y, z, z) ∧ Catcher(x, y, z, z)",
      "perplexity": 2.926875591278076
    }
  },
  {
    "id": 127,
    "nl_problem": {
      "context": [
        "All mammals are animals.",
        "All monkeys are mammals. ",
        "An animal is either a monkey or a bird.",
        "All birds fly.",
        "All animals breathe.",
        "If something can fly, then it has wings.",
        "If Rock is neither a fly nor a bird, then Rock neither flies nor breathes."
      ],
      "question": "Rock does not have wings.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "numbers": [
        "1",
        "2",
        "3",
        "4",
        "5",
        "5",
        "6",
        "7",
        "8",
        "9"
      ],
      "perplexity": [
        1.1307774782180786,
        1.716576099395752
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Monkey(x)"
      ],
      "fol_consts": [
        "rainy",
        "sunny"
      ],
      "fol_rules": [
        "(Moon(x) ∧ ¬Moon(x)) ∧ (Rainy(x) ∧ Rain(x))",
        "(Rainy(x) ∧ ¬Rain(x)) ∧ (Sunny(x) ∧ Sun(x))"
      ],
      "fol_conc": "Rainy(x) ∧ Rain(x) ∧ Sun(x) → ∃x (Monkey(x) ∧ Rain(x)) ∧ ∃x (Sun(x) ∧ Rain(x))",
      "perplexity": 4.694900035858154
    }
  },
  {
    "id": 128,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John has a wedding that is well-attended.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "A rose is a fruit and a rose is a tree.",
      "perplexity": [
        1.1683597564697266,
        4.853047847747803
      ]
    }
  },
  {
    "id": 129,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John does not have a wedding that is well-attended.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "Cubes are a type of geometric shapes that can be formed using three dimensions.",
      "perplexity": [
        1.1923600435256958,
        4.125759601593018
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Person(y)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)"
      ],
      "fol_consts": [
        "person1",
        "person2",
        "person3",
        "person4",
        "person5",
        "person6",
        "person7",
        "person8",
        "person9",
        "person10"
      ],
      "fol_rules": [
        "(Person(x) ∧ Person(y) ∧ Person(z)) → Person(z)"
      ],
      "fol_conc": "Johnsson(x, y) ∧ Person(z) ∧ Person(z) ∧ Person(z) ∧ Person(z) ∧ Person(z)",
      "perplexity": 3.233853816986084
    }
  },
  {
    "id": 130,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John has at least one child.",
      "options": []
    },
    "answer": "C",
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Person(y)",
        "Person(z)",
        "Person(z)",
        "Person(x, y)",
        "Person(z)"
      ],
      "fol_consts": [
        "person1",
        "person2",
        "person3",
        "person4",
        "person5",
        "person6",
        "person7",
        "person8",
        "person9",
        "person10"
      ],
      "fol_rules": [
        "(Person(x) ∧ Person(y) ∧ Person(z)) ∧ Person(z) ∧ Person(x) ∧ Person(z) ∧ Person(z) ∧ Person(x)"
      ],
      "fol_conc": "Johnsage(x) ∧ Person(z) ∧ Person(z) ∧ Person(x) ∧ Person(z) ∧ Person(z)",
      "perplexity": 3.778930902481079
    }
  },
  {
    "id": 131,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John has neither a wedding that is well-attended nor does he travel to Paris for his honeymoon.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "The answer is that arose is a fruit and arose is a tree.",
      "perplexity": [
        1.1921058893203735,
        2.509869337081909
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Person(y)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)",
        "Person(z)"
      ],
      "fol_consts": [
        "person1",
        "person2",
        "person3",
        "person4",
        "person5",
        "person6",
        "person7",
        "person8",
        "person9",
        "person10"
      ],
      "fol_rules": [
        "(Person(x) ∧ Person(y) ∧ Person(z) ∧ Person(z) ∧ Person(z) ∧ Person(z))",
        "Person(x) ∧ Person(y) ∧ Person(z) ∧ Person(z) ∧ Person(z) ∧ Person(z)"
      ],
      "fol_conc": "Johnsian(x, y, z) ∧ Person(x, y, z) ∧ Person(x, y, z) ∧ Person(x, y, z) ∧ Person(x, y, z) ∧ Person(x, y, z)",
      "perplexity": 3.349717855453491
    }
  },
  {
    "id": 132,
    "nl_problem": {
      "context": [
        "[BG] Some mammals have teeth.",
        "Platypus have no teeth.",
        "Platypus are mammals. ",
        "Humans have teeth."
      ],
      "question": "Platypus are mammals with no teeth.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "Realm": "Cubes",
      "Cubes": [
        "3x3",
        "4x4",
        "5x8",
        "6x8",
        "6x8",
        "6x8",
        "6x8"
      ],
      "perplexity": [
        1.1260602474212646,
        2.592606544494629
      ]
    }
  },
  {
    "id": 133,
    "nl_problem": {
      "context": [
        "[BG] Some mammals have teeth.",
        "Platypus have no teeth.",
        "Platypus are mammals. ",
        "Humans have teeth."
      ],
      "question": "Platypus are reptiles.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "previere": [
        "Cucumber",
        "Cucumber",
        "Cucumber",
        "Cucumber",
        "Cucumber",
        "Cucumber",
        "Cucumber",
        "Cucumber",
        "Cucumber",
        "Cucumber"
      ],
      "perplexity": [
        1.1236573457717896,
        1.7950280904769897
      ]
    }
  },
  {
    "id": 134,
    "nl_problem": {
      "context": [
        "[BG] Some mammals have teeth.",
        "Platypus have no teeth.",
        "Platypus are mammals. ",
        "Humans have teeth."
      ],
      "question": "Humans are mammals.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos",
        "Cosmos"
      ],
      "perplexity": [
        1.0570341348648071,
        2.9099738597869873
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Gaboriueein(x)",
        "Pachin(x)",
        "Cachin(x)",
        "Cachin(x)",
        "Cachin(x)"
      ],
      "fol_consts": [
        "cachin",
        "cachin",
        "cachin",
        "cachin",
        "cachin"
      ],
      "fol_rules": [
        "(Cachin(x) ∧ Cachin(x)) ∧ Cassin(x) ∧ Cassin(x) ∧ Cassin(x) ∧ Cassin(x) ∧ Cassin(x)"
      ],
      "fol_conc": "Cassin(x) ∧ Cassin(x) ∧ Cassin(x) ∧ Cassin(x) ∧ Cassin(x) ∧ Cassin(x)",
      "perplexity": 3.9130120277404785
    }
  },
  {
    "id": 135,
    "nl_problem": {
      "context": [
        "Plungers suck.",
        "Vacuums suck.",
        "Vampires suck.",
        "Space is a vacuum.",
        "A duster is a household appliance that doesn't suck."
      ],
      "question": "Space sucks.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 136,
    "nl_problem": {
      "context": [
        "Plungers suck.",
        "Vacuums suck.",
        "Vampires suck.",
        "Space is a vacuum.",
        "A duster is a household appliance that doesn't suck."
      ],
      "question": "Space is a vampire.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "real",
      "perplexity": [
        1.1727714538574219,
        4.9554877281188965
      ]
    }
  },
  {
    "id": 137,
    "nl_problem": {
      "context": [
        "Plungers suck.",
        "Vacuums suck.",
        "Vampires suck.",
        "Space is a vacuum.",
        "A duster is a household appliance that doesn't suck."
      ],
      "question": "If something is a household appliance, it sucks.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 138,
    "nl_problem": {
      "context": [
        "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.",
        "Unsupervised learning doesn't require labelled data.",
        "The state-of-the-art text summarization model is trained with machine learning algorithms.",
        "Reinforcement learning is not used to train the state-of-the-art text summarization model.",
        "The Machine Learning algorithm for training text summarization model requires labelled data."
      ],
      "question": "Supervised learning is used to train the state-of-the-art text summarization model.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "C",
        "C",
        "C",
        "C",
        "C",
        "C",
        "C",
        "C",
        "C",
        "C"
      ],
      "perplexity": [
        1.1082171201705933,
        3.976832151412964
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Computer(x)",
        "Computer(n)",
        "Computer(n)",
        "Computer(n)",
        "Computer(n)",
        "Cognitive(x)",
        "Cognitive(n)"
      ],
      "fol_consts": [
        "computer",
        "computer",
        "computer",
        "computer",
        "computer",
        "computer",
        "computer"
      ],
      "fol_rules": [
        "(Computer(x) ∧ Cognitive(x)) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x)"
      ],
      "fol_conc": "Computer(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x)",
      "perplexity": 3.3383214473724365
    }
  },
  {
    "id": 139,
    "nl_problem": {
      "context": [
        "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.",
        "Unsupervised learning doesn't require labelled data.",
        "The state-of-the-art text summarization model is trained with machine learning algorithms.",
        "Reinforcement learning is not used to train the state-of-the-art text summarization model.",
        "The Machine Learning algorithm for training text summarization model requires labelled data."
      ],
      "question": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "domain",
        "domain",
        "domain",
        "domain",
        "domain"
      ],
      "perplexity": [
        1.1748499870300293,
        6.94636344909668
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Computer(x)",
        "Computer(n)",
        "Computer(n)",
        "Computer(n)",
        "Computer(n)",
        "Cognitive(x)",
        "Cognitive(n)"
      ],
      "fol_consts": [
        "computer",
        "computer",
        "computer",
        "computer",
        "computer",
        "computer",
        "computer"
      ],
      "fol_rules": [
        "(Computer(x) ∧ Cognitive(x)) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x)"
      ],
      "fol_conc": "Computer(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x) ∧ Cognitive(x)",
      "perplexity": 3.28757905960083
    }
  },
  {
    "id": 140,
    "nl_problem": {
      "context": [
        "If a cartoon character is funny, then it is popular.",
        "If a cartoon character is ugly, then it is not popular.",
        "If a cartoon character is loved by children, then it is funny.",
        "If a cartoon character is from The Simpsons, then it is loved by children.",
        "If a cartoon character is yellow, then it is from The Simpsons.",
        "Ben is either from The Simpsons or funny."
      ],
      "question": "Ben is loved by children.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.1950035095214844,
        3.0826966762542725
      ]
    }
  },
  {
    "id": 141,
    "nl_problem": {
      "context": [
        "If a cartoon character is funny, then it is popular.",
        "If a cartoon character is ugly, then it is not popular.",
        "If a cartoon character is loved by children, then it is funny.",
        "If a cartoon character is from The Simpsons, then it is loved by children.",
        "If a cartoon character is yellow, then it is from The Simpsons.",
        "Ben is either from The Simpsons or funny."
      ],
      "question": "Ben is ugly or yellow.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "The movie is not funny.",
      "perplexity": [
        1.2482765913009644,
        9.229315757751465
      ]
    }
  },
  {
    "id": 142,
    "nl_problem": {
      "context": [
        "If a cartoon character is funny, then it is popular.",
        "If a cartoon character is ugly, then it is not popular.",
        "If a cartoon character is loved by children, then it is funny.",
        "If a cartoon character is from The Simpsons, then it is loved by children.",
        "If a cartoon character is yellow, then it is from The Simpsons.",
        "Ben is either from The Simpsons or funny."
      ],
      "question": "Ben is either yellow and ugly or neither yellow nor ugly.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "Dog",
      "perplexity": [
        1.0981922149658203,
        12.488903999328613
      ]
    }
  },
  {
    "id": 143,
    "nl_problem": {
      "context": [
        "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.",
        "Heck cattle were bred-back in the 1920s to resemble the aurochs.",
        "[BG] Heck cattle are animals.",
        "[BG] Aurochs are animals.",
        "Some animals to be bred-back resemble animals that are extinct."
      ],
      "question": "Some Heck cattle are artificially selected.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Breldedbye(x)",
        "Ribs(x)",
        "Nibs(x)"
      ],
      "fol_consts": [
        "nibs",
        "breldedbye"
      ],
      "fol_rules": [
        "(Nibs(x) ∧ Civic(x))",
        "Civic(x) → ∀x (Nibs(x) ∧ Civic(x))",
        "Nibs(x) → ∀x (Nibs(x) ∧ Civic(x))",
        "Nibs(x) → ∀x (Nibs(x) ∧ Civic(x))",
        "Nibs(x) → ∀x (Nibs(x) ∧ Civic(x))",
        "Nibs(x) → ∀x (Nibs(x) ∧ Civic(x))"
      ],
      "fol_conc": "Nibs(x) ∧ Civic(x) → ∀x (Nibs(x) ∧ Civic(x))",
      "perplexity": 2.9509966373443604
    }
  },
  {
    "id": 144,
    "nl_problem": {
      "context": [
        "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.",
        "Heck cattle were bred-back in the 1920s to resemble the aurochs.",
        "[BG] Heck cattle are animals.",
        "[BG] Aurochs are animals.",
        "Some animals to be bred-back resemble animals that are extinct."
      ],
      "question": "Aurochs are extinct.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "Cold",
        "Soft",
        "Soft",
        "Soft",
        "Soft",
        "Soft",
        "Soft",
        "Soft",
        "Soft",
        "Soft"
      ],
      "soft": [
        "soft",
        "soft",
        "soft",
        "soft",
        "soft",
        "soft",
        "soft",
        "soft",
        "soft",
        "soft"
      ],
      "perplexity": [
        1.1887855529785156,
        2.977893829345703
      ]
    }
  },
  {
    "id": 145,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Jerry is young.",
      "options": []
    },
    "answer": "C",
    "logic_problem_gcd": {
      "fol_preds": [
        "Study(x)",
        "Teaching(x)",
        "Teaching(x)",
        "Inequality(x)"
      ],
      "fol_consts": [
        "x1",
        "x2",
        "x3",
        "x4",
        "x5",
        "x6",
        "x7",
        "x8",
        "x9"
      ],
      "fol_rules": [
        "(Study(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x))",
        "(Xerox(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x))"
      ],
      "fol_conc": "Inequality(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x) ∧ ¬Is(x)",
      "perplexity": 4.030185222625732
    }
  },
  {
    "id": 146,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Jerry is not young.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "Personnyss",
      "perplexity": [
        1.1194918155670166,
        12.220771789550781
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Study(x)",
        "Teach(x)"
      ],
      "fol_consts": [
        "x1",
        "x2",
        "x3",
        "x4",
        "x5",
        "x6",
        "x7",
        "x8",
        "x9"
      ],
      "fol_rules": [
        "(Study(x)) ∧ (Teach(x)) ∧ (Develop(x) ∧ ¬Isteafe(x))"
      ],
      "fol_conc": "Inequality(x) ∧ ¬Isteafe(x) ∧ ¬Isteafe(x) ∧ ¬Isteafe(x) ∧ ¬Isteafe(x) ∧ ¬Isteafe(x)",
      "perplexity": 4.230286598205566
    }
  },
  {
    "id": 147,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Rose is a human or a manager.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 148,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Rose is a human or Jerry is a manager.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "Alice is a person, Bob is a person, and Carol is a person.",
      "Alice is a person, Bob is a person, and Carol is a person.": "Alice is a person, Bob is a person, and Carol is a person.",
      "perplexity": [
        1.2256921529769897,
        3.353771686553955
      ]
    }
  },
  {
    "id": 149,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "It is not true that Rose is a student and Jerry is a human.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "temporal",
        "physical",
        "temporal",
        "physical",
        "temporal",
        "temporal",
        "temporal",
        "temporal",
        "temporal",
        "temporal"
      ],
      "perplexity": [
        1.1107040643692017,
        3.32517409324646
      ]
    }
  },
  {
    "id": 150,
    "nl_problem": {
      "context": [
        "New Vessel Press is a publishing house which specializes in translating foreign literature into English.",
        "All of New Vessel Press's published books are in English.",
        "Neapolitan Chronicles is a book published by New Vessel Press.",
        "Neapolitan Chronicles was translated from Italian.",
        "Palace of Flies is a book published by New Vessel Press."
      ],
      "question": "Neapolitan Chronicles is an English book.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 151,
    "nl_problem": {
      "context": [
        "New Vessel Press is a publishing house which specializes in translating foreign literature into English.",
        "All of New Vessel Press's published books are in English.",
        "Neapolitan Chronicles is a book published by New Vessel Press.",
        "Neapolitan Chronicles was translated from Italian.",
        "Palace of Flies is a book published by New Vessel Press."
      ],
      "question": "Harry Potter was published by New Vessel Press.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "title": "The Catcher in the Rhyme",
      "author": "J.D. Salinger",
      "year": 1951,
      "perplexity": [
        1.1319546699523926,
        2.0793182849884033
      ]
    }
  },
  {
    "id": 152,
    "nl_problem": {
      "context": [
        "New Vessel Press is a publishing house which specializes in translating foreign literature into English.",
        "All of New Vessel Press's published books are in English.",
        "Neapolitan Chronicles is a book published by New Vessel Press.",
        "Neapolitan Chronicles was translated from Italian.",
        "Palace of Flies is a book published by New Vessel Press."
      ],
      "question": "Palace of Flies was translated from Italian.",
      "options": []
    },
    "answer": "C"
  },
  {
    "id": 153,
    "nl_problem": {
      "context": [
        "If people own a large desktop monitor at their home, then they work regularly and often at home.",
        "All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.",
        "All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.",
        "All people who work regularly and often at home visit the office supply store regularly.",
        "If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. ",
        "Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home. "
      ],
      "question": "Remy visits the office supply store regularly.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "P",
        "P",
        "P",
        "P",
        "P",
        "P",
        "P",
        "P",
        "P",
        "P"
      ],
      "perplexity": [
        1.0757324695587158,
        3.8002824783325195
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Potential(x)",
        "Potential(x)"
      ],
      "fol_consts": [
        "x1",
        "x2",
        "x3",
        "x4",
        "x5",
        "x6",
        "x7",
        "x8",
        "x9"
      ],
      "fol_rules": [
        "(Person(x)) ∧ (Potential(x)) ∧ (Potential(x) ∧ Potential(x))"
      ],
      "fol_conc": "Person(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x) ∧ Potential(x)",
      "perplexity": 3.8450698852539062
    }
  },
  {
    "id": 154,
    "nl_problem": {
      "context": [
        "If people own a large desktop monitor at their home, then they work regularly and often at home.",
        "All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.",
        "All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.",
        "All people who work regularly and often at home visit the office supply store regularly.",
        "If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. ",
        "Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home. "
      ],
      "question": "Remy has a fully stocked and impressive home office and also visits the office supply store regularly.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "Person",
        "Person",
        "Person",
        "Person",
        "Person",
        "Person",
        "Person"
      ],
      "perplexity": [
        1.0542062520980835,
        4.040270805358887
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Premetty(x)",
        "Premetty(x)"
      ],
      "fol_consts": [
        "x1",
        "x2",
        "x3",
        "x4",
        "x5",
        "x6",
        "x7",
        "x8",
        "x9"
      ],
      "fol_rules": [
        "(Person(x)) ∧ (Premetty(x)) ∧ (Premetty(x) ∧ Xerox(x))"
      ],
      "fol_conc": "Person(x) ∧ Premetty(x) ∧ Xerox(x) → Xerox(x) ∧ Xerox(x) ∧ Xerox(x)",
      "perplexity": 3.721729040145874
    }
  },
  {
    "id": 155,
    "nl_problem": {
      "context": [
        "If people own a large desktop monitor at their home, then they work regularly and often at home.",
        "All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.",
        "All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.",
        "All people who work regularly and often at home visit the office supply store regularly.",
        "If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. ",
        "Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home. "
      ],
      "question": "If Remy either goes to bed late and wakes up every day after noon or visits the office supply store regularly, then Remy neither spends their free time tidying and organizing the spaces in their home nor has a fully stocked and impressive home office.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "total_elements": 5,
      "total_elements_in_elements": 5,
      "total_elements_in_elements_in_data": 5,
      "total_elements_in_elements_in_data-1": 5,
      "total_elements_in_elements_in_data-2": 5,
      "total_elements_in_elements_in_data-3": 5,
      "total_elements_in_elements_in_data-4": 5,
      "total_elements_in_elements_in_data-5": 5,
      "perplexity": [
        1.2027530670166016,
        1.518943190574646
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Carbon(x)",
        "Carbon(x)"
      ],
      "fol_consts": [
        "carbon",
        "carbon",
        "carbon"
      ],
      "fol_rules": [
        "(Coinsticks(x) ∧ Coinsticks(x))",
        "Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x)"
      ],
      "fol_conc": "Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x) ∧ Coinsticks(x)",
      "perplexity": 4.243164539337158
    }
  },
  {
    "id": 156,
    "nl_problem": {
      "context": [
        "All humans are mortal.",
        "All Greeks are humans."
      ],
      "question": "Some Greeks are mortal.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "examples": [
        "1. Cannot be done.",
        "2. Cannot be done.",
        "3. Cannot be done.",
        "4. Cannot be done.",
        "5. Cannot be done.",
        "6. Cannot be done.",
        "7. Cannot be done.",
        "8. Cannot be done.",
        "9. Cannot be done.",
        "10. Cannot be done.",
        "11. Cannot be done.",
        "12. Cannot be done.",
        "13. Cannot be done.",
        "14. Cannot be done.",
        "15. Cannot be done.",
        "16. Cannot be done.",
        "17. Cannot be done.",
        "18. Cannot be done.",
        "19. Cannot be done.",
        "20. Cannot be done.",
        "21. Cannot be done.",
        "22. Cannot be done.",
        "23. Cannot be done.",
        "24. Cannot be done.",
        "25. Cannot be done.",
        "26. Cannot be done.",
        "27. Cannot be done.",
        "28. Cannot be done.",
        "29. Cannot be done.",
        "30. Cannot be done.",
        "31. Cannot be done.",
        "32. Cannot be done.",
        "33. Cannot be done.",
        "34. Cannot be done.",
        "35. Cannot be done.",
        "36. Cannot be done.",
        "37. Cannot be done.",
        "38. Cannot be done.",
        "39. Cannot be done.",
        "40. Cannot be done.",
        "41. Cannot be done.",
        "42. Cannot be done.",
        "43. Cannot be done.",
        "44. Cannot be done.",
        "45. Cannot be done.",
        "46. Cannot be done.",
        "47. Cannot be done.",
        "48. Cannot be done.",
        "49. Cannot be done.",
        "50. Cannot be done.",
        "51. Cannot be done.",
        "52. Cannot be done.",
        "53. Cannot be done.",
        "54. Cannot be done.",
        "55. Cannot be done.",
        "56. Cannot be done.",
        "57. Cannot be done.",
        "58. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done.",
        "59. Cannot be done."
      ],
      "perplexity": [
        1.1044374704360962,
        1.122412919998169
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Alien(x)",
        "Cerebral(x)",
        "Cerebral(x)"
      ],
      "fol_consts": [
        "eau",
        "cerebral",
        "cerebral",
        "tebral",
        "cerebral",
        "cerebral",
        "cerebral",
        "cerebral",
        "cerebral"
      ],
      "fol_rules": [
        "(Alien(x)) ∧ Cerebral(x) ∧ Cerebral(x) ∧ Cerebral(x) ∧ Cerebral(x) ∧ Cerebral(x)"
      ],
      "fol_conc": "Alien(x) ∧ Cerebral(x) ∧ Cerebral(x) ∧ Cerebral(x) ∧ Cerebral(x) ∧ Cerebral(x)",
      "perplexity": 3.4831507205963135
    }
  },
  {
    "id": 157,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "James has a part-time job offered by the university.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "name": "Frankenstein",
      "author": "Frankenstein",
      "title": "The Catcher in the Rhyme",
      "perplexity": [
        1.2871562242507935,
        1.9488716125488281
      ]
    }
  },
  {
    "id": 158,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "James does not have a part-time job offered by the university.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 159,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "James either takes the database course or has a part-time job offered by the university.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "domain",
        "domain",
        "domain",
        "domain",
        "domain"
      ],
      "perplexity": [
        1.168928623199463,
        5.793467044830322
      ]
    }
  },
  {
    "id": 160,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "Jack takes the database course.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "Realize that you can't buy a car.",
      "perplexity": [
        1.1648292541503906,
        11.755428314208984
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Aliceein(x)",
        "Aliceein(x)",
        "Aliceein(x)",
        "Aliceein(x)"
      ],
      "fol_consts": [
        "akaein",
        "akaein",
        "akaein",
        "akaein",
        "akaein",
        "akaein",
        "akaein",
        "akaein",
        "akaein"
      ],
      "fol_rules": [
        "(Aliceein(x) ∧ Akaein(x))",
        "(Aliceein(x) ∧ Akaein(x)) ∧ ¬Akaein(x) ∧ ¬Akaein(x) ∧ ¬Akaein(x) ∧ ¬Akaein(x) ∧ ¬Akaein(x)"
      ],
      "fol_conc": "Aliceein(x) ∧ Akaein(x) ∧ ¬Akaein(x) ∧ ¬Akaein(x) ∧ ¬Akaein(x) ∧ ¬Akaein(x)",
      "perplexity": 3.1641945838928223
    }
  },
  {
    "id": 161,
    "nl_problem": {
      "context": [
        "If George likes music, he wants to compose.",
        "If George has access to a program, he can compose.",
        "If George can compose and wants to compose, he will compose."
      ],
      "question": "If George likes music and has access to a program, he will compose.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.1510497331619263,
        6.966813087463379
      ]
    }
  },
  {
    "id": 162,
    "nl_problem": {
      "context": [
        "If George likes music, he wants to compose.",
        "If George has access to a program, he can compose.",
        "If George can compose and wants to compose, he will compose."
      ],
      "question": "If George will not compose, George can not compose.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain",
        "domain"
      ],
      "perplexity": [
        1.082922101020813,
        3.69222354888916
      ]
    }
  },
  {
    "id": 163,
    "nl_problem": {
      "context": [
        "A hawk never lands. ",
        "Some birds are hawks."
      ],
      "question": "All birds land",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 164,
    "nl_problem": {
      "context": [
        "On some Mondays at 8 pm, roses are given out on TV.",
        "Every rose given out on TV is on the Bachelor.",
        "Everything on the Bachelor portrays the lives of real people.",
        "All shows portraying the lives of real people are reality TV shows.",
        "Breaking Bad is not a reality TV show."
      ],
      "question": "Breaking Bad is on Monday at 8 pm.",
      "options": []
    },
    "answer": "C"
  },
  {
    "id": 165,
    "nl_problem": {
      "context": [
        "On some Mondays at 8 pm, roses are given out on TV.",
        "Every rose given out on TV is on the Bachelor.",
        "Everything on the Bachelor portrays the lives of real people.",
        "All shows portraying the lives of real people are reality TV shows.",
        "Breaking Bad is not a reality TV show."
      ],
      "question": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "Real",
      "perplexity": [
        1.2184381484985352,
        10.45300006866455
      ]
    }
  },
  {
    "id": 166,
    "nl_problem": {
      "context": [
        "On some Mondays at 8 pm, roses are given out on TV.",
        "Every rose given out on TV is on the Bachelor.",
        "Everything on the Bachelor portrays the lives of real people.",
        "All shows portraying the lives of real people are reality TV shows.",
        "Breaking Bad is not a reality TV show."
      ],
      "question": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 167,
    "nl_problem": {
      "context": [
        "Heinrich Scmidt was a Nazi German politician. ",
        "Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag."
      ],
      "question": "Heinrich Schmidt was either German or Russian.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 168,
    "nl_problem": {
      "context": [
        "Heinrich Scmidt was a Nazi German politician. ",
        "Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag."
      ],
      "question": "Some Nazi German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
      "options": []
    },
    "answer": "A"
  },
  {
    "id": 169,
    "nl_problem": {
      "context": [
        "Heinrich Scmidt was a Nazi German politician. ",
        "Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag."
      ],
      "question": "No politicans are part of the Nazi Reichstag.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 170,
    "nl_problem": {
      "context": [
        "If something is a deadly disease, then its survival rate is low. ",
        "All severe cancers are deadly diseases.",
        "Bile duct cancer is a severe cancer. ",
        "All Cholangiocarcinoma is bile duct cancer.",
        "No one with mild flu has a low survival rate.",
        "If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer."
      ],
      "question": "Colorectal cancer is a severe cancer",
      "options": []
    },
    "answer": "C",
    "logic_problem_gcd": {
      "fol_preds": [
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)"
      ],
      "fol_consts": [
        "cousntion",
        "cousntion",
        "cousntion",
        "cousntion",
        "cousntion",
        "cousntion",
        "cousntion",
        "cousntion",
        "cousntion"
      ],
      "fol_rules": [
        "(Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x))"
      ],
      "fol_conc": "Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x)",
      "perplexity": 2.5986781120300293
    }
  },
  {
    "id": 171,
    "nl_problem": {
      "context": [
        "If something is a deadly disease, then its survival rate is low. ",
        "All severe cancers are deadly diseases.",
        "Bile duct cancer is a severe cancer. ",
        "All Cholangiocarcinoma is bile duct cancer.",
        "No one with mild flu has a low survival rate.",
        "If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer."
      ],
      "question": "If colorectal cancer is a bile duct cancer or a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer and a mild flu.",
      "options": []
    },
    "answer": "A",
    "logic_problem_gcd": {
      "fol_preds": [
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)"
      ],
      "fol_consts": [
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion"
      ],
      "fol_rules": [
        "(Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x))"
      ],
      "fol_conc": "Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x)",
      "perplexity": 3.086989402770996
    }
  },
  {
    "id": 172,
    "nl_problem": {
      "context": [
        "If something is a deadly disease, then its survival rate is low. ",
        "All severe cancers are deadly diseases.",
        "Bile duct cancer is a severe cancer. ",
        "All Cholangiocarcinoma is bile duct cancer.",
        "No one with mild flu has a low survival rate.",
        "If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer."
      ],
      "question": "If colorectal cancer is not a mild flu and a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer or a Cholangiocarcinoma.",
      "options": []
    },
    "answer": "B",
    "logic_problem_gcd": {
      "fol_preds": [
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)",
        "Cosntion(x)"
      ],
      "fol_consts": [
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion",
        "cosntion"
      ],
      "fol_rules": [
        "(Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x))"
      ],
      "fol_conc": "Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x) ∧ Cosntion(x)",
      "perplexity": 2.566643476486206
    }
  },
  {
    "id": 173,
    "nl_problem": {
      "context": [
        "All people who eat salads regularly are very conscious about their health and eating habits.",
        "All people who grew up in health-conscious childhood homes eat salads regularly.",
        "All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.",
        "If people have good relationships with their parents, then they fulfill their nutritional daily intakes.",
        "If people have good relationships with their parents, then they do not eat salads regularly.",
        "If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.",
        "It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents."
      ],
      "question": "Taylor eats salads regularly.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "Realm of knowledge",
        "Realm of communication",
        "Realm of communication and knowledge"
      ],
      "elements": [
        "Person",
        "Personalities",
        "Personalities and knowledge"
      ],
      "conclusion": "The realms of knowledge, the realms of communication, and the realms of knowledge are all realms of human interaction.",
      "perplexity": [
        1.1425594091415405,
        2.6513168811798096
      ]
    }
  },
  {
    "id": 174,
    "nl_problem": {
      "context": [
        "All people who eat salads regularly are very conscious about their health and eating habits.",
        "All people who grew up in health-conscious childhood homes eat salads regularly.",
        "All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.",
        "If people have good relationships with their parents, then they fulfill their nutritional daily intakes.",
        "If people have good relationships with their parents, then they do not eat salads regularly.",
        "If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.",
        "It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents."
      ],
      "question": "Taylor visits the gym at least once a day.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.039383053779602,
        2.300260543823242
      ]
    }
  },
  {
    "id": 175,
    "nl_problem": {
      "context": [
        "All people who eat salads regularly are very conscious about their health and eating habits.",
        "All people who grew up in health-conscious childhood homes eat salads regularly.",
        "All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.",
        "If people have good relationships with their parents, then they fulfill their nutritional daily intakes.",
        "If people have good relationships with their parents, then they do not eat salads regularly.",
        "If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.",
        "It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents."
      ],
      "question": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "real": "The real thing is that you can't know what it's like to be a person who doesn't eat a peach.",
      "perplexity": [
        1.1986305713653564,
        7.646789073944092
      ]
    }
  },
  {
    "id": 176,
    "nl_problem": {
      "context": [
        "[BG] The Olympic games is a sporting event. ",
        "The last Olympic games was in Tokyo.",
        "The United States won the most medals in Tokyo. "
      ],
      "question": "The world championships is a sporting event.",
      "options": []
    },
    "answer": "C"
  },
  {
    "id": 177,
    "nl_problem": {
      "context": [
        "[BG] The Olympic games is a sporting event. ",
        "The last Olympic games was in Tokyo.",
        "The United States won the most medals in Tokyo. "
      ],
      "question": "The last Olympic games were not in Tokyo.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "The North Atlantic Ocean is the world's largest cenntion, located in the North Atlantic region of the opntion. It is a region of the oceent that is a part of the continental oceent. The oceent is a large, thin, and deep-sea region, with a large, thin, and deep-sea region. The oceent is a significant part of the continental oceent and is a significant part of the global economy. The oceent is a large, thin, and deep-sea region, with a large, thin, and deep-sea region. The oceent is a significant part of the continental oceent and is a significant part of the global economy.",
      "perplexity": [
        1.3154387474060059,
        2.236469268798828
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Celebrated(s)",
        "Unseen(s)",
        "Unseen(s)",
        "Unseen(s)",
        "Unseen(s)",
        "Unseen(s)",
        "Unseen(s)"
      ],
      "fol_consts": [
        "celebrated",
        "unseen",
        "unseen",
        "unseen",
        "unseen",
        "unseen",
        "unseen"
      ],
      "fol_rules": [
        "(Socnts(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s))",
        "Untouched(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s)"
      ],
      "fol_conc": "Celebrated(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s) ∧ Unseen(s)",
      "perplexity": 3.5779545307159424
    }
  },
  {
    "id": 178,
    "nl_problem": {
      "context": [
        "[BG] The Olympic games is a sporting event. ",
        "The last Olympic games was in Tokyo.",
        "The United States won the most medals in Tokyo. "
      ],
      "question": "The United States won the most medals in the last Olympic games.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "examples": [
        "What is the name of the world's largest ocean, located in the North Atlantic?",
        "What is the name of the continent where the North Atlantic is located?",
        "What is the name of the continent that is covered by the North Atlantic?",
        "What is the name of the continent that is covered by the North Atlantic?",
        "What is the name of the continent that is covered by the North Atlantic?",
        "What is the name of the continent that is covered by the North Atlantic?",
        "What is the name of the continent that is covered by the North Atlantic?",
        "What is the name of the continent that is covered by the North Atlantic?",
        "What is the name of the continent that is covered by the North Atlantic?"
      ],
      "perplexity": [
        1.1872265338897705,
        1.895461082458496
      ]
    }
  },
  {
    "id": 179,
    "nl_problem": {
      "context": [
        "All horses have hooves.",
        "No humans have hooves."
      ],
      "question": "Some humans are horses.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "dog",
        "cat"
      ],
      "examples": [
        "dog",
        "cat"
      ],
      "perplexity": [
        1.212737798690796,
        6.519896030426025
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Horses(x)",
        "Carrots(x)",
        "Casses(x)"
      ],
      "fol_consts": [
        "irrainy",
        "carrots",
        "casses"
      ],
      "fol_rules": [
        "(Horses(x)) ∧ (Carrots(x)) ∧ (Casses(x))"
      ],
      "fol_conc": "Yesterday(x) ∧ ∃x (Casses(x) ∧ Casses(x))",
      "perplexity": 4.728562355041504
    }
  },
  {
    "id": 180,
    "nl_problem": {
      "context": [
        "Susan flies to LGA airport.",
        "The departure and arrival can not be the same airport.",
        "John flies from LGA airport."
      ],
      "question": "Susan flies from LGA airport.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "real",
      "perplexity": [
        1.274092435836792,
        5.8056745529174805
      ]
    }
  },
  {
    "id": 181,
    "nl_problem": {
      "context": [
        "Susan flies to LGA airport.",
        "The departure and arrival can not be the same airport.",
        "John flies from LGA airport."
      ],
      "question": "John flies to LGA airport.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "Cube is a mathematical concept that represents a number, while cube is a physical unit used to measure dimensions.",
      "perplexity": [
        1.2670199871063232,
        3.0542094707489014
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Susaein(x)",
        "Travel(x, y)",
        "Travel(x, y)",
        "Travel(x, y)",
        "Travel(x, y)"
      ],
      "fol_consts": [
        "sussaein",
        "travel",
        "travel",
        "travel",
        "travel"
      ],
      "fol_rules": [
        "(Sussaein(x) ∧ ¬Is(x, y)) ∧ (Trip(x, y) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y))"
      ],
      "fol_conc": "Urnts(x) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y) ∧ ¬Travel(x, y)",
      "perplexity": 3.7879791259765625
    }
  },
  {
    "id": 182,
    "nl_problem": {
      "context": [
        "No one nice to animals is mean to animals.",
        "Some grumpy people are mean to animals.",
        "All animal lovers are nice to animals.",
        "If someone owns a pet, then they love animals.",
        "Tom is a pet owner."
      ],
      "question": "Tom is a grumpy person.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "real": "dog",
      "perplexity": [
        1.1510311365127563,
        9.155641555786133
      ]
    },
    "logic_problem_gcd": {
      "fol_preds": [
        "Person(x)",
        "Person(n)",
        "Person(n)",
        "Person(n)",
        "Person(n)",
        "Person(n)",
        "Person(n)",
        "Person(n)",
        "Person(n)"
      ],
      "fol_consts": [
        "realm",
        "realm",
        "realm",
        "realm",
        "realm",
        "realm",
        "realm",
        "realm",
        "realm",
        "realm"
      ],
      "fol_rules": [
        "(Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x))",
        "Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x)"
      ],
      "fol_conc": "Tomisaueein(x) ∧ Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x) ∧ Person(x)",
      "perplexity": 3.9979848861694336
    }
  },
  {
    "id": 183,
    "nl_problem": {
      "context": [
        "No one nice to animals is mean to animals.",
        "Some grumpy people are mean to animals.",
        "All animal lovers are nice to animals.",
        "If someone owns a pet, then they love animals.",
        "Tom is a pet owner."
      ],
      "question": "Tom is not a grumpy person and mean to animals.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "examples": [
        "1. cube: 3 * 3 * 3 = 9"
      ],
      "exclude": [
        "3. cube: 3 * 3 * 3 = 9"
      ],
      "perplexity": [
        1.1327835321426392,
        2.3872687816619873
      ]
    }
  },
  {
    "id": 184,
    "nl_problem": {
      "context": [
        "No one nice to animals is mean to animals.",
        "Some grumpy people are mean to animals.",
        "All animal lovers are nice to animals.",
        "If someone owns a pet, then they love animals.",
        "Tom is a pet owner."
      ],
      "question": "If Tom is not a grumpy person and mean to animals, then Tom is neither a grumpy person nor an Animal Lover.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 185,
    "nl_problem": {
      "context": [
        "A podcast is not a novel.",
        "[BG] If a person is born in American City, the person is American.",
        "[BG] If a book is novel and it is written by a person, then the person is a novel writer.",
        "Dani Shapiro is an American writer.",
        "Family History is written by Dani Shapiro.",
        "Family History is a novel written in 2003.",
        "Dani Shapiro created a podcast called Family Secrets.",
        "[BG] Boston is an American city."
      ],
      "question": "Dani Shapiro is a novel writer.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "description": "The novelist Jane Doe is a detective who solved the theft and the stolen diamond necklace.",
      "perplexity": [
        1.214951515197754,
        6.4999775886535645
      ]
    }
  },
  {
    "id": 186,
    "nl_problem": {
      "context": [
        "A podcast is not a novel.",
        "[BG] If a person is born in American City, the person is American.",
        "[BG] If a book is novel and it is written by a person, then the person is a novel writer.",
        "Dani Shapiro is an American writer.",
        "Family History is written by Dani Shapiro.",
        "Family History is a novel written in 2003.",
        "Dani Shapiro created a podcast called Family Secrets.",
        "[BG] Boston is an American city."
      ],
      "question": "Family Secrets is a novel.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.0543677806854248,
        1.1662585735321045
      ]
    }
  },
  {
    "id": 187,
    "nl_problem": {
      "context": [
        "A podcast is not a novel.",
        "[BG] If a person is born in American City, the person is American.",
        "[BG] If a book is novel and it is written by a person, then the person is a novel writer.",
        "Dani Shapiro is an American writer.",
        "Family History is written by Dani Shapiro.",
        "Family History is a novel written in 2003.",
        "Dani Shapiro created a podcast called Family Secrets.",
        "[BG] Boston is an American city."
      ],
      "question": "Dani Shapiro was born in Boston.",
      "options": []
    },
    "answer": "C"
  },
  {
    "id": 188,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "Yuri is an American.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "entities": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "examples": [
        "example1",
        "example2",
        "example3",
        "example4",
        "example5",
        "example6",
        "example7",
        "example8",
        "example9",
        "example10"
      ],
      "perplexity": [
        1.1452244520187378,
        1.9864808320999146
      ]
    }
  },
  {
    "id": 189,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "Yuri is not an American basketball player.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "context": "The question is asking about the difference between a cube and a cube.",
      "perplexity": [
        1.1963797807693481,
        4.630316734313965
      ]
    }
  },
  {
    "id": 190,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "Yuri is an American basketball player.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 191,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "If Yuri does not wear large shoes, then Yuri is an American basketball player.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "examples": [
        "apple",
        "orange",
        "kiwi",
        "orange",
        "kiwi",
        "orange",
        "kiwi",
        "orange",
        "kiwi",
        "orange"
      ],
      "perplexity": [
        1.1789604425430298,
        2.785073757171631
      ]
    }
  },
  {
    "id": 192,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "If Yuri is not an American basketball player, then Yuri is a basketball player.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "description": "The difference between a good boy and a bad boy is: ",
      "perplexity": [
        1.2150927782058716,
        4.551275253295898
      ]
    }
  },
  {
    "id": 193,
    "nl_problem": {
      "context": [
        "Events are either happy or sad.",
        "At least one event is happy. "
      ],
      "question": "All events are sad.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "Rovers are real.",
      "perplexity": [
        1.224413514137268,
        4.459139823913574
      ]
    }
  },
  {
    "id": 194,
    "nl_problem": {
      "context": [
        "The winner of the 1992 du Maurier Classic was Steinhauer.",
        "Steinhauer participated in the 1992 du Maurier Classic.",
        "There was one six-way tie on the leaderboard and one person in the six-way tie was from Belgium.",
        "Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.",
        "All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic."
      ],
      "question": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 195,
    "nl_problem": {
      "context": [
        "The winner of the 1992 du Maurier Classic was Steinhauer.",
        "Steinhauer participated in the 1992 du Maurier Classic.",
        "There was one six-way tie on the leaderboard and one person in the six-way tie was from Belgium.",
        "Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.",
        "All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic."
      ],
      "question": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
      "options": []
    },
    "answer": "C",
    "logic_problem_gcd": {
      "fol_preds": [
        "Inequality(x)",
        "Career(x)",
        "Career(n)"
      ],
      "fol_consts": [
        "inneviue",
        "career",
        "career",
        "career",
        "career",
        "career",
        "career"
      ],
      "fol_rules": [
        "(Dreams(x) ∧ Career(x)) ∧ (Career(x) ∧ Career(x))",
        "(Dreams(x) ∧ Career(x)) ∧ (Career(x) ∧ Career(x))",
        "Career(x) ∧ Career(x) ∧ Career(x) ∧ Career(x) ∧ Career(x) ∧ Career(x)"
      ],
      "fol_conc": "Ineviue(x) ∧ Career(x) ∧ Career(x) ∧ Career(x) ∧ Career(x) ∧ Career(x)",
      "perplexity": 4.153960704803467
    }
  },
  {
    "id": 196,
    "nl_problem": {
      "context": [
        "If an animal barks, then Jane does not like it.",
        "All dogs are animals that bark.",
        "If an animal jumps, then Jane likes it.",
        "If an animal has legs, then it jumps.",
        "If an animal is terricolous, then it has legs. ",
        "If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs."
      ],
      "question": "KiKi is terricolous.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.0302715301513672,
        1.2919307947158813
      ]
    }
  },
  {
    "id": 197,
    "nl_problem": {
      "context": [
        "If an animal barks, then Jane does not like it.",
        "All dogs are animals that bark.",
        "If an animal jumps, then Jane likes it.",
        "If an animal has legs, then it jumps.",
        "If an animal is terricolous, then it has legs. ",
        "If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs."
      ],
      "question": "KiKi barks and is a dog.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.029834270477295,
        1.2919307947158813
      ]
    }
  },
  {
    "id": 198,
    "nl_problem": {
      "context": [
        "If an animal barks, then Jane does not like it.",
        "All dogs are animals that bark.",
        "If an animal jumps, then Jane likes it.",
        "If an animal has legs, then it jumps.",
        "If an animal is terricolous, then it has legs. ",
        "If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs."
      ],
      "question": "KiKi neither barks nor is a dog.",
      "options": []
    },
    "answer": "A",
    "logic_problem": {
      "realms": [
        "Cucumber",
        "Banana"
      ],
      "examples": [
        "Cucumber",
        "Banana"
      ],
      "perplexity": [
        1.1553778648376465,
        3.921207904815674
      ]
    }
  },
  {
    "id": 199,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "No one playing for Nautico is Brazilian.",
      "options": []
    },
    "answer": "B"
  },
  {
    "id": 200,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton Silva foes not play for a football club.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "Alice is a football player, Bob is a football player, and Carol is a football player.",
      "perplexity": [
        1.2956279516220093,
        6.099954128265381
      ]
    }
  },
  {
    "id": 201,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton was not loaned out to a football club.",
      "options": []
    },
    "answer": "B",
    "logic_problem": {
      "real": "real",
      "perplexity": [
        1.229591965675354,
        7.7514166831970215
      ]
    }
  },
  {
    "id": 202,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton Silva played for Fluminense.",
      "options": []
    },
    "answer": "C"
  },
  {
    "id": 203,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton Silva was loaned out to a football club.",
      "options": []
    },
    "answer": "C",
    "logic_problem": {
      "realms": [
        "realms",
        "realms",
        "realms",
        "realms",
        "realms"
      ],
      "perplexity": [
        1.4157977104187012,
        1.118388056755066
      ]
    }
  }
]