[
  {
    "id": 0,
    "nl_problem": {
      "context": [
        "If people perform in school talent shows often, then they attend and are very engaged with school events.",
        "People either perform in school talent shows often or are inactive and disinterested members of their community.",
        "If people chaperone high school dances, then they are not students who attend the school.",
        "All people who are inactive and disinterested members of their community chaperone high school dances.",
        "All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.",
        "Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school. "
      ],
      "question": "Bonnie performs in school talent shows often.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 1,
    "nl_problem": {
      "context": [
        "If people perform in school talent shows often, then they attend and are very engaged with school events.",
        "People either perform in school talent shows often or are inactive and disinterested members of their community.",
        "If people chaperone high school dances, then they are not students who attend the school.",
        "All people who are inactive and disinterested members of their community chaperone high school dances.",
        "All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.",
        "Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school. "
      ],
      "question": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"AttendSchool(x)\", \"VeryEngagedWithEvents(x)\", \"PerformInTalentShowOften(x)\", \"InactiveAndDisinterestedMemberCommunity(x)\", \"ChaperoneHighSchoolDance(x)\", \"StudentAtSchool(x)\", \"YoungChildOrTeenagerWhoWishesToFurtherTheirAcademicCareerAndEducationalOpportunities\", \"NeitherAttendNorBeVeryEngagedWithEvents\"],\"fol_consts\": [\"bonnie\"],\"fol_rules\": [], \"fol_conc\": \"\"}",
      "perplexity": 1.9376435279846191,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 2,
    "nl_problem": {
      "context": [
        "If people perform in school talent shows often, then they attend and are very engaged with school events.",
        "People either perform in school talent shows often or are inactive and disinterested members of their community.",
        "If people chaperone high school dances, then they are not students who attend the school.",
        "All people who are inactive and disinterested members of their community chaperone high school dances.",
        "All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.",
        "Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school. "
      ],
      "question": "If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 3,
    "nl_problem": {
      "context": [
        "All employees who schedule a meeting with their customers will appear in the company today. ",
        "Everyone who has lunch in the company schedules meetings with their customers. ",
        "Employees will either have lunch in the company or have lunch at home.",
        "If an employee has lunch at home, then he/she is working remotely from home.",
        "All employees who are in other countries work remotely from home. ",
        "No managers work remotely from home. ",
        "James is either a manager and appears in the company today or neither a manager nor appears in the company today."
      ],
      "question": "James has lunch in the company.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Employee(x)\", \"ScheduleMeeting(x, y)\", \"AppearInCompany(x)\", \"HasLunch(x)\", \"WorkRemotelyFromHome(x)\" ],  \"fol_consts\": [\"james\"], \"fol_rules\": [ \"‚àÄx (ScheduleMeeting(x, customer) ‚Üí AppearInCompany(x))\", \"‚àÄx (HasLunch(x) ‚àß ScheduleMeeting(x, customer))\", \"‚àÉx (WorkRemotelyFromHome(x) ‚à® HasLunch(x))\", \"¬¨(Manager(x) ‚àß AppearInCompany(x))\" , \"‚àÄx ((WorkRemotelyFromHome(x) ‚Üí AppearsInCompany(x)) ‚àß ¬¨Manager(x))\"],  \"fol_conc\": \"HasLunch(james)\" }",
      "perplexity": 1.4878616333007812,
      "answer": "C",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 4,
    "nl_problem": {
      "context": [
        "All employees who schedule a meeting with their customers will appear in the company today. ",
        "Everyone who has lunch in the company schedules meetings with their customers. ",
        "Employees will either have lunch in the company or have lunch at home.",
        "If an employee has lunch at home, then he/she is working remotely from home.",
        "All employees who are in other countries work remotely from home. ",
        "No managers work remotely from home. ",
        "James is either a manager and appears in the company today or neither a manager nor appears in the company today."
      ],
      "question": "James does not have lunch in the company.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 5,
    "nl_problem": {
      "context": [
        "All employees who schedule a meeting with their customers will appear in the company today. ",
        "Everyone who has lunch in the company schedules meetings with their customers. ",
        "Employees will either have lunch in the company or have lunch at home.",
        "If an employee has lunch at home, then he/she is working remotely from home.",
        "All employees who are in other countries work remotely from home. ",
        "No managers work remotely from home. ",
        "James is either a manager and appears in the company today or neither a manager nor appears in the company today."
      ],
      "question": "If James is either a manager or in other countries,  then James either has lunch at home and works remotely from home, or neither has lunch at home nor works remotely from home.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"Employee(x)\", \",\"\n  , \"ScheduleMeetingWithCustomer(x, y)\",\n  \"InCompany(x) \",\n  \"LunchAtHome(y)\",\n  \"RemoteWorkFromHome(x)\",\n  \"Manager(x)\",\n  \"IsPresentInCountry(x, y)\" , 1],\n  \"fol_consts\": [\n    \"james\",\n    \"customer\",\n    \"manager\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"RemoteWorkFromHome(James) ‚à® (LunchAtHome(James))\"\n}",
      "perplexity": 2.5044777393341064,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 6,
    "nl_problem": {
      "context": [
        "Monkeypox is an infectious disease caused by the monkeypox virus.",
        "Monkeypox virus can occur in certain animals, including humans.",
        "Humans are mammals.",
        "Mammals are animals.",
        "Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.",
        "People feel tired when they get a glu."
      ],
      "question": "There is an animal.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"InfectiousDisease(x)\",\n    \"CausedBy(x, y)\",\n    \"OccurInAnimal(x, y)\",\n    \"Mammal(x)\",\n    \"Animal(x)\",\n    \"Symptoms(x)\",\n    \"FeelingTired(y)\" \n  ],\n  \"fol_consts\": [\n    \"monkeypox\",\n    \"virus\",\n    \"humans\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"‚àÉx (Animal(x))\"\n}\n```",
      "perplexity": 1.2402631044387817,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\" llow: \"\n  \t\t :\"fol_preds\", \":[ ]\"\n   \t :\"fol_consts\", \":[ \" :\", \" ,\",] ,\"\n  \t \t: \"fol_rules\", \":[ ], ]} )))))\"\n  \t\t: \"fol_conc\", \"}} } }\"\n  \t\t\t: \"fol_preds\", \":[ \" :\", ]\"\n   \t ,\"fol_consts\": [ \"Animal\"], \",\"\n  \t \t: \"fol_rules\" ,\"[ ]]}]}]] )))))\" :\"fol_conc\", \"\"\n\t\t: \":\" }\n",
      "perplexity": 14.12329387664795,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Animal(x)\", \"InfectiousDisease(x)\", \"Virus(x)\", \"Mammal(x)\", \"Human(x)\", \"Symptom(x)\", \"Tiredness(y, z)\"],  \"fol_consts\":[\"monkeypox\",\"virus\", \"animal\"], \"fol_rules\":[\n    \"‚àÉx (Animal(x))\", \"‚àÄx (InfectiousDisease(x) ‚Üí Virus(x))\", \"Virus(x) ‚Üí Mammal(x)\",\n    \"Mammal(x) ‚Üí Animal(x)\", \"Human(x) ‚àß Animal(x)\" , \"Symptom(y, z) ‚Üí Tiredness(z, y)\" ],  \"fol_conc\": \"‚àÉx (Animal(x))\"}",
      "perplexity": 2.630002498626709,
      "answer": "A",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 7,
    "nl_problem": {
      "context": [
        "Monkeypox is an infectious disease caused by the monkeypox virus.",
        "Monkeypox virus can occur in certain animals, including humans.",
        "Humans are mammals.",
        "Mammals are animals.",
        "Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.",
        "People feel tired when they get a glu."
      ],
      "question": "No one gets flu.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Is(x)\",\n    \"CausedBy(x, y)\",\n    \"OccurIn(x, y)\",\n    \"Mammal(x)\",\n    \"Animal(x)\",\n    \"FeelTired(y)\",\n    \"HaveSymptoms(x)\"\n  ],\n  \"fol_consts\": [\n    \"monkeypox\",\n    \"MonkeypoxVirus\",\n    \"Human\",\n    \"Flu\" \n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"¬¨‚àÄx (FeelTired(x))\"\n}\n\n```",
      "perplexity": 1.4155874252319336,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"IsInfectiousDisease(x)\", \"CausedBy(x, y)\", \"OccurIn(x, y)\", \"Mammal(x)\", \"Animal(x)\", \"HasSymptoms(x)\"],\"fol_consts\": [\n  \"Monkeypox\", \",\" ,\n  \"Human\", \"Flu\"], \"fol_rules\":[\"\"], \"fol_conc\":\"\"}",
      "perplexity": 2.8519163131713867,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"InfectiousDisease(x)\", \"CauseByVirus(x)\", \"Mammal(x)\", \"Animal(x)\", \"SymptomOf(x, y)\"], \n  \"fol_consts\": [\n    \"monkeypox\",\n    \"monkeypoxvirus\",\n    \"human\",\n    \"mammal\",\n    \"flu\" ], \n  \"fol_rules\": [\"InfectiousDisease(monkeypox)\", \"CauseByVirus(monkeypoxvirus)\"], \n  \"fol_conc\": \"¬¨ExistentialFlu(x)\" }",
      "perplexity": 2.001188278198242,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 8,
    "nl_problem": {
      "context": [
        "Monkeypox is an infectious disease caused by the monkeypox virus.",
        "Monkeypox virus can occur in certain animals, including humans.",
        "Humans are mammals.",
        "Mammals are animals.",
        "Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.",
        "People feel tired when they get a glu."
      ],
      "question": "Symptons of Monkeypox include coughing.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Infectious\", \"Virus\", \"Occur\", \"Mammal\", \"Animal\",\"Symptoms\",\"FeelTired\"],\"fol_consts\":[\"monkeypox\", \"virus\",\"humans\",\"mammals\",\"animals\"], \"fol_rules\": [], \"fol_conc\": \"Symptom(Monkeypox, Coughing)}\" }",
      "perplexity": 2.898743152618408,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Symptom(Monkeypox, Coughing)}"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"InfectiousDisease(x)\", \"Virus(y)\", \"CauseBy(x, y)\", \"Animal(z)\", \"Mammal(a)\", \"SymptomsOf(x)\", \"FeelingTired(x)\" ], \"fol_consts\": [\"monkeypox\"], \"fol_rules\": [ \"‚àÄx (InfectiousDisease(x) ‚Üí Virus(x))\", \"‚àÉx ‚àÄy (CauseBy(x, y) ‚Üí Animal(y))\", \"‚àÉx ‚àÄz (Animal(z) ‚Üí Mammal(z))\", \"‚àÄx (SymptomsOf(x) ‚äï FeelingTired(x))\" ], \"fol_conc\": \"SymptoomsOf(monkeypox)\"}",
      "perplexity": 1.8105130195617676,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 9,
    "nl_problem": {
      "context": [
        "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould‚Äôs wild turkey, Merriam‚Äôs wild",
        "turkey, Rio Grande wild turkey, and Ocellated wild turkey.",
        "Tom is not an Eastern wild turkey.",
        "Tom is not an Osceola wild turkey.",
        "Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.",
        "Tom is a wild turkey."
      ],
      "question": "Tom is an Ocellated wild turkey.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"WildTurkey(x)\", \"NotWildTurkey(x)\", \"IsEasternWildTurkey(x)\",\"IsOsceolaWildTurkey(x)\", \"IsGouldsWildTurkey(x)\", \"IsMerriamsWildTurkey(x)\", \"IsRioGrandeWildTurkey(x)\", \"IsOcellatedWildTurkey(x)\" ],\"fol_consts\": [\"Tom\"],\"fol_rules\": [\"\"], \"fol_conc\": \"IsOcellatedWildTurkey(tom)\"}",
      "perplexity": 1.3655219078063965,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 10,
    "nl_problem": {
      "context": [
        "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould‚Äôs wild turkey, Merriam‚Äôs wild",
        "turkey, Rio Grande wild turkey, and Ocellated wild turkey.",
        "Tom is not an Eastern wild turkey.",
        "Tom is not an Osceola wild turkey.",
        "Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.",
        "Tom is a wild turkey."
      ],
      "question": "Tom is an Eastern wild turkey.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 11,
    "nl_problem": {
      "context": [
        "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould‚Äôs wild turkey, Merriam‚Äôs wild",
        "turkey, Rio Grande wild turkey, and Ocellated wild turkey.",
        "Tom is not an Eastern wild turkey.",
        "Tom is not an Osceola wild turkey.",
        "Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.",
        "Tom is a wild turkey."
      ],
      "question": "Joey is a wild turkey.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\" üß† \"\n  \t  : { \"+\": [],\n\t\t\t\"fol_preds\": [ \"\\t\\tDependent(x)\", \"\\t\\tTypeOfWildTurkey(x)\"],\n\t\t  \"fol_consts\": [ \"tom\", \"joey\", \"eastern wild turkey\", \"osceola wild turkey\", \"gould's wild turkey\", \"merriam's wild turkey\", \"rio grande wild turkey\", \"ocellated wild turkey\"] , \"}\\t\\t: { 1 : 2, \\t\"\n  \t\t :\", \"\n\t}\n\t\t\t }",
      "perplexity": 6.47860860824585,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 12,
    "nl_problem": {
      "context": [
        "A Japanese game company created the game the Legend of Zelda.",
        "All games in the Top 10 list are made by Japanese game companies.",
        "[BG] If a game sells more than one million copies, then it will be selected into the Top 10 list.",
        "The Legend of Zelda sold more than one million copies."
      ],
      "question": "The Legend of Zelda is in the Top 10 list.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"CreatedBy(x, y)\",\n    \"InTop10List(x)\",\n    \"SoldMoreThanOneMillionCopies(x)\",\n    \"IsJapaneseCompany(y)\" \n  ],\n  \"fol_consts\": [\n    \"Zelda\",\n    \"LegendOfZelda\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (CreatedBy(x, y) ‚Üí InTop10List(y))\",\n    \"‚àÄx (SoldMoreThanOneMillionCopies(x) ‚àß InTop10List(x))\",\n    \"IsJapaneseCompany(JapanGameCo)\"\n  ],\n  \"fol_conc\": \"InTop10List(Zelda)\"\n}\n```",
      "perplexity": 1.270731806755066,
      "answer": "A",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"created\", \"game\", \"Top10List\",\"sellsMoreThanOneMillionCopies\"], \"fol_consts\": [\"The Legend of Zelda\", \"JapaneseGameCompany\",\"BG\"],\"fol_rules\": [], \"fol_conc\": \"In the Top 10 list\"}\n",
      "perplexity": 2.48230242729187,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "In the Top 10 list"
    }
  },
  {
    "id": 13,
    "nl_problem": {
      "context": [
        "A Japanese game company created the game the Legend of Zelda.",
        "All games in the Top 10 list are made by Japanese game companies.",
        "[BG] If a game sells more than one million copies, then it will be selected into the Top 10 list.",
        "The Legend of Zelda sold more than one million copies."
      ],
      "question": "FIFA 22 is made by a Japanese video game company.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Created(x, y)\", \"Top10(x)\", \"MakesGameCompany(y)\", \"SoldMoreThanOneMillionCopies(x)\"],  \"fol_consts\": [\"thelegendofzelda\", \"fifa22\"],  \"fol_rules\":[\n   \"‚àÄx (Created(x, thelegendofzelda) ‚Üí Top10(x))\", \"Top10(x) ‚àß SoldMoreThanOneMillionCopies(x)\" , \"MakesGameCompany(y) ‚Üí Top10(y)\", \"FIFA22MadeByJapaneseVideoGameCompany(fifa22)\"\n   ],  \"fol_conc\": \"FIFA22MadeByJapaneseVideoGameCompany(fifa22)\" }",
      "perplexity": 2.242486000061035,
      "answer": "C",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 14,
    "nl_problem": {
      "context": [
        "A Japanese game company created the game the Legend of Zelda.",
        "All games in the Top 10 list are made by Japanese game companies.",
        "[BG] If a game sells more than one million copies, then it will be selected into the Top 10 list.",
        "The Legend of Zelda sold more than one million copies."
      ],
      "question": "The Legend of Zelda is not in the Top 10 list.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Created\", \"Top10List(x)\", \"GameCompany(x)\", \"SoldMoreThanOneMillionCopies(x)\"], \"fol_consts\": [\"LegendOfZelda\", \"Japanese\", \"Games\",\"Top 10 List\"], \"fol_rules\": [\"\"], \"fol_conc\": \"\" }\n",
      "perplexity": 2.4257171154022217,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 15,
    "nl_problem": {
      "context": [
        "All squares have four sides.",
        "All four-sided things are shapes. "
      ],
      "question": "All squares are shapes.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Square(x)\",\n    \"FourSides(x)\",\n    \"Shape(x)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [],\n  \"fol_conc\": \"‚àÄx (Square(x) ‚àß Shape(x))\"\n}\n```",
      "perplexity": 1.1263673305511475,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Square\", \"FourSidedThing\", \"Shape\"],\n  \"fol_consts\": [], \",\"\n  : \"square\" ,\n  \"foll rules\": [\n    \"‚àÄx (Square(x) ‚Üí FourSidedThing(x))\",\n    \"‚àÄx (FourSidedThing(x) ‚Üí Shape(x))\" ],\n\"fol_conc\": \"‚àÄx (Square(x) ‚Üí Shape(x))\"}",
      "perplexity": 2.492140531539917,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Square(x)\", \"FourSided(x)\",\"Shape(x)\" ], \"fol_consts\": [ \"square\", \"foursided\"],  \"fol_rules\": [\n    \"‚àÄx (Square(x) ‚àß FourSided(x)) ‚Üí Shape(x)\", \"‚àÄx (Square(x) ‚àß FourSided(x))\"\n], \"fol_conc\": \"‚àÄx (Shape(x) ‚àß Square(x))\"}",
      "perplexity": 2.044163465499878,
      "answer": "A",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 16,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "Rock is a turtle.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Cute(x)\",\n    \"ExistentialTurtle(x)\", \n    \"Rabbit(x)\",\n    \"Squirrel(x)\",\n    \"Skittish(x)\",\n    \"Still(x)\"\n  ],\n  \"fol_consts\": [\n    \"rock\",\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Cute(x) ‚àß ExistentialTurtle(x))\",\n    \"‚àÉx (Rabbit(x) ‚à® Squirrel(x))\",\n    \"Skittish(x) ‚Üí ¬¨Still(x)\",\n    \"‚àÄx (Squirrel(x) ‚àß Skittish(x))\",\n    \"¬¨ExistentialTurtle(rock)\"\n  ],\n  \"fol_conc\": \"Rock is a turtle\"\n}\n```",
      "perplexity": 1.1869111061096191,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 12 column 3 (char 170)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Cute(x)\", \"Exist(turtles)\", \"Animal(x)\"], \"fol_consts\": [], \"fol_rules\": [\"\"], \"fol_conc\": \"Rock is a turtle\" } ",
      "perplexity": 2.0958282947540283,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Rock is a turtle"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Cute(x)\", \"Exist(x)\", \"IsRabbit(x)\", \"IsSquirrel(x)\", \"Skittish(x)\", \"Still(x)\"], \"fol_consts\":[\"rock\", \"turtle\"], \"fol_rules\":[\n    \"‚àÄx (Cute(x) ‚Üí IsRabbit(x)) ‚àß ‚àÉx (Exist(x))\", \"‚àÄx (IsRabbit(x) ‚à® IsSquirrel(x))\", \"IfSkittish(x) ‚Üí NotStill(x)\", \"AllSquirrelsAreSkittish(x)\",\n    \"NotRock(x) ‚àß Still(x) ‚àß Exist(x)\"\n], \"fol_conc\": \"IsTurtle(rock)\"}",
      "perplexity": 1.981472134590149,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 17,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "Rock is not a turtle.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Cute(x)\", \"Exist(x)\", \"Animal(x)\", \"Skittish(x)\", \"Still(x)\", \"Rabbit(x)\"],\"fol_consts\":[ \"rock\", \"turtle\", \"squirrel\"],\n  \"fol_rules\": [\n    \"‚àÄx (Cute(x) ‚üπ Animal(x))\",\n    \"‚àÉx Exist(x)\",\n    \"‚àÄx (Animal(x) ‚üπ Rabbit(x) ‚à® Squirrel(x))\",\n    \"Skittish(x) ‚Üí NotStill(x)\",\n    \"‚àÄx (Squirrel(x) ‚üπ Skittish(x))\",\n    \"NotRabbit(rock)\"\n  ],\n \"fol_conc\": \"¬¨Exist(turtle)\"}\n",
      "perplexity": 1.52274751663208,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "‚àÄx (Cute(x) ‚üπ Animal(x))"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Cute(x)\", \"Exists(x)\", \"Rabbit(x)\", \"Squirrel(x)\", \"Skittish(x)\", \"Still(x)\"], \n\"fol_consts\": [\"rock\", \"turtles\"], \n\"fol_rules\": [\n    \"‚àÄx (Rabbit(x) ‚Üí Cute(x))\", \"‚àÉx (Turtler(x))\", \"Animal(x) ‚Üí (Rabbit(x) ‚à® Squirrel(x))\", \"Skittish(x) ‚Üí ¬¨Still(x)\", \"All(squirrel) ‚Üí Skittish(squirrel)\"\n], \n\"fol_conc\": \"¬¨RockIsTurtle(rock)\" }",
      "perplexity": 1.9015244245529175,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Squirrel/1, Squirrel/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Squirrel/1, Squirrel/0"
    }
  },
  {
    "id": 18,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "Rock is a turtle or cute.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Cute(x)\", \"Exist(x)\",\"Animal(x)\"],\"fol_consts\":[\"rock\", \"rabbit\",\"turtle\"],\"fol_rules\":[\n  \"(‚àÄx (Rabbit(x)) ‚Üí Cute(x)), ‚àÉx (exist(x)) ‚àß Animal(x)\",\n  \"((SomeTurtles(x)) ‚à® Exist(x)) ‚àß (Animal(x) ‚äï Rabbit(x)),\", \"\\n (Animal(x) ‚à® Squirrel(x)) \\n \", \"Skittish(x) ‚Üí NotStill(x), \\n\\n (AllSquirrels(x) ‚àß Skittish(x))\",\n  \"NotStill(rock)\",\n   \"\" ], \"fol_conc\": \"Rock ‚à® Cute\"}\n",
      "perplexity": 2.752243995666504,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "(‚àÄx (Rabbit(x)) ‚Üí Cute(x)), ‚àÉx (exist(x)) ‚àß Animal(x)"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n  \"IsCute(x)\",\n  \"Exists(x)\", \"Rabbit(x)\", \"Squirrel(x)\", \"Skittish(x)\" ,\n  \"Still(x)\"], \"fol_consts\": [\n    \"rock\",\n    \"animal\"\n  ], \"fol_rules\": [\n   \"‚àÄx (IsCute(x) ‚Üí Rabbit(x))\", \"‚àÉx (Exists(x) ‚àß Squirrel(x))\", \"Skittish(x) ‚Üí ¬¨Still(x)\", \"‚àÄx (Squirrel(x) ‚Üí Skittish(x))\", \"NotRabbit(rock) ‚äï Exists(animal)\"\n  ], \"fol_conc\": \"RockOrCute(rock)\"\n}",
      "perplexity": 2.309572458267212,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 19,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "If Rock is not both a turtle and a squirrel, then Rock is either cute or skittish.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\" üçÉ üå±  fol_preds: [\": \"Cute(x)\", \"ExistentialTurtles(x)\" :\n\"Skittish(x)\", \"Rabbit(x) , Squirrel(x) ] üåø  , üå±\"\n    :\"is (x) \" } ",
      "perplexity": 15.555716514587402,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Cute(x)\", \"Exist(x)\", \"Animal(x)\", \"Skittish(x)\"], \"fol_consts\": [\"rock\", \"turtle\", \"squirrel\"],  \"fol_rules\": [\n    \"‚àÄx (Rabbit(x) ‚Üí Cute(x))\", \"‚àÉx (Turtle(x))\", \"All(animal, rabbit) ‚à® All(animal, squirrel)\", \"Skittish(x) ‚Üí NotStill(x)\", \"All(squirrel, skittish)\" , \"NotSkittish(rock)\"],  \"fol_conc\": \"IfRockIsNeitherTurtleNorSquirrelThenCuteOrSkittish(rock)\"\n}",
      "perplexity": 2.256164073944092,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Skittish/1, Skittish/0, Rabbit/1, Rabbit/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Skittish/1, Skittish/0, Rabbit/1, Rabbit/0"
    }
  },
  {
    "id": 20,
    "nl_problem": {
      "context": [
        "All rabbits are cute. ",
        "Some turtles exist. ",
        "An animal is either a rabbit or a squirrel.",
        "If something is skittish, then it is not still.",
        "All squirrels are skittish.",
        "Rock is still."
      ],
      "question": "If Rock is cute and still, then Rock is a turtle and skittish.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Cute(x)\", \"Exists(x)\", \"Rabbit(x)\", \"Squirrel(x)\", \"Skittish(x)\", \"Still(x)\"],\n\"fol_consts\": [\n  \"rock\", \",\"\n],\n\"fol_rules\": [],\n\"fol_conc\": \"Rock is Cute and Still ‚Üí Rock is a Turtle and Skittish\"}\n",
      "perplexity": 1.8428583145141602,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Rock is Cute and Still ‚Üí Rock is a Turtle and Skittish"
    }
  },
  {
    "id": 21,
    "nl_problem": {
      "context": [
        "\"Stranger Things\" is a popular Netflix show.",
        "If a Netflix show is popular, Karen will binge-watch it.",
        "If and only if Karen binge-watches a Netflix show, she will download it.",
        "Karen does not download \"Black Mirror\".",
        "\"Black Mirror\" is a Netflix show.",
        "If Karen binge-watches a Netflix show, she will share it to Lisa."
      ],
      "question": "Karen will share \"Stranger Things\" to Lisa.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Popular(x)\", \"BingeWatch(x, y)\", \"Download(x, y)\", \"Show(y)\"],\"fol_consts\": [\"Karen\",\"Stranger Things\", \"Black Mirror\", \"Lisa\", \"Netflix\"],\"fol_rules\":[\n  \"‚àÄx (Popular(x) ‚Üí BingeWatch(x, Karen))\", 1,\"BingeWatch(x, y) ‚àß Download(x, y) ‚Üí x= Netflix Show\",\n  \"¬¨Download(Karen, Black Mirror)\", \"BingeWatch(Karen, Netflix Show) ‚à® Download(Karen, Netflix show) ‚Üí ShareTo(Karen, Lisa)\",\n  \"\"],\n\"fol_conc\": \"ShareTo(Karen, Lisa)\" }",
      "perplexity": 2.0603549480438232,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Popular(x)\", \"BingeWatch(x, y)\", \"Download(y)\", \"ShareTo(x, y)\", \"NetflixShow(x)\"],  \"fol_consts\": [\"karen\", \"blackmirror\",\"strangerthings\"], \"fol_rules\":[\n    \"Popular(netflixshow) ‚Üí BingeWatch(karen, netflixshow)\", \"(BingeWatch(karen, netflixshow)) ‚Üí Download(karen, netflixshow)\",\n    \"¬¨Download(karen, blackmirror)\" , \"(NetflixShow(x) ‚àß BingeWatch(karen, x)) ‚Üí ShareTo(karen, x)\",\n  \"StrangerThingsPopular(netflixshow) ‚Üí NetflixShow(netflixshow)\"\n], \"fol_conc\": \"ShareTo(karen, strangerthings)\" }",
      "perplexity": 2.071624279022217,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 22,
    "nl_problem": {
      "context": [
        "\"Stranger Things\" is a popular Netflix show.",
        "If a Netflix show is popular, Karen will binge-watch it.",
        "If and only if Karen binge-watches a Netflix show, she will download it.",
        "Karen does not download \"Black Mirror\".",
        "\"Black Mirror\" is a Netflix show.",
        "If Karen binge-watches a Netflix show, she will share it to Lisa."
      ],
      "question": "\"Black Mirror\" is popular.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"Popular(x)\", \"BingeWatch(x, y)\", \"Download(x, y)\", \"Share(x, y)\", \"NetflixShow(x)\" ], \"\\n\"\n  \t\t :\"fol_consts\" , \"[ 'Stranger Things', 'Black Mirror', 'Karen', 'Lisa']\\n\"\n   \t :\"fol_rules\" , \"\\n    ‚àÄx (Popular(x) ‚Üí BingeWatch(karen, x)) \\n     BingeWatch(karen, NetflixShow) ‚àß Download(karen, y) ‚Üí  Share(karen, lisa) \\n \"\n     : \"\\n       ¬¨Download(\"\n}",
      "perplexity": 3.973745822906494,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 23,
    "nl_problem": {
      "context": [
        "\"Stranger Things\" is a popular Netflix show.",
        "If a Netflix show is popular, Karen will binge-watch it.",
        "If and only if Karen binge-watches a Netflix show, she will download it.",
        "Karen does not download \"Black Mirror\".",
        "\"Black Mirror\" is a Netflix show.",
        "If Karen binge-watches a Netflix show, she will share it to Lisa."
      ],
      "question": "Karen will share \"Black Mirror\" to Lisa.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Popular(x)\", \"BingeWatch(x, y)\", \"Download(x, y)\", \"ShareTo(x, y)\"],\"fol_consts\":[\"StrangerThings\",\"Karen\", \"Lisa\", \"BlackMirror\",\"Netflix\"],\"fol_rules\":[\n  \"‚àÄx (Popularity(x) ‚Üí BingeWatch(x))\", 1\n  ,\"BingeWatch(x) ‚Üí Download(x)\",\n   \"NotDownload(x) ‚àß Popularity(x) ‚Üí ShareTo(x, Lisa)\"\n], \"fol_conc\": \"ShareTo(Karen, BlackMirror)\" }",
      "perplexity": 2.2167840003967285,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"NetflixShow(x)\", \"Popular(x)\", \"BingeWatch(x, y)\", \"Download(x, y)\", \"Share(x, y)\"], \"fol_consts\":[\"stranger\", \"karen\",\"blackmirror\", \"lisa\"], \"fol_rules\": [\n    \"‚àÄx (NetflixShow(x) ‚àß Popular(x)) ‚Üí BingeWatch(karen, x)\",\n    \"BingeWatch(karen, x) ‚Üí Download(karen, x)\",\n    \"¬¨Download(karen, x) ‚Üí ¬¨Share(karen, x)\",\n    \"BlackMirror(x) ‚àß NetflixShow(x)\" ,\n    \"BingeWatch(karen, x) ‚Üí Share(karen, lisa)\"], \"fol_conc\": \"Share(karen, blackmirror)\"}",
      "perplexity": 1.4742255210876465,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 24,
    "nl_problem": {
      "context": [
        "Beijing is the capital of the People's Republic of China. ",
        "Beijing is the world's most populous national capital city.",
        "Beijing is located in Northern China.",
        "Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.",
        "Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics",
        "Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world."
      ],
      "question": "Beijing has hosted both the 2008 Summer Olympics and a winter olympics.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Capital(x, y)\", \n    \"WorldPopulousNationalCaptitalCity(x)\",\n    \"LocatedIn(x, y)\",\n    \"HostedOlympics(x, y)\",\n    \"ConsistentlyRankedAmongTheBest(x)\",\n  ],\n  \"fol_consts\": [\n    \"beijing\", \n    \"china\", \n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"HostedOlympics(Beijing, Summer Olympics) ‚àß HostedOlympics(Beijing, Winter Olympics)\"\n}\n```",
      "perplexity": 1.418407917022705,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 8 column 3 (char 179)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Capital(x)\", \"PopulousCity(x)\", \"Location(x, y)\", \"HostedGames(x, y)\", \"University(x)\", \"BestInTheAsiaPacific\"],\n  \"fol_consts\": [\n    \"Beijing\",\n    \"People'sRepublicOfChina\", 0\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"HostedGames(Beijing, SummerOlympics) ‚àß HostedGames(Beijing, WinterOlympics)\" } ",
      "perplexity": 1.8688429594039917,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 25,
    "nl_problem": {
      "context": [
        "Beijing is the capital of the People's Republic of China. ",
        "Beijing is the world's most populous national capital city.",
        "Beijing is located in Northern China.",
        "Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.",
        "Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics",
        "Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world."
      ],
      "question": "Beijing is located in southern China.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 26,
    "nl_problem": {
      "context": [
        "Beijing is the capital of the People's Republic of China. ",
        "Beijing is the world's most populous national capital city.",
        "Beijing is located in Northern China.",
        "Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.",
        "Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics",
        "Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world."
      ],
      "question": "Beijing is the second largest Chinese city by urban population.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Capital(x)\", \"Population(x, y)\", \"Location(x, y)\", \"Hosted(x, y)\", \"Ranked\", \"Urban\"],\n\"fol_consts\": [\n  \"Beijing\", 2019,\"China\", \"Summer Olympics\",\"Winter Olympics\", \"Paralympics\",\"Asia-Pacific\"] ,\n\"fol_rules\": [],\n\"fol_conc\": \"None\"}\n",
      "perplexity": 2.632402181625366,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "None"
    }
  },
  {
    "id": 27,
    "nl_problem": {
      "context": [
        "All aliens are extraterrestrial.",
        "If someone is from Mars, then they are aliens.",
        "No extraterrestrial is human.",
        "Everyone from Earth is a human.",
        "Marvin cannot be from Earth and from Mars.",
        "If Marvin is not from Earth, then Marvin is an extraterrestrial."
      ],
      "question": "Marvin is an alien.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Alien(x)\",\n    \"Extraterrestrial(x)\",\n    \"Human(x)\",\n    \"FromEarth(x, y)\", \n    \"Mars(y)\" ,\n  ],\n  \"fol_consts\": [\n    \"Marvin\",\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Alien(x) ‚Üí Extraterrestrial(x))\",\n    \"‚àÄx (FromEarth(x, Earth) ‚àß Alien(x))\",\n    \"¬¨Extraterrestrial(x) ‚à® Human(x)\",\n    \"¬¨FromEarth(Marvin, Mars)\",\n    \"¬¨FromEarth(Marvin, Earth) ‚Üí Alien(Marvin)\" ,  \n  ],\n  \"fol_conc\": \"Alien(Marvin)\" \n}\n\n```",
      "perplexity": 1.3666951656341553,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 8 column 3 (char 120)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Alien(x)\", \"Extraterrestrial(x)\", \"Human(x)\", \"From(x, y)\"],\"fol_consts\": [\"Marvin\"],\"fol_rules\":[\n    \"‚àÄx (Alien(x) ‚àß Extraterrestrial(x))\",\n    \"If (From(x, Mars) )  then ( Alien(x))\",\n    \"¬¨(Extraterrestrial(x) ‚àß Human(x))\",\n    \"‚àÄx ( From(x, Earth) ‚Üí Human(x)),\"\n    ,\" ¬¨(From(Marvin, Earth) ‚àß From(Mars, Marvin)) \",\n    \"If (Not From(Marvin, Earth))  then Alien(Marvin)\"\n],\"fol_conc\": \"Alien(Marvin)}\"}",
      "perplexity": 1.7678221464157104,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "If (From(x, Mars) )  then ( Alien(x))"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Alien(x)\", \"Extraterrestrial(x)\", \"Human(x)\", \"FromMars(x)\", \"NotEarth(x)\"],  \"fol_consts\": [\"marvin\"], \"fol_rules\": [\n    \"‚àÄx (Alien(x) ‚Üí Extraterrestrial(x))\", \"(FromMars(x) ‚Üí Alien(x))\", \"(¬¨Extraterrestrial(x) ‚Üí Human(x))\", \"AllHumansAreOnEarth(x)\", \"NotEarth(marvin) ‚Üí Alien(marvin)\",\n    \"MarvinNotFromEarthAndMars(x)\"\n  ],  \"fol_conc\": \"Alien(marvin)\"}",
      "perplexity": 2.2214417457580566,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 28,
    "nl_problem": {
      "context": [
        "All aliens are extraterrestrial.",
        "If someone is from Mars, then they are aliens.",
        "No extraterrestrial is human.",
        "Everyone from Earth is a human.",
        "Marvin cannot be from Earth and from Mars.",
        "If Marvin is not from Earth, then Marvin is an extraterrestrial."
      ],
      "question": "Marvin is neither a human nor from Mars.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Alien(x)\",\n    \"FromMars(x)\",\n    \"Human(x)\",\n    \"Earthly(x)\"\n  ],\n  \"fol_consts\": [\n    \"marvin\", \n    \"mars\",\n    \"earth\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Alien(x) ‚Üí Extraterrestrial(x))\",\n    \"FromMars(x) ‚Üí Alien(x)\",\n    \"¬¨ExtraterrestrialsHuman(x)\", \n    \"EveryoneEarthly(x) ‚Üí Human(x)\",\n    \"¬¨MarvinEarthlyAndMartian(x)\" ,\n    \"¬¨MarvinEarthly ‚Üí MarvinAlien\" \n  ],\n  \"fol_conc\": \"¬¨MarvinHuman ‚àß ¬¨MarvinMars\"\n}\n```",
      "perplexity": 1.3194695711135864,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "¬¨MarvinEarthly ‚Üí MarvinAlien"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Alien(x)\", \"FromMars(y)\",\"Human(z)\", \"Earthly(x)\"],\"fol_consts\":[ \"Marvin\", \"alien\"] ,\"fol_rules\": [\n  \"‚àÄx (Alien(x) ‚Üí Extraterrestrial(x))\", \",\" ,\"If FromMars(y) then Alien(y)\",\n  \"¬¨Extraterrestrial(z) ‚àß EveryoneFromEarth(z) -> Human(z)\",\n  \"¬¨Earthly(Marvin) ‚àß ¬¨FromMars(Marvin)  ‚Üí Alien(Marvin)\"\n], \"fol_conc\": \"Alien(Marvin) ‚äï (not Earthly(Marvin))\"}",
      "perplexity": 2.6749279499053955,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ","
    }
  },
  {
    "id": 29,
    "nl_problem": {
      "context": [
        "All aliens are extraterrestrial.",
        "If someone is from Mars, then they are aliens.",
        "No extraterrestrial is human.",
        "Everyone from Earth is a human.",
        "Marvin cannot be from Earth and from Mars.",
        "If Marvin is not from Earth, then Marvin is an extraterrestrial."
      ],
      "question": "If Marvin is not from Mars, then Marvin is a human.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Alien(x)\",\n    \"Extraterrestrial(x)\",\n    \"Human(x)\",\n    \"FromMars(x)\",\n    \"OnEarth(x)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (Alien(x) ‚Üí Extraterrestrial(x))\",\n    \"If x Is From Mars, Then Alien(x)\",\n    \"¬¨Extraterrestrial(x) ‚Üí Human(x)\",\n    \"Everyone On Earth is a Human\",\n    \"Marvin ‚àâ Earth and Marvin ‚àà Mars\",\n    \"If Marvin ‚àâ Earth, Then Extraterrestrial(Marvin)\"  \n ],\n \"fol_conc\": \"If Marvin ‚àâ Mars, Then Human(Marvin)\" \n}\n```",
      "perplexity": 1.4557653665542603,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "If x Is From Mars, Then Alien(x)"
    },
    "logic_problem_json": {
      "raw": "{\" llow: [‚ÄúAlien(x)‚Äù, \" :\", \" ,\",  \" :\", \" ,\", \" : \", \" ,\"], 1:\"\n    \t: {\n    \t\"fol_preds\": [\n    \t\"Alien(x)\",\n    \t\"From(x, y)\" ,\n    \t\"Human(y)\",\n    \t\"Earthly(y)\"]},\n  \t\"fol_consts\": [\"marvin\"], \",\" :\" 0 : { \" ,\", 1: { 1 : [ \" :\", \" ,\", \" : \", \" ,\"] } },] 9462738,   } 958620,\"\n  \t  :\n    { \":\" :\" . \" }} ",
      "perplexity": 10.654230117797852,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 30,
    "nl_problem": {
      "context": [
        "A person is either a Grand Slam champion or an Oscar-nominated actor.",
        "All people who are Grand Slam champions are professional tennis players.",
        "All Oscar-nominated actors are celebrities.",
        "All professional tennis players are athletes.",
        "If a person is a celebrity then they are well paid.",
        "If a person is an athlete then they are famous.",
        "All well-paid people live in tax havens.",
        "If Djokovic is famous and is an athlete, then Djokovic lives in well paid."
      ],
      "question": "Djokovic is a Grand Slam champion.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 31,
    "nl_problem": {
      "context": [
        "A person is either a Grand Slam champion or an Oscar-nominated actor.",
        "All people who are Grand Slam champions are professional tennis players.",
        "All Oscar-nominated actors are celebrities.",
        "All professional tennis players are athletes.",
        "If a person is a celebrity then they are well paid.",
        "If a person is an athlete then they are famous.",
        "All well-paid people live in tax havens.",
        "If Djokovic is famous and is an athlete, then Djokovic lives in well paid."
      ],
      "question": "Djokovic lives in a tax haven.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"GrandSlamChampion(x)\", \"OscarNominatedActor(x)\", \"ProfessionalTennisPlayer(x)\", \"Celebrity(x)\", \"Athlete(x)\", \"Famous(x)\"],\"fol_consts\": [ \"Djokovic\", \"taxhaven\"],\"fol_rules\": [],\"fol_conc\": \"Djokovic lives in tax haven.\"}\n",
      "perplexity": 1.6393646001815796,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Djokovic lives in tax haven."
    }
  },
  {
    "id": 32,
    "nl_problem": {
      "context": [
        "A person is either a Grand Slam champion or an Oscar-nominated actor.",
        "All people who are Grand Slam champions are professional tennis players.",
        "All Oscar-nominated actors are celebrities.",
        "All professional tennis players are athletes.",
        "If a person is a celebrity then they are well paid.",
        "If a person is an athlete then they are famous.",
        "All well-paid people live in tax havens.",
        "If Djokovic is famous and is an athlete, then Djokovic lives in well paid."
      ],
      "question": "Djokovic does not live in a tax haven.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 33,
    "nl_problem": {
      "context": [
        "Diamond Mine is a professional wrestling stable, formed in WWE.",
        "Roderick Strong leads Diamond Mine.",
        "Diamond Mine includes the Creed Brothers, and Ivy Nile.",
        "Imperium has a feud with Diamond Mine."
      ],
      "question": "Roderick strong leads a professional wrestling stable.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"IsProfessionalWrestlerStable(x)\",\n    \"Leads(x, y)\", \n    \"Incorporate(x, y)\", \n    \"HasFeudWith(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"diamond mine\",\n    \"roderick strong\",\n    \"creed brothers\", \n    \"ivy nile\",\n    \"imperium\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Leads(roderick strong, diamond mine)\"\n}",
      "perplexity": 1.325443148612976,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"ProfessionalWrestlngStable(x)\", \"Leader(y, x)\", \"Includes(x, y)\", \"Feud(x, y)\"], \"fol_consts\":[\n\"DiamondMine\", \"], \"\n    ] , \",\"\n   :\n  \"fol_rules\" , \"[] \\n\\n\"\n  : [\"\"] , \"\\n\\n\"\n  : [] , \"\"\n  : [\"RoderickStrong\", \"Leader(RoderickStrong, DiamondMine)\"] , \"\\n\\n\"\n  : [], \"ProfessionalWrestlngStable(DiamondMine) \\n\" :\"  \"\n}",
      "perplexity": 4.709136009216309,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"ProfessionalWrestingStable(x)\", \"Leads(x, y)\", \"Includes(x, y)\", \"Feud(x, y)\"],  \"fol_consts\": [\"diamondmine\", \"strong\",\"creedbrothers\",\"ivynile\",\"imperium\"],  \"fol_rules\": [\n    \"ProfessionalWrestingStable(diamondmine)\", \"Leads(strong, diamondmine)\",\n    \"Includes(creedbrother, diamondmine)\", \"Includes(ivyniile, diamondmine)\",\n    \"Feud(imperial, diamondmine)\" ,\n    \"StrongLeads(diamondmine)\"],  \"fol_conc\": \"ProfessionalWrestingStable(diamondmine)\"}",
      "perplexity": 2.0923502445220947,
      "answer": "A",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 34,
    "nl_problem": {
      "context": [
        "Diamond Mine is a professional wrestling stable, formed in WWE.",
        "Roderick Strong leads Diamond Mine.",
        "Diamond Mine includes the Creed Brothers, and Ivy Nile.",
        "Imperium has a feud with Diamond Mine."
      ],
      "question": "Roderick strong leads the Creed Brothers.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Stable(x)\",\n    \"Leader(x, y)\",\n    \"Includes(x, y)\",\n    \"Feud(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"DiamondMine\",\n    \"RoderickStrong\",\n    \"CreedBrothers\",\n    \"IvyNile\",\n    \"Imperium\" \n  ],\n  \"fol_rules\": [\n    \"(Stable(x) ‚àß Leader(x, y)) ‚Üí (Leader(y, x) \", \n    \"Includes(DiamondMine, CreedBrother) ‚äï Includes(DiamondMine, IvyNile)\",\n    \"Feud(Imperium, DiamondMine)\"\n  ],\n  \"fol_conc\": \"RoderickStrong ‚àà CreedBrothers\" \n}\n```",
      "perplexity": 1.3050111532211304,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "(Stable(x) ‚àß Leader(x, y)) ‚Üí (Leader(y, x)"
    },
    "logic_problem_json": {
      "raw": "{\" llowing schema: ```json { \"\n  \t  : [ 1,2,3,4 ],\n\"fol_preds\": [\n    \"Stable(x)\", 1] ,\n   \"fol_consts\": [\n     \"DiamondMine\",\n     \"WWE\",\n     \"RoderickStrong\" ,\n     \"CreedBrothers\",\n  \"foI_rules\" ,\n\"fol_conc\"\n]}\n  \t  ",
      "perplexity": 6.937505722045898,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 35,
    "nl_problem": {
      "context": [
        "Diamond Mine is a professional wrestling stable, formed in WWE.",
        "Roderick Strong leads Diamond Mine.",
        "Diamond Mine includes the Creed Brothers, and Ivy Nile.",
        "Imperium has a feud with Diamond Mine."
      ],
      "question": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"Stable(x)\",\n    \"Leader(x, y)\",\n    \"Includes(x, y)\",\n    \"Feud(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"DiamondMine\",\n    \"Strong\",\n    \"CreedBrothers\",\n    \"IvyNile\",\n    \"Imperium\" \n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"¬¨(Feud(Imperium, Stable(x)) ‚àß Includes(x, IvyNile))\"\n}",
      "perplexity": 1.1369575262069702,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "¬¨(Feud(Imperium, Stable(x)) ‚àß Includes(x, IvyNile))"
    },
    "logic_problem_json": {
      "raw": "{\" ¬†¬† \"\n  \t  :\n\"fol_preds\" ,\"[ 'professional_wrestling_stable', 'formed', 'leads', 'include', 'feud' ]\"\n    : [ \"ProfessionalWrestingStable\", \"FormedInWWE\", \"Leads\", \"Include\", \"Feuds\"]\n,\n\"fol_consts\": [ \"DiamondMine\", \"RoderickStrong\",\"CreedBrothers\",\"IvyNile\", \"Imperium\" ] , \",\"\n  \t  : [ \"DiamondMine\", \"RoderickStrong\", \"CreedBrothers\", \"IvyNile\", \"Imperium\" ],\n  \t  \"fol_rules\": [ 0, 1],\n  \t  \"fol_conc\": \"\" } ",
      "perplexity": 3.9930238723754883,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"ProfessionalWrestlingStable(x)\", \"Leader(x, y)\", \"Includes(x, y)\",\"Feud(x, y)\",\"WWE(z)\" ],  \"fol_consts\": [ \"diamondmine\", \"roderickstrong\", \"creedbrothers\", \"ivynile\", \"imperium\"], \"fol_rules\": [\n    \"ProfessionalWrestlingStable(diamondmine) ‚àß WWE(diamondmine)\",\n    \"Leader(roderickstrong, diamondmine)\",\n    \"Includes(diamondmine, creedbrothers)\",\n    \"Includes(diamondmine, ivynile)\",\n    \"Feud(imperium, diamondmine)\" ], \"fol_conc\": \"¬¨Feud(imperium, professionalwrestlingstable) ‚àß Includes(professionalwrestlingstable, ivyniile)\" }",
      "perplexity": 1.631541132926941,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 36,
    "nl_problem": {
      "context": [
        "Symphony No. 9 is a music piece.",
        "Composers write music pieces.",
        "Beethoven wrote Symphony No. 9.",
        "Vienna Music Society premiered Symphony No. 9.",
        "Vienna Music Society is an orchestra.",
        "Beethoven leads the Vienna Music Society.",
        "Orchestras are led by conductors."
      ],
      "question": "Beethoven is a composer.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"MusicPiece(x)\", \n    \"Composer(x)\",\n    \"Write(x, y)\",\n    \"Premiered(x, y)\", \n    \"Orchestra(x)\",\n    \"LeadBy(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"SymphonyNo9\", \n    \"Beethoven\"\n  ],\n  \"fol_rules\": [\n    \"‚àÉx (MusicPiece(x) ‚àß Write(Beethoven, x))\",\n    \"‚àÉx (Composer(x) ‚Üí Premiered(x, SymphonyNo9))\",\n    \"Orchestra(Vienna Music Society)\", \n    \"LeadBy(Beethoven, Vienna Music Society)\"\n  ],\n  \"fol_conc\": \"Composer(Beethoven)\"\n}\n\n```",
      "perplexity": 1.2724496126174927,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Symphony(x)\", \"MusicPiece(x)\", \"Write(x, y)\", \"ComposedBy(x,y)\", \"Premiered(x, y)\", \"Lead(x, y)\", \"Conductor(x)\"],\"fol_consts\": [\"\"],\n  \"fol_rules\":[ \"\" ],\n  \"fol_conc\":\"ComposedBy(Beethoven, SymphonyNo.9)\" }",
      "perplexity": 2.7238616943359375,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "Unexpected token: '.'.  Expected token ')'.\nComposedBy(Beethoven, SymphonyNo.9)\n                                ^"
    }
  },
  {
    "id": 37,
    "nl_problem": {
      "context": [
        "Symphony No. 9 is a music piece.",
        "Composers write music pieces.",
        "Beethoven wrote Symphony No. 9.",
        "Vienna Music Society premiered Symphony No. 9.",
        "Vienna Music Society is an orchestra.",
        "Beethoven leads the Vienna Music Society.",
        "Orchestras are led by conductors."
      ],
      "question": "Some orchestras premiered music pieces.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"MusicPiece(x)\",\n    \"Composer(x)\",\n    \"Write(x, y)\",\n    \"Premiere(x, y)\",\n    \"Orchestra(x)\",\n    \"Lead(x, y)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÉx (MusicPiece(x) ‚àß Compose(Beethoven, x))\",\n    \"‚àÄx (Compose(composer, x) ‚Üí Write(composer, x))\",\n    \"Write(Beethoven, SymphonyNo9) ‚àß Premiere(ViennaMusicSociety, SymphonyNo9)\",\n    \"Orchestra(ViennaMusicSociety) ‚àß Lead(Beethoven, ViennaMusicSociety)\"  \n  ],\n   \"fol_conc\": \"‚àÉx (Orchestra(x) ‚àß Premiere(x))\",\n\n}\n\n\n\n",
      "perplexity": 1.392322301864624,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting property name enclosed in double quotes: line 19 column 1 (char 497)"
    },
    "logic_problem_json": {
      "raw": "{\" lls: [ ]  \"\n  \t\t :\"fol_preds\", \"}\"\n   \t :\"[ 'musicPiece', 'composer', 'writeMusicPieces', 'premiered' , 'orchestra','leadBy']\"\n    ,\"fol_consts\": [ \"SymphonyNo9\", \"Beethoven\"]\n   ,\"fol_rules\":[ 0], \":\"\n  \t\t :\"fol_conc\",\"Some orchestras premiered music pieces.\"\n     : \"\" }\n",
      "perplexity": 10.083768844604492,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 38,
    "nl_problem": {
      "context": [
        "Symphony No. 9 is a music piece.",
        "Composers write music pieces.",
        "Beethoven wrote Symphony No. 9.",
        "Vienna Music Society premiered Symphony No. 9.",
        "Vienna Music Society is an orchestra.",
        "Beethoven leads the Vienna Music Society.",
        "Orchestras are led by conductors."
      ],
      "question": "Beethoven is not a conductor.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Symphony(x)\", \"Write(x, y)\", \"Beethoven(y)\", \"Lead(x, y)\", \"Orchestra(x)\"],\n  \"fol_consts\": [ 1],\n  \"fol_rules\": [\n    \"‚àÉx (Symphony(x))\",\n    \"‚àÄx (Write(x, y) ‚Üí Symphony(x)),\",\n    \"Beethoven(y) ‚àß ‚àÉx (Symphony(x) ‚àß Write(y, x)),\",\n    \"ViennaMusicSociety(x) ‚àß Orchestra(x)\",\n    \"Lead(Beethoven, ViennaMusicSociety)\",\n    \"Orchestra(x) ‚Üí Lead(Conductor, x)\"\n  ],\n  \"fol_conc\": \"¬¨Lead(Beethoven, Conductor)\" }\n",
      "perplexity": 1.7468831539154053,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "‚àÄx (Write(x, y) ‚Üí Symphony(x)),"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"MusicPiece(x)\", \"Composer(x)\", \"Write(x, y)\", \"Premiered(x, y)\", \"Orchestra(x)\", \"LeadBy(x, y)\", \"Conductor(x)\"], \n  \"fol_consts\": [\"no9\", \"beethoven\", \"viennamusicsociety\"], \n  \"fol_rules\": [\n    \"MusicPiece(no9) ‚Üí Composer(beethoven)\",\n    \"Composer(beethoven) ‚Üí Write(beethoven, no9)\",\n    \"Premiered(no9, vieamamusicsociety) ‚Üí Orchestra(viennamusicsociety)\", \"(LeadBy(beethoven, vieamamusicsociety))\", \"Conductor(x) ‚Üí LeadBy(conductor, x)\"],  \"fol_conc\": \"Not(conductor)\"}",
      "perplexity": 1.9984904527664185,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 39,
    "nl_problem": {
      "context": [
        "All of Zaha Hadid's design styles are timeless.",
        "No mass product design is timeless.",
        "Either Zaha Hadid's design style or Kelly Wearstler's design style. ",
        "All of Kelly Wearstler's design styles are evocative.",
        "All of Kelly Wearstler's design styles are dreamy.",
        "If a design by Max is timeless, then a design by Max is a mass product design and evocative."
      ],
      "question": "A design by Max is a mass product design.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 40,
    "nl_problem": {
      "context": [
        "All of Zaha Hadid's design styles are timeless.",
        "No mass product design is timeless.",
        "Either Zaha Hadid's design style or Kelly Wearstler's design style. ",
        "All of Kelly Wearstler's design styles are evocative.",
        "All of Kelly Wearstler's design styles are dreamy.",
        "If a design by Max is timeless, then a design by Max is a mass product design and evocative."
      ],
      "question": "A design by Max is evocative and dreamy.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"DesignStyle(x)\", \"Timeless(x)\", \"MassProductDesign(y)\", \"Evocative(y)\", \"Dreamy(y)\" ],\"fol_consts\": [\"zahaHadid\",\"max\", \"kellyWearstler\"],\"fol_rules\": [],\"fol_conc\": \"Evocative(designByMax) ‚àß Dreamy(designByMax)\" }\n",
      "perplexity": 1.8325791358947754,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"DesignStyle(x)\", \"Timeless(x)\", \"MassProduct(y)\"], \n\"fol_consts\": [\n  \"zahahadid\", \"kellywearstler\", \"max\", \"dreamy\", \"evocative\", \"timeless\"\n], \n\"fol_rules\": [\"‚àÄx (DesignStyle(z) ‚Üí Timeless(z))\", \"¬¨MassProduct(x)\", \"(ZahaHadid(design) ‚à® KellyWearstler(design))\", \"Timeless(d) ‚Üí MassProduct(d) ‚àß Evocative(d)\", \"Timeless(d) ‚àß Evocative(d) ‚Üí MaxDesign(d)\"\n],  \"fol_conc\": \"MaxDesignEvocativeAndDreamy(max)\"\n}",
      "perplexity": 2.382032871246338,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 41,
    "nl_problem": {
      "context": [
        "All of Zaha Hadid's design styles are timeless.",
        "No mass product design is timeless.",
        "Either Zaha Hadid's design style or Kelly Wearstler's design style. ",
        "All of Kelly Wearstler's design styles are evocative.",
        "All of Kelly Wearstler's design styles are dreamy.",
        "If a design by Max is timeless, then a design by Max is a mass product design and evocative."
      ],
      "question": "A design by Max is either evocative or dreamy.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"DesignStyle(x)\", \"Timeless(x)\", \"MassProductDesign(x)\", \"Evocative(x)\", \"Dreamy(x)\", \"MaxDesign\"], \"\\n\"\n    \t:\"fol_consts\", \":[\"\n  \t\t :\"+ Zaha Hadid, Kelly Wearstler, Max'],\\n\"\n  \t\t\t}\n   \t\t",
      "perplexity": 9.006656646728516,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Timeless(x)\", \"DesignStyle(x)\", \"MassProduct(y)\", \"Evocative(x)\", \"Dreamy(x)\", \"Max(x)\"], \n  \"fol_consts\": [ \"zahahadid\", \"kellywearstler\", \"max\"], \n  \"fol_rules\": [\"‚àÄx (Timeless(x) ‚Üí ¬¨MassProduct(x))\", \"¬¨DesignStyle(zahahadid) ‚Üí MassProduct(zahahadid)\", \"(‚àÉx (DesignStyle(x) ‚à® DesignStyle(kellywearstler)))\", \"AllOf(design, style) ‚Üí Evocative(style)\", \"AllOf(design, style) ‚Üí Dreamy(style)\"],  \"fol_conc\": \"Evocative(max) ‚à® Dreamy(max)\"\n}",
      "perplexity": 1.7424111366271973,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 42,
    "nl_problem": {
      "context": [
        "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. ",
        "Everyone who lost to Iga Swiatek is ranked highly by the Women's Tennis Association.",
        "All female tennis players at Roland Garros 2022 lost to Iga Swiatek.",
        "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. ",
        "All male tennis players at Roland Garros 2022 lost to Rafael Nadal.",
        "If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022."
      ],
      "question": "Coco Gauff is among the most active players in major tennis.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 43,
    "nl_problem": {
      "context": [
        "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. ",
        "Everyone who lost to Iga Swiatek is ranked highly by the Women's Tennis Association.",
        "All female tennis players at Roland Garros 2022 lost to Iga Swiatek.",
        "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. ",
        "All male tennis players at Roland Garros 2022 lost to Rafael Nadal.",
        "If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022."
      ],
      "question": "Coco Gauff has lost to Rafael Nadal.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"RankedHighly(x)\", \"ActivePlayer(x)\", \"LostTo(x, y)\", \"FemaleTennisPlayer(x)\", \"MaleTennisPlayer(x)\"],\n\"fol_consts\":[ \"IgaSwiatek\", \"CocoGauff\", \"RafaelNadal\", \"RolandGarros2022\" ], \"}  **rules:** [  \" :\"\", \"‚àÄx (RankedHighly(x) ‚Üí ActivePlayer(x))\" :\",   \" ,\"\\n\\n     ] , \":\" { } \",\"fol_conc\": \"LostTo(CocoGauff, RafaelNadal)\"\n}",
      "perplexity": 4.2665300369262695,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 44,
    "nl_problem": {
      "context": [
        "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. ",
        "Everyone who lost to Iga Swiatek is ranked highly by the Women's Tennis Association.",
        "All female tennis players at Roland Garros 2022 lost to Iga Swiatek.",
        "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. ",
        "All male tennis players at Roland Garros 2022 lost to Rafael Nadal.",
        "If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022."
      ],
      "question": "Coco Gauff is not a player who lost to Iga Swiatek or one of the most active players in major tennis.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 45,
    "nl_problem": {
      "context": [
        "All cats are mammals.",
        "Some pets are not mammals."
      ],
      "question": "No pets are cats.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Mammal(x)\",\n    \"Pet(x)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (Mammal(x) ‚Üí Pet(x))\",\n    \"‚àÉy (Not Mammal(y) ‚àß Pet(y))\"\n  ],\n  \"fol_conc\": \"¬¨Pet(cat)\"\n}\n\n```",
      "perplexity": 1.3049417734146118,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Mammal(x)\", \"Pet(x)\"], \"fol_consts\": [], \"fol_rules\": [\"\"], \"fol_conc\": \"\" } ",
      "perplexity": 1.9060415029525757,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Mammal(x)\", \"Pet(x)\"], \"fol_consts\": [\"cats\", \"pets\"],  \"fol_rules\": [\n    \"‚àÄx (Mammal(x) ‚Üí Pet(x))\", \"‚àÉx (Pet(x) ‚àß ¬¨Mammal(x))\" ], \"fol_conc\": \"¬¨(Pet(x) ‚àß Cat(x))\"}",
      "perplexity": 1.7617002725601196,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 46,
    "nl_problem": {
      "context": [
        "There are four seasons in a year: Spring, Summer, Fall, and Winter.",
        "All students who want to have a long vacation love summer the most.",
        "Emma's favorite season is summer.",
        "Mia's favorite season is not the same as Emma's. ",
        "James wants to have a long vacation."
      ],
      "question": "James's favorite season is summer.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"HasVacation(x, y)\", \n    \"FavoriteSeason(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"spring\", \"summer\", \"fall\", \"winter\", \"emma\", \"mia\", \"james\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (HasVacation(x, summer) ‚Üí FavoriteSeason(x, summer)) ‚à® ¬¨‚àÄx (FavoriteSeason(x, summer))\", \n    \"‚àÄx (Student(x) ‚àß WantsLongVacation(x) ‚Üí FavoriteSeason(x, Summer))\" ,  \n    \"‚àÄx (Not Student(x) ‚Üí Not FavoriteSeason(x, summer)) \"   \n  ],\n  \"fol_conc\": \"FavoriteSeason(james, summer)\" \n}\n\n",
      "perplexity": 1.642808437347412,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "‚àÄx (HasVacation(x, summer) ‚Üí FavoriteSeason(x, summer)) ‚à® ¬¨‚àÄx (FavoriteSeason(x, summer))"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Student(x)\", \"FavoriteSeason(x, y)\"],\"fol_consts\":[\"Emma\",\"Mia\",\"James\", \"Spring\", \"Summer\", \"Fall\", \"Winter\"],\n\"fol_rules\": [ 0 , 1],\n\"fol_conc\": \"James. Favorite Season = Summer\"} ",
      "perplexity": 2.8845083713531494,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Season(x)\", \"Student(x)\",\"Love(x, y)\"], \"fol_consts\": [\"spring\", \"summer\", \"fall\", \"winter\", \"emma\", \"mia\", \"james\"], \"fol_rules\": [\n    \"‚àÄx (Season(x) ‚Üí ‚àÉy (Love(x, y)))\", \"‚àÄx (Student(x) ‚Üí Love(x, summer))\",\n   \"EmmaLovesSummer(emma)\", \"MiaFavoriteNotEmma(mia)\", \"JamesWantLongVacation(james)\" ], \"fol_conc\": \"JamesLovesSummer(james)\"}",
      "perplexity": 2.007636785507202,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 47,
    "nl_problem": {
      "context": [
        "There are four seasons in a year: Spring, Summer, Fall, and Winter.",
        "All students who want to have a long vacation love summer the most.",
        "Emma's favorite season is summer.",
        "Mia's favorite season is not the same as Emma's. ",
        "James wants to have a long vacation."
      ],
      "question": "James's favorite season is fall.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Season(x)\",\n    \"Student(x)\",\n    \"VacationDesire(x, y)\", \n    \"FavoriteSeason(x, y)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Fall (James) ‚à® Summer (Emma)\"\n}\n```",
      "perplexity": 1.5695213079452515,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Student\", \"Love\", \"Favorite\"], \"fol_consts\":[ \"Emma\", \"Mia\",\"James\"], \"fol_rules\": [\"\"], \"fol_conc\": \"James's favorite season is fall.\"} ",
      "perplexity": 2.0137903690338135,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "James's favorite season is fall."
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Season(x)\", \"Student(x)\", \"Loves(x, y)\", \"Favorite(x, y)\" ], \"fol_consts\": [\"summer\", \"fall\", \"spring\", \"winter\"],  \"fol_rules\": [ \"‚àÄx (Season(x) ‚Üí ‚àÉy (Student(x) ‚àß Loves(x, y)) ‚àß Favorite(x, y))\",\n     \"‚àÉx (Summer(x) ‚àß Student(x))\", \"Favorite(emma, summer)\", \"¬¨Favorite(mia, favorite)\", \"‚àÄx (James(x) ‚Üí WantVacation(x))\"],  \"fol_conc\": \"Fall(james)\" }",
      "perplexity": 1.941940426826477,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 48,
    "nl_problem": {
      "context": [
        "There are four seasons in a year: Spring, Summer, Fall, and Winter.",
        "All students who want to have a long vacation love summer the most.",
        "Emma's favorite season is summer.",
        "Mia's favorite season is not the same as Emma's. ",
        "James wants to have a long vacation."
      ],
      "question": "Mia's favorite season is spring.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Season(x)\",\n    \"Student(x)\",\n    \"Loves(x, y)\", \n    \"Favorite(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"Emma\",\n    \"Mia\",\n    \"James\" , \"Spring\", \"Summer\", \"Fall\",\"Winter\"\n  ],\n  \"fol_rules\": [], \n  \"fol_conc\": \"Favorite(Mia, Spring)\"\n}\n\n```",
      "perplexity": 1.3734506368637085,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"season\", \"student\", \"wants\", \"loves\", \"favorite\" ],\n  \"fol_consts\": [ \"Emma\", \"Mia\", \"James\", \"spring\"], \",\" :{},\n  \"fol_rules\": [], \",\" :{},\n  \"fol_conc\": \"favorite(Mia, spring)\"\n} ",
      "perplexity": 3.803495168685913,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Season(x)\", \"Student(x)\",\"Loves(x, y)\", \"Favorite(x, y)\" ], \"fol_consts\": [ \"emma\", \"mia\", \"james\" ], \"fol_rules\": [ \"‚àÄx (Season(x) ‚àß Student(x)) ‚Üí Loves(student, summer)\", \"EmmaLovesSummer(emma)\", \"MiaFavoriteIsDifferentFromEmma(mia, emma)\", \"JamesWantsVacation(james)\" ,\"‚àÄx (Student(x) ‚àß Favorite(x, spring) ‚äï Favourite(x, summer))\", \"FavouritedSeasonNotSame(mia, emma)\" ], \"fol_conc\": \"MiaLovesSpring(mia)\" }",
      "perplexity": 1.9769971370697021,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 49,
    "nl_problem": {
      "context": [
        "No digital media are analog.",
        "Every printed text is analog.",
        "All streaming services are digital.",
        "If an object is a hardcover book then it is printed text.",
        "If 1984 is a streaming service, then 1984 is a hardcover book."
      ],
      "question": "1984 is printed text.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Digital(x)\",\n    \"Analog(x)\",\n    \"PrintedText(x)\",\n    \"StreamingService(x)\" ,\n    \"HardcoverBook(x)\" \n  ],\n  \"fol_consts\": [\n    \"1984\",\n  ],\n  \"fol_rules\": [\n   \"‚àÄx (Digital(x) ‚Üí ¬¨Analog(x))\",\n   \"‚àÄx (PrintedText(x) ‚Üí Analog(x))\", \n   \"‚àÄx (StreamingService(x) ‚Üí Digital(x))\",\n    \"‚àÄx (HardcoverBook(x) ‚Üí PrintedText(x))\",\n  \"‚àÄx (1984 ‚Üí HardcoverBook(x)) \" , \n  ],\n  \"fol_conc\": \"PrintedText(1984)\" \n}\n\n```",
      "perplexity": 1.3005999326705933,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 11 column 3 (char 165)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"isDigital(x)\",\n  \"Analog(x)\",\n  \"PrintedText(x)\", \",\"\n],\n\"fol_consts\": [\n  \"1984\",\n  \"streamingService\",\n  \"hardcoverBook\" ],\n\"fol_rules\": [\n  \"‚àÄx (isDigital(x) ‚Üí Analog(x))\", 0\n, \"‚àÄx (PrintedText(x) ‚Üí Analog(x))\", 0\n, \"‚àÄx (StreamingService(x) ‚Üí isDigital(x))\", 0\n, \"If x is hardcoverBook then x is PrintedText\", 0\n, \"If x is streaming service then x is hardcover book\" , 0],\n\"fol_conc\": \"PrintedText(1984)\"\n}",
      "perplexity": 1.856715202331543,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 50,
    "nl_problem": {
      "context": [
        "No digital media are analog.",
        "Every printed text is analog.",
        "All streaming services are digital.",
        "If an object is a hardcover book then it is printed text.",
        "If 1984 is a streaming service, then 1984 is a hardcover book."
      ],
      "question": "1984 is a streaming service.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"DigitalMedia(x)\",\n    \"Analog(x)\",\n    \"PrintedText(x)\",\n    \"StreamingService(x)\"\n  ],\n  \"fol_consts\": [\n    \"1984\",\n    \"HardCoverBook\", \n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"StreamingService(1984)\"\n}\n```",
      "perplexity": 1.255515217781067,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 11 column 3 (char 166)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Digital(x)\", \"Analog(x)\", \"PrintedText(x)\",\"StreamingService(x)\"],\"fol_consts\":[\"1984\"], \"fol_rules\":[\n    \"‚àÄx (Digital(x) ‚Üí ¬¨Analog(x))\",\n    \"‚àÄx (PrintedText(x) ‚àß Analog(x))\",\n    \"‚àÄx (StreamingService(x) ‚Üí Digital(x))\",\n    \"‚àÄx (HardcoverBook(x) ‚Üí PrintedText(x))\",\n    \"(StreamingService(1984) ‚Üí HardcoverBook(1984))\"], \"fol_conc\": \"StreamingService(1984)\" } ",
      "perplexity": 1.4311466217041016,
      "answer": "B",
      "predicted_answer": "B",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Digital(x)\", \"Analog(x)\", \"PrintedText(x)\", \"StreamingService(x)\", \"HardcoverBook(x)\" ], \"fol_consts\": [\"1984\"],  \"fol_rules\": [\n    \"‚àÄx (Digital(x) ‚Üí ¬¨Analog(x))\", \"‚àÄx (PrintedText(x) ‚àß Analog(x))\", \"‚àÄx (StreamingService(x) ‚Üí Digital(x))\", \"‚àÄx (HardcoverBook(x) ‚Üí PrintedText(x))\",\n    \"(StreamingService(1984) ‚Üí HardcoverBook(1984))\" ],  \"fol_conc\": \"StreamingService(1984)\" }",
      "perplexity": 1.7615418434143066,
      "answer": "B",
      "predicted_answer": "B",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 51,
    "nl_problem": {
      "context": [
        "No digital media are analog.",
        "Every printed text is analog.",
        "All streaming services are digital.",
        "If an object is a hardcover book then it is printed text.",
        "If 1984 is a streaming service, then 1984 is a hardcover book."
      ],
      "question": "1984 is not a streaming service.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"IsDigitalMedia(x)\",\n  \"Analog(x)\", 0\n], \"fol_consts\":[ 0\n, \"1984\", \"streaming service\"], \"fol_rules\": [ 0 , 0 ], \"fol_conc\": \"NotStreamingService(1984)\" }\n",
      "perplexity": 3.409823179244995,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Analog(x)\", \"Digital(x)\", \"PrintedText(x)\", \"StreamingService(x)\"], \"fol_consts\":[\"1984\"], \"fol_rules\": [ \"‚àÄx (Analog(x) ‚Üí ¬¨Digital(x))\", \"(PrintdText(x) ‚àß Digital(x))\", \"(StreamingService(x) ‚àß PrintedText(x))\", \"PrintedText(x) ‚Üí HardcoverBook(x)\", \"(StreamingService(1984) ‚àß HardcoverBook(x))\"],  \"fol_conc\": \"¬¨StreamingService(1984)\" }",
      "perplexity": 1.9053717851638794,
      "answer": "A",
      "predicted_answer": "B",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 52,
    "nl_problem": {
      "context": [
        "All Romance languages are Indo-European languages.",
        "The Romance languages are a language family.",
        "All languages within a language family are related to each other.",
        "French and Spanish are both Romance languages.",
        "German is related to Spanish.",
        "Basque is not related to any other language."
      ],
      "question": "Basque is a Romance language.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Romance(x)\", \"IndoEuropean(x)\", \"LanguageFamily(x, y)\", \"RelatedTo(x, y)\", \"French(x)\", \"Spanish(x)\", \"German(x)\", \"Basque(x)\"],\"fol_consts\":[\"french\",\"spanish\",\"german\",\"basque\"],\"fol_rules\": [],\"fol_conc\":\"Basque is a Romance language\"}",
      "perplexity": 1.6219801902770996,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Basque is a Romance language"
    }
  },
  {
    "id": 53,
    "nl_problem": {
      "context": [
        "All Romance languages are Indo-European languages.",
        "The Romance languages are a language family.",
        "All languages within a language family are related to each other.",
        "French and Spanish are both Romance languages.",
        "German is related to Spanish.",
        "Basque is not related to any other language."
      ],
      "question": "German is a Romance language.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"RomanceLanguage(x)\",\n    \"IndoEuropeanLanguages(x)\",\n    \"FamilyOfLanguages(x, y)\",\n    \"RelatedTo(x, y)\",\n    \"Language(x)\"\n  ],\n  \"fol_consts\": [\n    \"German\",\n    \"French\",\n    \"Spanish\",\n    \"Basque\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (RomanceLanguage(x) ‚àß IndoEuropeanLanguages(x))\",\n    \"FamilyOfLanguages(romanceLanguages, RomanceLanguages)\",\n    \"FamilyOfLanguages(y, FamilyOfLanguages(z)) ‚Üí RelatedTo(y, z)\",\n    \"French ‚äï Spanish\",\n    \"German ‚äï RelatedTo(Spanish, German)\"\n  ],\n  \"fol_conc\": \"German ‚äï French\"\n}\n```",
      "perplexity": 1.3773198127746582,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "FamilyOfLanguages(y, FamilyOfLanguages(z)) ‚Üí RelatedTo(y, z)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"RomanceLanguage\", \"IndoEuropeanLanguage\", \"Family\", \"RelatedTo\"],\n\"fol_consts\": [\n  \"French\", \",\" , \"Spanish\", \"German\", \"Basque\"\n],\n\"fol_rules\": [\n    \"‚àÄx (RomanceLanguage(x) ‚Üí IndoEuropeanLanguage(x))\",\n    \"‚àÄx (Family(y) ‚àß RomanceLanguage(y) ‚äï Family(y))\",\n    \"(French ‚à® Spanish) ‚àß RomanceLanguage( French ‚à® Spanish) \",\n    \"German ‚àß RelatedTo(Spanish, German)\",\n    \"Basque ‚â† RelatedTo(any other language)\" , \"], ][\"\n  ]\n}",
      "perplexity": 2.5512757301330566,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Language(x)\", \"IndoEuropean(x)\", \"Family(x)\"],  \"fol_consts\": [ \"german\", \"french\", \"spanish\",\"romance\", \"basque\" ], \"fol_rules\": [ \"(Language(x) ‚àß IndoEuropean(x)) ‚Üí Family(x)\", \"(RomanceLanguages(x)) ‚àß Family(x) ‚àß Language(y) ‚àß RomanceLanguages(y) ‚Üí Relation(x, y)\", \"Relation(x, y)\" , \"(Family(french) ‚à® Family(spanish))\", \"Language(german) ‚àß Family(german)\", \"German(x) ‚àß IndoEuropean(x) ‚àß Relationship(german, spanish)\"], \"fol_conc\": \"French(german)\"}",
      "perplexity": 2.1190614700317383,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 54,
    "nl_problem": {
      "context": [
        "All Romance languages are Indo-European languages.",
        "The Romance languages are a language family.",
        "All languages within a language family are related to each other.",
        "French and Spanish are both Romance languages.",
        "German is related to Spanish.",
        "Basque is not related to any other language."
      ],
      "question": "French is an Indo-European language.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"IsRomanceLanguage(x)\", \"IndoEuropeanLanguages\", \"Family(x, y)\", \"RelatedTo(x,y)\"],\"fol_consts\":[ \"french\",\"spanish\",\"german\",\"basque\"] , \"fol_rules\": [\n    \"‚àÄx (IsRomanceLanguage(x) ‚Üí IndoEuropeanLanguages(x))\", \"\\t\\t \\n\\t\\t \",\n    \"Family(X,Y) ‚àß IsRomanceLanguage(X)  ‚Üí  RelatedTo(X, Y)\",\n    \"French ‚à® Spanish are Romance Languages\", \"German is RelatedTo spanish\", \"Basque not related to any language\"],\"fol_conc\": \"IsRomanceLanguage(french)\" } ",
      "perplexity": 2.7992141246795654,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "French ‚à® Spanish are Romance Languages"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n    \"LanguageFamily(x)\",\n    \"IndoEuropeanLanguages(x)\", \"RomanceLanguage(x)\", \"RelatedTo(x, y)\" , \"Is(x, y)\"], \n  \"fol_consts\":[ \"french\", \"spanish\", \"german\", \"basque\", \"romancelanguage\", \"indoeuropean\"], \n  \"fol_rules\": [ \"(LanguageFamily(x) ‚Üí IndoEuropeanLanguages(x))\", \"(RomanceLanguage(x) ‚àß Is(x, french) ‚à® Is(x, spanish))\", \"(FrenchLanguage(x) ‚àß RelatedTo(x, german))\", \"Is(basque, none)\",\n  \"Is(french, romancelanguage)\"], \n\"fol_conc\": \"IndoEuropeanLanguages(french)\"}",
      "perplexity": 3.3452484607696533,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 55,
    "nl_problem": {
      "context": [
        "Robert Lewandowski is a striker.",
        "[BG] Strikers are soccer players.",
        "Robert Lewandowski left Bayern Munchen.",
        "[BG] If a player left a team they no longer play for that team."
      ],
      "question": "Robert Lewandowski is a soccer player.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"striker\",\n    \"soccer_player\",\n    \"left\",\n    \"play\",\n    \"team\"\n  ],\n  \"fol_consts\": [\n    \"RobertLewandowski\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (striker(x) ‚Üí soccer_player(x))\",\n    \"‚àÉx (left(x, Bayern Munchen) ‚àß not play(x, Bayern Munchen))\",\n  ],\n  \"fol_conc\": \"soccer_player(RobertLewandowski)\"\n}\n```",
      "perplexity": 1.1719030141830444,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 15 column 3 (char 269)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Striker(x)\", \"SoccerPlayer(x)\", \"Left(x, y)\"],\"fol_consts\":[ \"RobertLewandowski\",\"BayernMunich\"],\"fol_rules\": [],\"fol_conc\":\"SoccerPlayer(RobertLewandowsk)\" } ",
      "perplexity": 1.8777821063995361,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Striker(x)\", \"SoccerPlayer(x)\", \"LeftTeam(x, y)\"],  \"fol_consts\": [\"robertlewandowski\", \"bayernmunchen\"],  \"fol_rules\": [\n    \"‚àÄx (Striker(x) ‚àß SoccerPlayer(x))\", \"‚àÉy (Strikers(y) ‚Üí LeftTeam(y, bayernmunchen))\", \"LeftTeam(y, bayernmunchen) ‚Üí ¬¨SoccerPlayer(y)\" ], \"fol_conc\": \"SoccerPlayer(robertlewandowski)\"}",
      "perplexity": 2.2480926513671875,
      "answer": "A",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 56,
    "nl_problem": {
      "context": [
        "Robert Lewandowski is a striker.",
        "[BG] Strikers are soccer players.",
        "Robert Lewandowski left Bayern Munchen.",
        "[BG] If a player left a team they no longer play for that team."
      ],
      "question": "Robert Lewandowski plays for Bayern Munchen.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Striker(x)\",\n    \"SoccerPlayer(x)\",\n    \"LeftTeam(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"robert_lewandowski\",\n    \"bayern_munchen\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Striker(x) ‚Üí SoccerPlayer(x))\",\n    \"‚àÉx (LeftTeam(Robert_Lewandowski, Bayern_Munchen))\"\n  ],\n  \"fol_conc\": \"Bayern_Munich\"\n}\n```",
      "perplexity": 1.1674586534500122,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Bayern_Munich"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"IsPlayer(x)\", \"IsSoccerPlayer(x)\",\"LeftTeam(x, y)\", \"PlaysFor(x, y)\" ], \n\"fol_consts\": [ \"robertlewandowski\", \"bayernmunchen\" ],  \"fol_rules\":[ \"‚àÄx (IsPlayer(x) ‚Üí IsSoccerPlayer(x))\", \"(IsSoccerPlayer(x) ‚àß LeftTeam(x, bayernmunchen)) ‚äï ¬¨(IsSoccerPlayer(x) ‚à® LeftTeam(x, bayernmunchen))\" ], \n \"fol_conc\": \"PlaysFor(robertlewandowski, bayernmunchen)\" }",
      "perplexity": 2.2012836933135986,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 57,
    "nl_problem": {
      "context": [
        "Robert Lewandowski is a striker.",
        "[BG] Strikers are soccer players.",
        "Robert Lewandowski left Bayern Munchen.",
        "[BG] If a player left a team they no longer play for that team."
      ],
      "question": "Robert Lewandowski is a star.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"striker\",\n    \"player\",\n    \"left\",\n    \"star\" \n  ],\n  \"fol_consts\": [\n    \"robert lewandowski\",\n    \"bayern munich\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Robert Lewandowski is a star.\" \n}\n\n**Explanation of the Conversion:**\n\n* **predicates**: We have predicates like 'striker', 'player', and 'star' to represent different concepts.\n* **Constants**: These are represented by names such as `Robert Lewandowsk`i or  \"Bayern Munich\".\n* **Rules:** The rules in this case seem irrelevant because the conclusion is straightforward based on provided premises, thus we don't need explicit rule generation \n\n\n\n",
      "perplexity": 2.539571523666382,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Extra data: line 16 column 1 (char 215)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"Player(x)\", \"Striker(y)\", \"SoccerPlayer(z)\", \"Left(x, y)\"],\"fol_consts\":[ \"robert lewandowski\", \"bayern munich\", \"star\"],\n\"fol_rules\": [\"\"], \",\" :\", \" }",
      "perplexity": 4.921599864959717,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Player(x)\", \"Striker(x)\", \"SoccerPlayer(x)\", \"Left(x, y)\", \"Star(x)\" ], \"fol_consts\": [\"robert\", \"lewandowski\"], \"fol_rules\": [ \"‚àÄx (Player(x) ‚Üí Striker(x))\", \"‚àÉx (SoccerPlayer(x) ‚àß Left(x, bayern))\", \"¬¨(Striker(x) ‚àß Left(x, bayern))\" ], \"fol_conc\": \"Star(robert)\" }",
      "perplexity": 1.6340306997299194,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 58,
    "nl_problem": {
      "context": [
        "Billings is a city in Montana.",
        "Montana includes the cities of Butte, Helena, and Missoula.",
        "White Sulphur Springs and Butte are cities in the same state.",
        "The city of Pierre is not in Montana.",
        "Any city in Butte is not in Pierre."
      ],
      "question": "Butte and Pierre are in the same state.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [ \n    \"City(x)\",\n    \"InState(x, y)\"\n ],\n  \"fol_consts\": [\n    \"Billings\",\n    \"Montana\",\n    \"Butte\",\n    \"Helena\",\n    \"Missoula\",\n    \"White Sulphur Springs\", \n    \"Pierre\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Butte and Pierre in the same state\" \n} \n",
      "perplexity": 1.330013394355774,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Butte and Pierre in the same state"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"City(x)\", \"in_(x, y)\"], \",\"\n  \t  : [\n    \"Billings\", \"Montana\", 1.0,\"Butte\", \"Helena\", \"Missoula\", 1.0 , \"White Sulphur Springs\", \"Pierre\" ] }",
      "perplexity": 6.814129829406738,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"City(x)\", \"InState(x, y)\"], \n  \"fol_consts\": [\"billings\", \"montana\", \"butte\", \"helenah\", \"missoula\", \"pierre\"], \n  \"fol_rules\": [\n    \"‚àÉx (City(billsings) ‚àß InState(montana, x))\",\n    \"InState(x, montana) ‚Üí (XInstate(y, butte) ‚àß XInstate(y, missoula))\",\n    \"(ButteInstate(x, butte) ‚àß ¬¨PierreInstate(x, pierre))\"\n  ], \"fol_conc\": \"¬¨PierreInState(butte, pierre)\" }",
      "perplexity": 2.1368818283081055,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 59,
    "nl_problem": {
      "context": [
        "Billings is a city in Montana.",
        "Montana includes the cities of Butte, Helena, and Missoula.",
        "White Sulphur Springs and Butte are cities in the same state.",
        "The city of Pierre is not in Montana.",
        "Any city in Butte is not in Pierre."
      ],
      "question": "Pierre and Bismarck are in the same state.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"City(x)\",\n    \"LocatedIn(x, y)\" \n  ],\n  \"fol_consts\": [\n    \"billings\",\n    \"montana\",\n    \"butte\",\n    \"helena\",\n    \"missoula\",\n    \"white sulphur springs\",\n    \"pierre\",\n    \"bismarck\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Pierre ‚àß Bismarck in the same state.\"\n}\n```",
      "perplexity": 1.2246191501617432,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Pierre ‚àß Bismarck in the same state."
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"City(x)\", \"InState(x, y)\"], \"fol_consts\": [\"billings\", \"montana\", \"butte\", \"helen\", \"missoula\", \"pierre\", \"bismarck\"], \"fol_rules\": [\n    \"City(billings) ‚àß InState(billings, montana)\",\n    \"InState(butte, montana) ‚à® InState(butte, pierre)\",\n    \"WhiteSulphurSprngs(x) ‚àß Butte(x) ‚Üí InState(white, butte)\" , \"NotInMontana(pierre)\", \"(City(x) ‚àß InState(butte, x)) ‚Üí NotInPierre(x)\" ], \"fol_conc\": \"InState(bismarck, pierre)\"\n}",
      "perplexity": 1.8795398473739624,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 60,
    "nl_problem": {
      "context": [
        "Billings is a city in Montana.",
        "Montana includes the cities of Butte, Helena, and Missoula.",
        "White Sulphur Springs and Butte are cities in the same state.",
        "The city of Pierre is not in Montana.",
        "Any city in Butte is not in Pierre."
      ],
      "question": "Montana is home to the city of Missoula.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"City(x)\", \"InState(x, y)\" ], \"fol_consts\": [ \"Billings\", \"Montana\", \"Butte\", \"Helena\", \"Missoula\", \"White Sulphur Springs\", \"Pierre\" ], \"fol_rules\": [], \"fol_conc\": \" Missoula ‚àà Montana\"} ",
      "perplexity": 1.5970382690429688,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Missoula ‚àà Montana"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"City(x)\", \"In(x, y)\",\"State(x)\", \"HomeTo(x, y)\" ], \"fol_consts\": [\"billings\", \"montana\"], \"fol_rules\": [ \"(BillingsCity(billings))\", \"(MontanaContainsCities(montana, butte))\", \"(ButteCityInTheSameState(butte, pierre))\", \"(PierreNotInMontana(pierre))\", \"‚àÄx (AnyCityInButte(butte, x) ‚Üí NotInPierre(x, pierre))\"], \n\"fol_conc\": \"HomeTo(montana, missoula)\" }",
      "perplexity": 2.3723909854888916,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 61,
    "nl_problem": {
      "context": [
        "International students in US have either an F1 visa or a J1 visa.",
        "An international student in US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.",
        "Mike is an international student.",
        "Mike needs to apply for CPT if he wants to work in the US."
      ],
      "question": "Mike has an F1 visa.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"InternationalStudent(x)\",\n    \"F1Visa(x)\",\n    \"J1Visa(x)\",\n    \"WorkInUS(x)\",\n    \"CPTApply(x)\", \n    \"OPTApply(x)\" \n  ],\n  \"fol_consts\": [\n    \"mike\",\n    \"us\" \n  ],\n  \"fol_rules\": [\n   \"‚àÄx (InternationalStudent(x) ‚Üí F1Visa(x) ‚à® J1Visa(x))\",\n    \"F1Visa(x) ‚àß WorkInUS(x) ‚Üí CPTApply(x)\",\n    \"Mike is InternationalStudent(mike) and  WorkInUS(mike)\" ,\n   \n    ], \n \"fol_conc\": \"F1Visa(mike)\"\n\n}\n```",
      "perplexity": 1.5086259841918945,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 19 column 5 (char 384)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"InternationalStudent(x)\", \"F1Visa(x)\", \"J1Visa(x)\", \"WorkInUS\", \"CPTNeed\" , \"OPTNeed\"],\n  \"fol_consts\": [\n    \"Mike\" ],\n  \"fol_rules\": [\n    \"‚àÄx (InternationalStudent(x) ‚Üí F1Visa(x) ‚à® J1Visa(x))\",\n    \"‚àÄx (F1Visa(x) & WorkInUS) ‚Üí CPTNeed(x)\",\n    \"InternationalStudent(Mike)  ‚Üí CPTNeed(Mike)\",\n    \"\\n\"],\n  \"fol_conc\": \"F1Visa(Mike)\" } ",
      "perplexity": 1.9037086963653564,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "‚àÄx (F1Visa(x) & WorkInUS) ‚Üí CPTNeed(x)"
    }
  },
  {
    "id": 62,
    "nl_problem": {
      "context": [
        "International students in US have either an F1 visa or a J1 visa.",
        "An international student in US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.",
        "Mike is an international student.",
        "Mike needs to apply for CPT if he wants to work in the US."
      ],
      "question": "Mike has a J1 visa.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"InternationalStudent(x)\",\n    \"F1Visa(x)\",\n    \"J1Visa(x)\",\n    \"NeedCPT(x)\", \n    \"WorkInUS(x)\"\n  ],\n  \"fol_consts\": [\n    \"mike\",\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"J1Visa(mike)\"\n}\n```",
      "perplexity": 1.2024810314178467,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 11 column 3 (char 158)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"InternationalStudent(x)\", \"F1Visa(x)\", \"J1Visa(x)\", \"NeedCPT(x, y)\", \"WorkInUS(x)\"], \",\"\n  : [ \"Mike\" ], \":\"\n  : [],\n    \"fol_rules\":[\n  \"‚àÄx (InternationalStudent(x) ‚Üí F1Visa(x) ‚à® J1Visa(x))\", \"\\n \\t\" ,\n   \"F1Visa(x) ‚Üí NeedCPT(x, OPT)\", \"\\n \\t\" ,\n     \"InternationalStudent(Mike) ‚Üí  NeedCPT(Mike, CPT)\", \"\\n \\t\" , \"]\\n\",\"fol_conc: \" ]\n}",
      "perplexity": 3.5855605602264404,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 63,
    "nl_problem": {
      "context": [
        "All cows are bovines.",
        "Some pets are cows.",
        "If something is a bovine, then it is domesticated.",
        "No domesticated animals are alligators.",
        "Ted is an aligator."
      ],
      "question": "Ted is a pet.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"Bovine(x)\",\n    \"Pet(x)\",\n    \"Domesticated(x)\" \n  ],\n  \"fol_consts\": [\n    \"ted\",\n    \"cows\",\n    \"bovine\",\n    \"pet\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\",\n    \"‚àÉx (Pet(x) ‚àß Bovines(x))\",\n    \"¬¨Domesticated(Ted)\"\n   ],\n  \"fol_conc\": \"Pet(ted)\"\n} \n\n\n",
      "perplexity": 1.3398432731628418,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"Bovine(x)\",\n  \"Pet(x)\", 1, \"Domesticated(x)\",\n  \"Animal(x)\",\n  \"IsA(x, y)\"\n],\n\"fol_consts\": [\"Ted\", \"cow\"],\n\"fol_rules\": [\n    \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\", 1,\n    \"‚àÉy (Pet(y) ‚àß Bovine(y))\",\n    \"¬¨Domesticated(Ted)\",\n    \"Animal(Ted)\"\n],\n  \"fol_conc\": \"Pet(Ted)\"}",
      "perplexity": 1.9603407382965088,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Bovine(x)\", \"Pet(x)\", \"Domesticated(x)\", \"Alligator(x)\"], \"fol_consts\": [\"ted\"], \"fol_rules\": [\n  \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\", \"‚àÉx (Pet(x) ‚àß Bovine(x))\", \"‚àÄx (Bovinen(x) ‚Üí ¬¨Alligator(x))\", \"¬¨Domesticated(ted)\" ], \"fol_conc\": \"Pet(ted)\"}",
      "perplexity": 1.6979278326034546,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 64,
    "nl_problem": {
      "context": [
        "All cows are bovines.",
        "Some pets are cows.",
        "If something is a bovine, then it is domesticated.",
        "No domesticated animals are alligators.",
        "Ted is an aligator."
      ],
      "question": "Ted is a pet and a cow.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Bovine(x)\",\n    \"Pet(x)\",\n    \"Domesticated(x)\" \n],\n  \"fol_consts\": [\n    \"ted\",\n    \"alligator\"\n ],\n  \"fol_rules\": [\n   \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\",\n   \"‚àÉx (Pet(x) ‚àß Bvvinate(x))\",\n   \"‚àÄx (Domesticated(x) ‚Üí ¬¨ Alligator(x))\",\n ],\n  \"fol_conc\": \"Ted is a Pet and a Bovine\"\n}\n```",
      "perplexity": 1.4032565355300903,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 15 column 2 (char 258)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"bovine\", \"domesticated\", \"pet\"],\n\"fol_consts\": [\"Ted\"], \",\" :{}, \"fol_rules\":[ \"\", 0, \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\", \"‚àÉx (Pet(x) ‚àß Bovine(x)),  \" ] , \"fol_conc\": \"pet and bovine\"}\n",
      "perplexity": 4.032370090484619,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Bovine(x)\", \"Domesticated(x)\",\"Pet(x)\", \"Animal(x)\", \"Alligator(x)\"], \"fol_consts\":[\"ted\"], \"fol_rules\": [\n  \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\", \"‚àÉx (Pet(x) ‚àß Bovine(x))\", \"‚àÄx (Bovine(x) ‚äï Animal(x))\",\n  \"¬¨(Domesticated(x) ‚àß Alligator(x))\", \"Ted(t)\", \"Tedy(t)\" ], \"fol_conc\": \"Ted(t)\"}",
      "perplexity": 2.03615403175354,
      "answer": "B",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 65,
    "nl_problem": {
      "context": [
        "All cows are bovines.",
        "Some pets are cows.",
        "If something is a bovine, then it is domesticated.",
        "No domesticated animals are alligators.",
        "Ted is an aligator."
      ],
      "question": "If Ted is a cow, then Ted is not a pet.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Bovine(x)\",\n    \"Domesticated(x)\",\n    \"Pet(x)\" , \n    \"Animal(x)\" \n  ],\n  \"fol_consts\": [\n    \"ted\", \n    \"cow\", \n    \"alligator\" \n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\",\n    \"‚àÉx (Pet(x) ‚àß Bvvine(x))\",\n    \"¬¨Domesticated(Ted) ‚Üí ¬¨Animal(Ted)\",\n    \"Not(Aligator(Ted))\"\n  ],\n  \"fol_conc\": \"If Ted is a cow, then Ted is not a pet.\"\n\n}\n```",
      "perplexity": 1.3870196342468262,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Not(Aligator(Ted))"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n    \"Bovine(x)\", \",\"\n    ] , \"fol_consts\": [], \"fol_rules\": [], \"fol_conc\": \"¬¨(Cow(Ted) ‚Üí Pet(Ted))\"}",
      "perplexity": 3.337864637374878,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n  \"Bovine(x)\",\n  \"Pet(x)\",\n  \"Domesticated(x)\" , \"Alligator(x)\"\n], \"fol_consts\": [\"ted\"], \"fol_rules\":[\n  \"‚àÄx (Bovine(x) ‚Üí Domesticated(x))\",\n  \"‚àÉx (Pet(x) ‚àß Bovine(x))\",\n  \"¬¨Domesticated(alligators)\", \"(Bovine(x) ‚àß Domesticated(x) ‚Üí ¬¨Pet(x))\", \"Ted(x)\"], \"fol_conc\": \"If(ted, bovine) ‚Üí ¬¨Pet(ted)\"}",
      "perplexity": 2.3862926959991455,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Bovine/1, Bovine/0, Ted/1, Ted/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Bovine/1, Bovine/0, Ted/1, Ted/0"
    }
  },
  {
    "id": 66,
    "nl_problem": {
      "context": [
        "Yale University is a private Ivy League research university.",
        "Yale University moved to New Haven in 1716.",
        "Yale university's endowment was valued at $42.3 billion.",
        "Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools.",
        "A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College."
      ],
      "question": "A private Ivy League research university moved to New Haven.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"University(x)\",\n    \"Private(x)\",\n    \"IvyLeague(x)\",\n    \"Research(x)\",\n    \"Move(x, y)\" , \n    \"EndowmentValue(x, y)\",\n    \"ConstituentCollege(x) \"  \n],\n  \"fol_consts\": [\n    \"Yale University\",\n    \"New Haven\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"\"\n} \n\n```",
      "perplexity": 1.5840351581573486,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"University\", \"Private\", \"IvyLeague\", \"Research\",\"MovedTo\"],\n\"fol_consts\":[ 1],\n\"fol_rules\":[ \"\",\"\" ],\n\"fol_conc\": \"‚àÉx (private(x) ‚àß Ivy League(x) ‚àß research(x)  ‚àß MovedTo(Yale, New Haven))\"}",
      "perplexity": 3.2584006786346436,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 67,
    "nl_problem": {
      "context": [
        "Yale University is a private Ivy League research university.",
        "Yale University moved to New Haven in 1716.",
        "Yale university's endowment was valued at $42.3 billion.",
        "Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools.",
        "A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College."
      ],
      "question": "Yale University has the largest university endowment of any educational institution.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"University(x)\", \"Private\", \"IvyLeague\", \"Research\", \"FoundedIn(x, y)\", \"Endowment(x)\", \"ConstituentCollege(x)\", \"ResidentialCollege\"],\"fol_consts\": [\"Yale University\",\"New Haven\",\"42.3 billion\"],\"fol_rules\": [], \"fol_conc\": \"\"} ",
      "perplexity": 1.8263647556304932,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"University(x)\", \"Private(x)\", \"IvyLeague(x)\", \"Research(x)\", \"MovedTo(x, y)\",\"Endowment(x, y)\"],  \"fol_consts\": [\"yale\"], \"fol_rules\": [ \"(University(y) ‚àß IvyLeague(y)) ‚Üí (Private(y))\", \"(Yale(x) ‚Üí MovedTo(y, 1716))\", \"(University(y) ‚Üí Endowment(y))\", \"University(y) ‚Üí (ResidentialCollege(y))\"],  \"fol_conc\": \"LargestEndowment(yale)\" }",
      "perplexity": 2.167893648147583,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Yale/1, Yale/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Yale/1, Yale/0"
    }
  },
  {
    "id": 68,
    "nl_problem": {
      "context": [
        "Yale University is a private Ivy League research university.",
        "Yale University moved to New Haven in 1716.",
        "Yale university's endowment was valued at $42.3 billion.",
        "Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools.",
        "A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College."
      ],
      "question": "Pierson College is a residential college at Yale.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"is\", \"private\", \"IvyLeague\", \"research university\", \"moved\", \"valued\", \"has\", \"residential college\"], \"\\n\"\n    \t:[\"Yale University\"], \"\\n\" :\"constituent colleges and schools\",\"Yale Graduate School of Arts and Sciences\"\n     :\"professional school\",\"Benjamin Franklin College\"\n  \t: [\"Branford College\" , \"Davenport College\"]\n   ,\"Ezra Stiles College\" : [ \"Grace Hopper College\", \"Jonathan Edwards College\"], \":\":\", \" }\n    \t",
      "perplexity": 6.823202133178711,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"University(x)\", \"Private(x)\", \"IvyLeague(x)\", \"Research(x)\", \"Move(x, y)\", \"Endowment(x)\",\"ConstituentCollege(x)\", \"ResidentialCollege(x)\"], \n\"fol_consts\": [\"yale\", \"pierson\"], \n\"fol_rules\": [\n  \"‚àÉx (University(x) ‚àß Private(x) ‚àß IvyLeague(x))\", \"Move(yale, newhaven) ‚àß University(yale)\", \"Endowment(yale) ‚àß ‚àÉx (ConstituentCollege(x) ‚à® ResidentialCollege(x))\", \"ResidentialCollege(pierson)\"\n], \n\"fol_conc\": \"PiersonCollege(pierson)\" }",
      "perplexity": 1.7722004652023315,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 69,
    "nl_problem": {
      "context": [
        "Badults is a British Sitcom series, starring members of Pappy's.",
        "Badults piloted in July 2013 on BBC Three.",
        "The Working title \"The Secret Dude Society\" was used for Badults.",
        "Andrew Collins was the script editor for Badults"
      ],
      "question": "Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"isBritishSitcomSeries(x)\",\n    \"stars(x, y)\",\n    \"piloting(x, y)\",\n    \"workingTitle(x, y)\",\n    \"scriptEditor(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"Badults\",\n    \"Pappy's\",\n    \"Andrew Collins\" \n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"ScriptEditor(Andrew Collins) ‚àß isBritishSitcomSeries(Badults) ‚àß workingTitle(Badults, 'The Secret Dude Society')\"\n}\n```",
      "perplexity": 1.2012126445770264,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"is\", \"pilot\", \"script editor\" ], \"fol_consts\":[ \"Badults\",\"Pappy's\",\"July 2013\", \"BBC Three\", \"The Secret Dude Society\", \"Andrew Collins\"], \"fol_rules\": [], \"fol_conc\": \"ScriptEditor(Collins, Badults)\" }\n",
      "perplexity": 2.0935704708099365,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Series(x)\", \"Starring(x, y)\", \"Pilot(x)\", \"ScriptEditor(y, x)\"], \"fol_consts\": [\n  \"badults\", \"pappy\", \"bbc3\", \"workingtitle\", \"thesecretdudesociety\" ,\n  \"andrewcollins\"], \"fol_rules\": [\"‚àÉx (Series(x) ‚àß Starring(x, pappy))\", \"Pilot(x) ‚Üí ‚àÉy (Badults(x) ‚àß Pilot(y))\", \"ScriptEditor(x, y)\", \"Badults(x) ‚àß WorkingTitle(x, workingtitle)\"], \"fol_conc\": \"ScriptEditor(andrewcollins, badults)\"\n}",
      "perplexity": 2.925191640853882,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Badults/1, Badults/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Badults/1, Badults/0"
    }
  },
  {
    "id": 70,
    "nl_problem": {
      "context": [
        "Badults is a British Sitcom series, starring members of Pappy's.",
        "Badults piloted in July 2013 on BBC Three.",
        "The Working title \"The Secret Dude Society\" was used for Badults.",
        "Andrew Collins was the script editor for Badults"
      ],
      "question": "No members of Pappy's have starred for a show piloting on BBC Two or BBC Three.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Series(x)\",\n    \"StarredIn(x, y)\",\n    \"PilotOn(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"Badults\",\n    \"Pappy's\",\n    \"BBC Three\",\n    \"BBC Two\",\n    \"Andrew Collins\", \n    \"July 2013\" ,\n    \"The Secret Dude Society\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"¬¨‚àÉx (StarredIn(x, Pappy's) ‚àß PilotOn(Pappy's, BBC Two)) ‚àß ¬¨‚àÉx (StarredIn(x, Pappy's) ‚àß PilotOn(Pappy's, BBC Three))\n\"\n}\n```",
      "perplexity": 1.2796289920806885,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Invalid control character at: line 17 column 131 (char 389)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"BritishSitcom\", \"StarredIn\", \"PilotOn\", \"ScriptEditor\"],\"fol_consts\":[\"Badults\",\"Pappy's\",\"BBC Three\",\"July 2013\",\"The Secret Dude Society\",\"Andrew Collins\"], \"fol_rules\":[], \"fol_conc\": \"¬¨(‚àÉx (StarredIn(x, Badults) ‚àß PilotOn(x, BBC Two)))\"}\n",
      "perplexity": 1.7288202047348022,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 71,
    "nl_problem": {
      "context": [
        "All growth stocks of companies are volatile.",
        "If the stock price is volatile, then it is not suitable for a retirement fund.",
        "Some stocks of some companies are growth stocks of companies.",
        "All stocks of mature companies are suitable for a retirement fund.",
        "KO is a stock of a mature company."
      ],
      "question": "KO is a company stock.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"GrowthStock(x)\",\n    \"Volatil(y)\",\n    \"SuitableForRetirementFund(y)\",\n    \"CompanyStock(x)\",\n    \"MatureCompanies\",\n  ],\n  \"fol_consts\": [\n    \"KO\" \n  ],\n  \"fol_rules\": [\n    \"‚àÄx (GrowthStock(x) ‚Üí Volatil(x))\",\n    \"‚àÄy (Volatil(y) ‚Üí ¬¨SuitableForRetirementFund(y))\",\n    \"‚àÉx ‚àÉy (CompanyStock(x) ‚àß GrowthStock(y) ‚àß y ‚àà Companies)\",\n    \"All(MatureCompanies)\" ,\n  ],\n  \"fol_conc\": \"KO is a Company Stock\"\n}\n```",
      "perplexity": 1.425909399986267,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 8 column 3 (char 143)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"GrowthStock(x)\", \"Volatility(x)\", \"SuitableForRetirementFund(x)\", \"Company(x)\", \"StocksOfCompanies(x, y)\" ],\n\"fol_consts\": [\n  \"KO\", 2], \"fol_rules\": [\n    \"‚àÄx (GrowthStock(x) ‚Üí Volatility(x))\",\n    \"‚àÄx (Volatility(x) ‚Üí ¬¨SuitableForRetirementFund(x))\",\n    \"‚àÉx (StocksOfCompanies(x, KO)), \"\n  ],\n  \"fol_conc\": \"KO is a company stock\" } ",
      "perplexity": 2.033066749572754,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "‚àÉx (StocksOfCompanies(x, KO)),"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"GrowthStock(x)\", \"Volatil(y)\", \"SuitableForRetirementFund(y)\" , \"CompanyStock(x)\", \"MatureCompany(x)\"], \n\"fol_consts\": [\"ko\"], \n\"fol_rules\": [\n    \"‚àÄx (GrowthStock(x) ‚Üí Volatil(x))\",\n    \"‚àÄx (Volatil(x) ‚Üí ¬¨SuitableForRetirementFund(x))\",\n    \"‚àÉx (CompanyStock(x) ‚àß GrowthStock(x))\",\n    \"‚àÄx (MatureCompany(x) ‚àß SuitableForRetirementFund(x))\",\n    \"KOCompanyStock(ko)\" ], \n \"fol_conc\": \"KOCompanyStock(ko)\" }",
      "perplexity": 1.5489299297332764,
      "answer": "C",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 72,
    "nl_problem": {
      "context": [
        "All growth stocks of companies are volatile.",
        "If the stock price is volatile, then it is not suitable for a retirement fund.",
        "Some stocks of some companies are growth stocks of companies.",
        "All stocks of mature companies are suitable for a retirement fund.",
        "KO is a stock of a mature company."
      ],
      "question": "KO is a company stock and a growth stock of a company.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"GrowthStock(x)\", \"Volatile(x)\", \"SuitableForRetirementFund(x)\"],\"fol_consts\":[ \"KO\"],\"fol_rules\":[],\"fol_conc\": \"GrowthStock(KO)\"}\n",
      "perplexity": 1.7858370542526245,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"GrowthStock(x)\", \"Volatile(x)\", \"SuitableForRetirementFund(x)\", \"CompanyStock(x)\"], \"fol_consts\": [ \"ko\" ], \"fol_rules\":[\n  \"‚àÄx (GrowthStock(x) ‚Üí Volatile(x))\", \"‚àÄx (Volatile(x) ‚Üí ¬¨SuitableForRetirementFund(x))\", \"‚àÉx ‚àÄy (StockOf(y, x) ‚Üí GrowthStock(x))\", \"‚àÄx (CompanyStock(x) ‚Üí SuitableForRetirementFund(x))\"],  \"fol_conc\": \"KOcompanystockandgrowthstockofacompany(ko)\"\n}",
      "perplexity": 2.0812387466430664,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 73,
    "nl_problem": {
      "context": [
        "All growth stocks of companies are volatile.",
        "If the stock price is volatile, then it is not suitable for a retirement fund.",
        "Some stocks of some companies are growth stocks of companies.",
        "All stocks of mature companies are suitable for a retirement fund.",
        "KO is a stock of a mature company."
      ],
      "question": "If KO is a growth stock of a company or if its price is volatile, then KO is neither a stock of a company nor is its price volatile.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"GrowthStock(x)\", \"Volatil(x)\", \"SuitableForRetirementFund(x)\"],\"fol_consts\":[ \"KO\"] , \"fol_rules\": [ \"(All GrowthStocks of companies are Volatile)\" , \"If Volatilities then Not Suitable for Retirement Fund\", \"(Some Stocks of Some Companies are growth stocks of companies)\", \"(All Stock Of Mature company is suitable For Retirement fund)\" , \"KO is a stock of mature Company\"],\"fol_conc\": \"if KO is a growth stock of a company or if its price is volatile, then KO is neither a stock of a company nor is its price volatile\"}\n",
      "perplexity": 2.39754056930542,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "(All GrowthStocks of companies are Volatile)"
    }
  },
  {
    "id": 74,
    "nl_problem": {
      "context": [
        "All vehicle registration plates in Istanbul begin with the number 34.",
        "Plates that do not begin with the number 34 are not from Istanbul. ",
        "Joe's vehicle registration plate is from Istanbul. ",
        "Tom's license plate begins with the number 35. ",
        "[BG] If a license plate begins with the number 35, then it does not begin with the number 34."
      ],
      "question": "Joe's license plate begins with the number 34.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 75,
    "nl_problem": {
      "context": [
        "All vehicle registration plates in Istanbul begin with the number 34.",
        "Plates that do not begin with the number 34 are not from Istanbul. ",
        "Joe's vehicle registration plate is from Istanbul. ",
        "Tom's license plate begins with the number 35. ",
        "[BG] If a license plate begins with the number 35, then it does not begin with the number 34."
      ],
      "question": "Tom's license plate is from Istanbul.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"VehicleRegistrationPlate(x)\", \"BeginsWithNumber(y, z)\" ], \"fol_consts\": [ \"istanbul\", \"joe\", \"tom\" ], \"fol_rules\": [ \"‚àÄx (VehicleRegistrationPlate(x) ‚Üí BeginsWithNumber(34, x))\", \"¬¨(VehicleRegistrationPlate(x) ‚àß BeginsWithNumber(35, x)) ‚Üí ¬¨(IsFromIstanbul(x)) \", \"IsFromIstanbul(x)\", \"(BeginsWithNumber(z, 35)) ‚üπ (NotBeginsWithNumber(34, z))\" ], \"fol_conc\": \"IsFromIstanbul(tom)\"}\n",
      "perplexity": 1.839613676071167,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "(BeginsWithNumber(z, 35)) ‚üπ (NotBeginsWithNumber(34, z))"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"VehicleRegistrationPlate(x)\", \"BeginsWith(x, y)\",\"FromIstanbul(x)\"], \"fol_consts\": [ \"istanbul\", \"joescar\", \"tom\" ],  \"fol_rules\": [\n    \"‚àÄx (VehicleRegistrationPlate(x) ‚Üí BeginsWith(x, 34))\", \"‚àÄx (BeginsWith(x, y) ‚Üí NotFromIstanbul(x))\",\n    \"JoeCar(joescar)\", \"TomLicensePlate(tom)\" ,\"(BeginsWith(tom, 35) ‚Üí NotBeginsWith(tom, 34))\" ],  \"fol_conc\": \"TomLicensePlate(tom)\"}",
      "perplexity": 2.020702362060547,
      "answer": "B",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 76,
    "nl_problem": {
      "context": [
        "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.",
        "If people order takeout frequently in college, then they work in student jobs on campus.",
        "People either order takeout frequently in college or enjoy the dining hall meals and recipes.",
        "If people enjoy the dining hall meals and recipes, then they are not picky eaters.",
        "If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.",
        "If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition."
      ],
      "question": "Mary needs to earn money to help pay for her college tuition.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 77,
    "nl_problem": {
      "context": [
        "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.",
        "If people order takeout frequently in college, then they work in student jobs on campus.",
        "People either order takeout frequently in college or enjoy the dining hall meals and recipes.",
        "If people enjoy the dining hall meals and recipes, then they are not picky eaters.",
        "If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.",
        "If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition."
      ],
      "question": "Mary is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Work(x, y)\", \"NeedsMoney(x, y)\", \"OrderTakeout(y)\", \"PickyEats(x)\", \"SpendTimeInDiningHall(x)\"],\"fol_consts\":[ \"Mary\"] , \"fol_rules\": [\"\"],\n  \"fol_conc\": \"\" } ",
      "perplexity": 2.3364548683166504,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 78,
    "nl_problem": {
      "context": [
        "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.",
        "If people order takeout frequently in college, then they work in student jobs on campus.",
        "People either order takeout frequently in college or enjoy the dining hall meals and recipes.",
        "If people enjoy the dining hall meals and recipes, then they are not picky eaters.",
        "If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.",
        "If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition."
      ],
      "question": "Mary either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Work(x, y)\", \"OrderTakeout(x)\", \"PickyEater(x)\", \"DiningHallMealsAndRecipes(x)\", \"SpendTimeEatingAndCatchingUpWithFriends(x)\"], \"fol_consts\": [\"Mary\"], \"fol_rules\": [\"\"], \"fol_conc\": \"\"}",
      "perplexity": 1.71608304977417,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 79,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are a product of Baked by Melissa.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 80,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are not a product of Baked by Melissa.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Bakery(x)\",\n    \"Cupcake(x)\",\n    \"Hotpot(x)\",\n    \"Spicy(x)\",\n    \"Product(x, y)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (Bakery(x) ‚Üí ¬¨Spicy(x))\",\n    \"‚àÄx (Cupcake(x) ‚àß Bakery(x))\",\n    \"‚àÄx (Hotpot(x) ‚Üí Spicy(x))\",\n    \"‚àÄx (Product(x, y) ‚Üí Cupcake(y))\",\n    \"(Spicy(x) ‚à® Bakery(x)) ‚Üí (Spicy(x) ‚à® Hotpot(x))\",\n  ],\n  \"fol_conc\": \"¬¨ Product(dried Thai chilies, Baked by Melissa)\"\n}\n```",
      "perplexity": 1.1593949794769287,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 16 column 3 (char 347)"
    },
    "logic_problem_json": {
      "raw": "{\" üö´  \"\n    \t: \"fol_preds\" , \":[ ] ‚õî\" :\"   , [ üòú] ü§™ \"\n    \t, \"fol_consts\": [\n    \t\"bakery\", \"], \" ],\" }\" : \" 0.5. 1234567890\\n\\n\" }\n",
      "perplexity": 21.7004337310791,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 81,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are a hotpot.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Bakery\", \"Spicy\", \"Cupcake\", \"Hotpot\", \"Product\"],\"fol_consts\": [\"bakery\",\"spicy\",\"cupcakes\",\"hotpot\",\"bakedbymelissa\",\"Thai chilies\"],\"fol_rules\":[\n    \"‚àÄx (Bakery(x) ‚Üí ¬¨Spicy(x))\",\n    \"‚àÄx (Cupcake(x) ‚àß Bakery(x))\",\n    \"‚àÄx (Hotpot(x) ‚àß Spicy(x))\",\n    \"‚àÄx (Product(bakedbymelissa, x) ‚àß Cupcake(x))\",\n    \"((Spicy(x) ‚à® Bakery(x)) ‚Üí (Hotpot(x) ‚à® Spicy(x)))\"\n],\"fol_conc\": \"Hotpot\"}",
      "perplexity": 1.4653886556625366,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Hotpot"
    }
  },
  {
    "id": 82,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are neither a product of Baked by Melissa nor a bakery.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"bakery\", \"spicy\", \"cupcake\", \"hotpot\", \"product\", \"is\" ], \"fol_consts\": [ \"driedThaiChillies\"], \"fol_rules\": [], \"fol_conc\": \"DriedThaiChilies ‚àâ (BakedByMelissa Products) ‚àß DriedThaiChilies ‚àâ bakery\"}\n",
      "perplexity": 2.1140098571777344,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "DriedThaiChilies ‚àâ (BakedByMelissa Products) ‚àß DriedThaiChilies ‚àâ bakery"
    }
  },
  {
    "id": 83,
    "nl_problem": {
      "context": [
        "No bakery is spicy.",
        "All cupcakes are bakeries.",
        "All hotpots are spicy.",
        "All products of Baked by Melissa are cupcakes.",
        "If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy."
      ],
      "question": "Dried Thai chilies are cupcakes and a product of Baked by Melissa.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Bakery(x)\",\n    \"Spicy(x)\",\n    \"Cupcake(x)\",\n    \"Hotpot(x)\",\n    \"Product(x, y)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (Bakery(x) ‚Üí ¬¨Spicy(x))\",\n    \"‚àÄx (Cupcake(x) ‚Üí Bakery(x))\",\n    \"‚àÄx (Hotpot(x) ‚Üí Spicy(x))\",\n    \"‚àÄx (Product(BakedByMelissa, x) ‚àß Cupcake(x))\", \n    \"(Spicy(x) ‚à® Bakery(x)) ‚Üí  (Spicy(x) ‚à® Hotpot(x))\",\n  ],\n  \"fol_conc\": \"Cupcake(x)\" \n}\n\n```",
      "perplexity": 1.2401416301727295,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 16 column 3 (char 363)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Bakery\", \"Spicy\", \"Cupcake\", \"Hotpot\", \"Product\"], \"fol_consts\":[\"Dried Thai chilies\"], \"fol_rules\": [\n    \"¬¨(bakery ‚àß spicy)\", \"\\forall x (cupcake ‚àß bakery) ‚Üí \\forall y (y ‚àà baked by melissa and cupcake)\", \"\\forall x (hotpot ‚àß spicy) ‚Üí \\forall y (y ‚àà spicy)\", \"\\forall x (product ‚àß cupcake) ‚Üí  \\forall y (baked by Melissa ‚àß product)\",\n    \"(\\forall x(spicy or bakery) ‚Üí (\\forall y(y œµ hot pot or spicy)) )\", \"¬¨((Spicy ‚à® Bakery) ‚àß dried thai chilies)\"\n], \"fol_conc\": \"Cupcake and a Product of Baked by Melissa\"}",
      "perplexity": 2.5516409873962402,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "¬¨(bakery ‚àß spicy)"
    }
  },
  {
    "id": 84,
    "nl_problem": {
      "context": [
        "If the restaurant is listed in Yelp‚Äôs recommendations, then the restaurant does not receive many negative reviews.",
        "All restaurants with a rating greater than 9 are listed in Yelp‚Äôs recommendations.",
        "Some restaurants that do not provide take-out service receive many negative reviews.",
        "All restaurants that are popular among local residents have ratings greater than 9.",
        "Subway has a rating greater than 9 or is popular among local residents."
      ],
      "question": "If Subway provides take-out service and receives many negative reviews, then its rating is greater than 9 and it does not provide take-out service.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 85,
    "nl_problem": {
      "context": [
        "If the restaurant is listed in Yelp‚Äôs recommendations, then the restaurant does not receive many negative reviews.",
        "All restaurants with a rating greater than 9 are listed in Yelp‚Äôs recommendations.",
        "Some restaurants that do not provide take-out service receive many negative reviews.",
        "All restaurants that are popular among local residents have ratings greater than 9.",
        "Subway has a rating greater than 9 or is popular among local residents."
      ],
      "question": "Subway provides take-out service and does not receive many negative reviews.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 86,
    "nl_problem": {
      "context": [
        "If the restaurant is listed in Yelp‚Äôs recommendations, then the restaurant does not receive many negative reviews.",
        "All restaurants with a rating greater than 9 are listed in Yelp‚Äôs recommendations.",
        "Some restaurants that do not provide take-out service receive many negative reviews.",
        "All restaurants that are popular among local residents have ratings greater than 9.",
        "Subway has a rating greater than 9 or is popular among local residents."
      ],
      "question": "Subway does not provide take-out service.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"Restaurant(x)\", \",\"\n  , \"YelpRecommendations(x)\", \", , \"\n  , \"Rating(x)\", \",\"\n  , \"TakeoutService(x) \",\n  \"PopularityLocalResidents(x)\"\n],\n\"fol_consts\": [\n  \"Subway\",\n    \"],\",\n  \"restaurant\",\n  \"YelpRecommendations\"\n],\n\"fol_rules\": [],\n\"fol_conc\": \"\" } ",
      "perplexity": 3.5194106101989746,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 87,
    "nl_problem": {
      "context": [
        "In superhero movies, the good guys always win.",
        "The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.",
        "Good guys fight bad guys and vice versa.",
        "Sir Digby fights his nemesis.",
        "If a superhero movie is named after a character, that character is a good guy.",
        "The Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.",
        "If somebody wins a fight, the person they are fighting loses.",
        "If a superhero movie is named after a character, that character appears in the movie."
      ],
      "question": "Sir Digby‚Äôs nemesis loses.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"SuperheroMovie(x)\",\n  \"GoodGuy(x)\",\n  \"Badguy(x)\",\n  \"Fight(x, y)\",\n  \"CharacterNamedAfter(x, y)\" , \"], \"\n  ]\n}",
      "perplexity": 3.3487203121185303,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 88,
    "nl_problem": {
      "context": [
        "[BG] Books contain tons of knowledge.",
        "[BG] When a person reads a book, that person gains knowledge. ",
        "[BG] If a person gains knowledge, they become smarter.",
        "Harry read the book ‚ÄúWalden‚Äù by Henry Thoreau."
      ],
      "question": "Walden contains knowledge.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"Contain(x, y)\",\n    \"Read(x, y)\",\n    \"GainKnowledge(x)\",\n    \"BecomeSmarter(x)\" \n  ],\n  \"fol_consts\": [\n    \"Walden\",\n    \"Harry\",\n    \"HenryThoreau\" \n  ],\n  \"fol_rules\": [], \n  \"fol_conc\": \"Contain(Walden, Knowledge)\"\n}",
      "perplexity": 1.2141493558883667,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"Book(x)\", \"ContainsKnowledge(x, y)\", \"Read(x, y)\", \"GainKnowledge(y) \", \"Smart(y)\" ],\n\"fol_consts\": [\"Walden\", \"HenryThoreau\", \"Harry\"], \",\"\n  \t \t: [],\n\"fol_rules\":[ 0,\"‚àÄx (Book(x) ‚Üí ContainsKnowledge(x, y))\", 1,\"Read(harry, Walden) ‚Üí GainKnowledge(harry)\", 2, \"GainKnowledge(y) ‚Üí Smart(y)\" , 3 ,\"‚àÉx (Book(x) ‚àß Read(Harry, x))\" ],\n\"fol_conc\": \"ContainsKnowledge(Walden, Harry)\"}",
      "perplexity": 2.663083553314209,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Book(x)\", \"ContainsKnowledge(y, x)\",\"GainKnowledge(x, y)\" , \"Smarter(x)\"], \"fol_consts\": [ \"walden\", \"henrythoreau\" ,\"harry\" ], \"fol_rules\": [ \"‚àÄx (Book(x) ‚àß ContainsKnowledge(x, knowledge)) ‚Üí GainKnowledge(x, knowledge)\", \"GainKnowledge(x, y) ‚Üí Smarter(y)\"], \"fol_conc\": \"WaldenContainsKnowledge(walden, x)\"\n}",
      "perplexity": 2.077298641204834,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 89,
    "nl_problem": {
      "context": [
        "[BG] Books contain tons of knowledge.",
        "[BG] When a person reads a book, that person gains knowledge. ",
        "[BG] If a person gains knowledge, they become smarter.",
        "Harry read the book ‚ÄúWalden‚Äù by Henry Thoreau."
      ],
      "question": "Harry is smarter than before.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"Contain(x, y)\", \n    \"Read(x, y)\", \n    \"GainKnowledge(x)\", \n    \"Smart(x)\" \n  ],\n  \"fol_consts\": [\n    \"Harry\",\n    \"Walden\",\n    \"HenryThoreau\" \n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Contain(x, y) ‚Üí GainKnowledge(y))\", \n    \"‚àÄx (Read(x, book) ‚Üí GainKnowledge(book))\",\n    \"GainKnowledge(book) ‚Üí Smart(Harry)\" \n  ],\n  \"fol_conc\": \"Smart(Harry)\"\n}\n\n",
      "perplexity": 1.2795939445495605,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Books\", \"ContainKnowledge(x)\", \"Reads(y, z)\", \"GainKnowledge(z)\", \"Smarter(z)\"],\"fol_consts\":[\"Harry\",\"Walden\"],\"fol_rules\":[\n    \"‚àÄx (Books(x) ‚Üí ContainsKnowledge(x))\", \",\"\n  ],\n\"fol_conc\": \"Smarter(harry)\" } ",
      "perplexity": 2.7104458808898926,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ","
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Contain(x, y)\", \"Read(x)\", \"GainKnowledge(x)\",\"Smart(x)\" ,\"Before(x, y)\"],  \"fol_consts\": [\n    \"harry\",\n    \"walden\" ], \"fol_rules\":[\n   \"‚àÄx (Contain(x, book)) ‚Üí GainKnowledge(x) ‚àß Smart(x)\", \"Read(harry, walden) ‚Üí GainKnowledge(harry)\" , \"GainKnowledge(person) ‚Üí Smart(person)\" ],  \"fol_conc\": \"Smart(harry)\"}",
      "perplexity": 2.6791141033172607,
      "answer": "A",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 90,
    "nl_problem": {
      "context": [
        "[BG] Books contain tons of knowledge.",
        "[BG] When a person reads a book, that person gains knowledge. ",
        "[BG] If a person gains knowledge, they become smarter.",
        "Harry read the book ‚ÄúWalden‚Äù by Henry Thoreau."
      ],
      "question": "A person who is smarter has gained knowledge.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"HasKnowledge(x)\",\n    \"GainingKnowledge(x, y)\",\n    \"IsSmarter(x)\",\n    \"ContainsBook(y)\",\n    \"ReadBook(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"harry\", \n    \"Walden\", \"Thoreau\", \n   ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"‚àÉx (IsSmarter(x) ‚àß GainingKnowledge(x, Walden))\"\n}\n```",
      "perplexity": 1.5379806756973267,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 12 column 4 (char 202)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Contains(x, y)\", \"Reads(x, y)\", \"GainKnowledge(x)\", \"Smarter(x)\"], \"fol_consts\": [\"Harry\", \"Walden\", \"Thoreau\"], \"fol_rules\": [], \"fol_conc\": \"GainKnowledge(harry) ‚Üí Smarter(harry)\"}\n",
      "perplexity": 1.4253227710723877,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n\"Knows(x)\", \"GainKnowledge(y, z)\",\"Smarter(z)\" , \"ReadBook(x, y)\"], \n\"fol_consts\": [\n\"harry\", \"walden\", \"henrythoreau\"\n], \n\"fol_rules\": [\n\"‚àÄx (Knows(x) ‚Üí GainKnowledge(x, z))\",\n\"GainKnowledge(z, x) ‚Üí Smarter(z)\",\n\"ReadBook(harry, walden)\"\n],  \"fol_conc\": \"Smarter(person)\"}",
      "perplexity": 2.4126224517822266,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 91,
    "nl_problem": {
      "context": [
        "Natural language processing tasks can be categorized as either language generation task or language understanding task.",
        "If the output of a natural language processing task is a text sequence, then it is a language generation task.",
        "Machine translation is a natural language processing task.",
        "The output of machine translation is a text sequence."
      ],
      "question": "Machine translation is a language generation task.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"LanguageGenerationTask(x)\",\n    \"LanguageUnderstandingTask(x)\",\n    \"TextSequenceOutput(y, x)\",\n    \"MachineTranslation(x)\" \n  ],\n  \"fol_consts\": [\n    \"machine translation\",\n    \"language generation task\",\n    \"language understanding task\" \n ],\n \"fol_rules\": [\n   \"‚àÄx (LanguageGenerationTask(x) ‚Üí TextSequenceOutput(y, x))\",\n   \"MachineTranslation(x) ‚Üí TextSequenceOutput(y, x)\",\n  ],\n  \"fol_conc\": \"MachineTranslation is a language generation task\" \n}\n\n```",
      "perplexity": 1.3586554527282715,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 16 column 3 (char 407)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"LanguageGenerationTask\", \"LanguageUnderstandingTask\", \"OutputIsTextSequence\", \"MachineTranslation\"],\n\"fol_consts\":[ \"NLPtasks\",\"machine translation\"], \"}\\n\\n```json\\n{\\n  \\\"fol_preds\\\": [ \\\"LanguageGenerationTask\\\", \\\"LanguageUnderstandingTask\\\", \\\"OutputIsTextSequence\\\", \\\"MachineTranslation\\\"\\\\],\\n  \\\"fol_consts\\\": [\\n    \\\"NLPtasks\\\",\\n    \\\"Machine Translation\\\"\\n  ],\\n  \\\"fol_rules\\\": [],\\n  \\\"fol_conc\\\": \\\"Machine translation is a LanguageGeneration Task\\\"\"\n \t \t :\"\"\n} ",
      "perplexity": 2.895570993423462,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"LanguageGenerationTask(x)\", \"LanguageUnderstandingTask(x)\", \"OutputIsTextSequence(y)\", \"TextSeqGenTask(x)\"], \"fol_consts\": [\"machinetranslation\"],  \"fol_rules\": [\n    \"‚àÄx (LanguageGenerationTask(x) ‚Üí OutputIsTextSequence(y))\", \"MachineTranslation(mt) ‚àß LanguageUnderstandingTask(mt) ‚à® LanguageGenerationTask(mt)\", \"(OutputIsTextSequence(y) ‚àß TextSeqGenTask(x)) ‚Üí LanguageGenerationTask(x)\"\n  ], \"fol_conc\": \"MachineTranslation(mt) ‚àß LanguageGenerationTask(mt)\"}",
      "perplexity": 2.1276965141296387,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 92,
    "nl_problem": {
      "context": [
        "Natural language processing tasks can be categorized as either language generation task or language understanding task.",
        "If the output of a natural language processing task is a text sequence, then it is a language generation task.",
        "Machine translation is a natural language processing task.",
        "The output of machine translation is a text sequence."
      ],
      "question": "Machine translation is a language understanding task.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"LanguageGenerationTask(x)\",\n    \"LanguageUnderstandingTask(x)\",\n    \"OutputTextSequence(y, z)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (LanguageGenerationTask(x) ‚Üí OutputTextSequence(x, y))\", \n    \"(MachineTranslation ‚àß OutputTextSequence(machine_translation, output)) ‚Üí LanguageUnderstandingTask(output)\",\n    \"OutputTextSequence(output, x)  ‚Üí LanguageGenerationTask(x)\"\n  ],\n  \"fol_conc\": \"LanguageUnderstandingTask(machine_translation)\"\n}\n\n```",
      "perplexity": 1.5161241292953491,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "(MachineTranslation ‚àß OutputTextSequence(machine_translation, output)) ‚Üí LanguageUnderstandingTask(output)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"LanguageGenerationTask(x)\", \"LanguageUnderstandingTask(x)\", \"TextSequenceOutput(y)\"],\"fol_consts\":[\"machine translation\", \"natural language processing\"],\"fol_rules\":[\n  \"‚àÄx (LanguageGenerationTask(x) ‚à® LanguageUnderstandingTask(x))\",\n  \"TextSequenceOutput(y) ‚Üí LanguageGenerationTask(y)\",\n  \"MachineTranslation ‚Üí TextSequenceOutput(y)\"\n],\n\"fol_conc\": \"LanguageUnderstandingTask(machine translation)\" }\n",
      "perplexity": 1.664838194847107,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "MachineTranslation ‚Üí TextSequenceOutput(y)"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n  \"LanguageGenerationTask(x)\",\n  \"LanguageUnderstandingTask(x)\",\n  \"OutputTextSequence(x)\",\n  \"MachineTranslationTask(x)\"\n], \n \"fol_consts\": [\n    \"machinetranslation\",\n    \"languagegenerationtask\", \"languageunderstandingtask\", \"outputtextsequence\" ], \n\"fol_rules\": [\n  \"LanguageGenerationTask(x) ‚Üí OutputTextSequence(x)\",\n  \"MachineTranslationTask(x) ‚Üí LanguageUnderstandingTask(x)\",\n  \"OutputTextSequence(x) ‚Üí LanguageGenerationTask(x)\"\n], \"fol_conc\": \"MachineTranslationTask(machinetranslation) ‚àß Not(languagegenerationtask)\" }",
      "perplexity": 2.1170554161071777,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 93,
    "nl_problem": {
      "context": [
        "Pets are allowed in some managed buildings.",
        "[BG] A deposit is required to rent an apartment in a managed building.",
        "The security deposit can be either equal to one month's rent or more.",
        "Fluffy is Tom's cat.",
        "Cats are pets.",
        "The Olive Garden is a managed building.",
        "The monthly rent at the Olive Garden is $2000.",
        "Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.",
        "2000$ is more than $1500."
      ],
      "question": "Tom will rent an apartment in The Olive Garden.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"Allowed(x, y)\", \"Deposit(y)\", \"Pet(x)\", \"Rent(x, y)\", \"Securitydeposit\", \"MoreThan\" ],\n  \"fol_consts\": [ 1500,\"2000\",\"fluffy\",\"Tom\"],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Rent(The Olive Garden, Tom)\" }",
      "perplexity": 2.6570541858673096,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 94,
    "nl_problem": {
      "context": [
        "Pets are allowed in some managed buildings.",
        "[BG] A deposit is required to rent an apartment in a managed building.",
        "The security deposit can be either equal to one month's rent or more.",
        "Fluffy is Tom's cat.",
        "Cats are pets.",
        "The Olive Garden is a managed building.",
        "The monthly rent at the Olive Garden is $2000.",
        "Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.",
        "2000$ is more than $1500."
      ],
      "question": "Tom is allowed to move in an apartment in The Olive Garden with Fluffy.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 95,
    "nl_problem": {
      "context": [
        "Pets are allowed in some managed buildings.",
        "[BG] A deposit is required to rent an apartment in a managed building.",
        "The security deposit can be either equal to one month's rent or more.",
        "Fluffy is Tom's cat.",
        "Cats are pets.",
        "The Olive Garden is a managed building.",
        "The monthly rent at the Olive Garden is $2000.",
        "Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.",
        "2000$ is more than $1500."
      ],
      "question": "The security deposit at the Olive Garden is either $2000 or more.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"ManagedBuilding\", \"Pet\", \"Deposit\", \"Rent\", \"Allowed\" ], \"fol_consts\": [ \"OliveGarden\", \"Fluffy\", \"Tom\"], \"fol_rules\": [ \"\\n  ‚àÄx (ManagedBuilding(y) ‚Üí Pet(x))\", \"\\n    ‚àÉx ( Deposit(y, x) )\", \"\\n   \\t\\t 2000$ > $1500\", \"\\n   \\t\\t \\t \\t\" ], \"fol_conc\": \"Deposit(OliveGarden, 2000$)\" }\n",
      "perplexity": 2.3700919151306152,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "2000$ > $1500"
    }
  },
  {
    "id": 96,
    "nl_problem": {
      "context": [
        "If animals are loved by tourists, then they are Max's favorite animals. ",
        "All animals from Australia are loved by tourists. ",
        "All quokka are animals from Australia. ",
        "All of Max's favorite animals are very fluffy.",
        "All of Max's favorite animals love to sleep. ",
        "If a koala is very fluffy, then the koala is not a quokka."
      ],
      "question": "Koalas love to sleep.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"LovedBy(x, y)\", \"FavoriteAnimalOf(x, y)\", \"AnimalFromAustralia(x)\", \"Fluffy(y)\", \"Sleeps(x)\"],\n  \"fol_consts\": [\"Max\", \"Koalas\",\"Animals\", \"Quokkas\", \"Tourist\"],\n  \"fol_rules\": [\n    \"‚àÄx (LovedBy(max, x) ‚àß FavoriteAnimalOf(x))\",\n    \"AllAustralia Animals ‚à® All Australia Quokka\", 2.07\n   ],\n  \"fol_conc\": \"KoalasSleeps\"}",
      "perplexity": 3.0124731063842773,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 97,
    "nl_problem": {
      "context": [
        "If animals are loved by tourists, then they are Max's favorite animals. ",
        "All animals from Australia are loved by tourists. ",
        "All quokka are animals from Australia. ",
        "All of Max's favorite animals are very fluffy.",
        "All of Max's favorite animals love to sleep. ",
        "If a koala is very fluffy, then the koala is not a quokka."
      ],
      "question": "Koalas love to sleep and are quokka.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"LovedByTourists(x, y)\",\n    \"FavoriteAnimal(x, y)\",\n    \"AnimalFromAustralia(x)\",\n    \"Quokka(x)\",\n    \"Fluffy(x)\",\n    \"Sleeps(x)\" \n  ],\n  \"fol_consts\": [\n    \"Max\",\n    \"animals\",\n    \"koala\",\n  ],\n  \"fol_rules\": [\n    \"(LovedByTourists(x, y) ‚Üí FavoriteAnimal(x, y))\",\n    \"AllAnimalsFromAustralia(x) ‚àß LovedByTourists(x, y)\",\n    \"Quokka(x) ‚äÜ AnimalFromAustralia(x)\",\n    \"FavoriteAnimal(Max, x) ‚àß Fluffy(x) ‚Üí Sleeps(x)\",  \n  ],\n  \"fol_conc\": \"KoalaSleeps(koala)\" \n}\n\n```",
      "perplexity": 1.4042620658874512,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 14 column 3 (char 221)"
    }
  },
  {
    "id": 98,
    "nl_problem": {
      "context": [
        "If animals are loved by tourists, then they are Max's favorite animals. ",
        "All animals from Australia are loved by tourists. ",
        "All quokka are animals from Australia. ",
        "All of Max's favorite animals are very fluffy.",
        "All of Max's favorite animals love to sleep. ",
        "If a koala is very fluffy, then the koala is not a quokka."
      ],
      "question": "If a koala is a quokka, then the koala either loves to sleep or is very fluffy.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\" ¬†¬† ¬†\"\n  \t \t:\n   \"fol_preds\" ,\"[‚ÄúAnimal‚Äù,‚ÄùLovesTourist‚Äù, ‚ÄúFavoriteAnimals‚Äù, \" :{},\"IsQuokka\" :{}, \",\" :{},\n  \t\"fol_consts\": [\n    \"Max\",\n    \"koala\", \"], \"\n  \t \t, 1] , \"], 2: ]], 3: [ ], 4: []}\" :\"{\"\n   \t ,\"fol_preds\": [\"Animal\",\"LovesTourist\",\"FavoriteAnimals\",\"IsQuokka\"] , \",\"\n   \t\t: 2.0 , \"},\"\n  \t \t:\n   \t\t[\"\"]\n} ",
      "perplexity": 15.655437469482422,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 99,
    "nl_problem": {
      "context": [
        "A man is either kind or evil.",
        "No ugly person is handsome.",
        "All evil people are ugly.",
        "All gentlemen are handsome.",
        "All CEOs are gentlemen.",
        "Harry is a gentleman."
      ],
      "question": "Harry is a CEO.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Kind(x)\",\n    \"Evil(x)\",\n    \"Ugly(x)\",\n    \"Handsome(x)\",\n    \"Gentleman(x)\",\n    \"CEO(x)\"\n  ],\n  \"fol_consts\": [\n    \"harry\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Kind(x) ‚äï Evil(x))\",\n    \"¬¨Ugly(x) ‚Üí Handsome(x)\",\n    \"Evil(x) ‚Üí Ugly(x)\",\n    \"Gentleman(x) ‚Üí Handsome(x)\",\n    \"CEO(x) ‚Üí Gentleman(x)\" ,\n   \"Kind(harry) ‚à® Evil(harry)\",\n    \"All Men are Gentlemen\",  \n ],\n  \"fol_conc\": \"Harry is a CEO.\"\n}\n```",
      "perplexity": 1.3045963048934937,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 21 column 2 (char 386)"
    },
    "logic_problem_json": {
      "raw": "{\" üå± \"\n  \t  : \"fol_preds\"\n    \t, \"}\": [\n\t\"Kind(x)\",\n\t\"Evil(x)\",\n\t\"Handsome(x)\",\n\t\"Ugly(x)\",\n\t\"Gentleman(x)\",\n\t\"CEO(x)\"\n],\n   \t\t\"fol_consts\" : [\"Harry\"],\n    \"fol_rules\": [ \"\\n\", \"‚àÄx (Kind(x) ‚à® Evil(x))\", \"\\n\", \"¬¨Ugly(x) ‚àß Handsome(x)\", \"\\n\", \"Evil(x) ‚àß Ugly(x)\", \"\\n\", \"Gentleman(x) ‚àß CEO(x)\", \"\\n\", \"Harry ‚àß Gentleman(x)\\n\"],\n  \t\t\"fol_conc\": \"Harry ‚àß CEO(x)\" }",
      "perplexity": 2.542865753173828,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Harry ‚àß Gentleman(x)"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Kind(x)\", \"Evil(x)\", \"Ugly(x)\", \"Handsome(x)\", \"Gentleman(x)\"], \"fol_consts\": [ \"harry\" ],  \"fol_rules\": [ \"‚àÄx (Kind(x) ‚à® Evil(x))\", \"¬¨(Ugly(x) ‚àß Handsome(x))\", \"‚àÄx (Evil(x) ‚Üí Ugly(x))\", \"‚àÄx (Gentleman(x) ‚Üí Handsome(x))\", \"‚àÄx (CEO(x) ‚Üí Gentleman(x))\", \"Harry(x)\", \"Handsome(harry)\" ], \"fol_conc\": \"Harry(x) ‚àß CEO(x)\"}",
      "perplexity": 1.3990380764007568,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Harry/1, Harry/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Harry/1, Harry/0"
    }
  },
  {
    "id": 100,
    "nl_problem": {
      "context": [
        "A man is either kind or evil.",
        "No ugly person is handsome.",
        "All evil people are ugly.",
        "All gentlemen are handsome.",
        "All CEOs are gentlemen.",
        "Harry is a gentleman."
      ],
      "question": "Harry is kind or a CEO.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Kind(x)\",\n    \"Evil(x)\",\n    \"Ugly(x)\",\n    \"Handsome(x)\",\n    \"Gentleman(x)\",\n    \"CEO(x)\"\n  ],\n  \"fol_consts\": [\n    \"Harry\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Kind(harry) ‚à® CEO(harry)\"\n}\n```",
      "perplexity": 1.0844308137893677,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Kind(x)\", \"Evil(x)\", \"Ugly(x)\", \"Handsome(x)\", \"CEO(x)\"], \"fol_consts\": [\"Harry\"], \"fol_rules\": [\"\"], \"fol_conc\": \"Kind(harry) ‚à® CEO(harry)\" }\n",
      "perplexity": 1.4439871311187744,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n  \"Kind(x)\", \"Evil(x)\", \"Ugly(x)\", \"Handsome(x)\" , \"Gentleman(x)\", \"CEO(x)\"], \n  \"fol_consts\": [\n    \"harry\"\n  ],  \"fol_rules\": [\n    \"‚àÄx (Kind(x) ‚à® Evil(x))\", \"¬¨Ugly(x) ‚Üí Handsome(x)\", \"(Evil(x) ‚àß Ugly(x))\", \"(Gentleman(x) ‚àß CEO(x))\", \"Harry(gentlemen)\"],  \"fol_conc\": \"Kind(harry) ‚à® (CEO(harry))\"}",
      "perplexity": 2.7676966190338135,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Harry/1, Harry/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Harry/1, Harry/0"
    }
  },
  {
    "id": 101,
    "nl_problem": {
      "context": [
        "A man is either kind or evil.",
        "No ugly person is handsome.",
        "All evil people are ugly.",
        "All gentlemen are handsome.",
        "All CEOs are gentlemen.",
        "Harry is a gentleman."
      ],
      "question": "If Harry is either both evil and ugly, or neither evil nor ugly, then Harry is neither kind nor a CEO.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Kind(x)\", \n    \"Evil(x)\",\n    \"Handsome(x)\", \n    \"Ugly(x)\",\n    \"Gentleman(x)\",\n    \"CEO(x)\"\n  ],\n  \"fol_consts\": [\n    \"harry\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Evil(x) ‚Üí Ugly(x))\", \n    \"¬¨Ugly(x) ‚Üí Handsome(x)\", \n    \"AllEvilPeople are ugly\", \n    \"Gentlemen are handsome\", \n    \"allCEOs are gentlemen\", \n  ],\n  \"fol_conc\": \"If Harry is either both evil and ugly, or neither evil nor ugly, then Harry is neither kind nor a CEO.\"\n}\n\n```",
      "perplexity": 1.4040385484695435,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 19 column 3 (char 331)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Kind\", \"Evil\", \"Handsome\", \"Ugly\"], \"fol_consts\": [\n  \"Harry\" ],\"fol_rules\": [], \"fol_conc\": \"Neither Kind(harry) nor CEO(harry)\" } ",
      "perplexity": 2.6165263652801514,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Neither Kind(harry) nor CEO(harry)"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Kind(x)\", \"Evil(x)\", \"Ugly(x)\", \"Handsome(x)\", \"Gentleman(x)\", \"CEO(x)\"], \"fol_consts\": [\"harry\"], \"fol_rules\": [\n\"‚àÄx (Kind(x) ‚à® Evil(x))\", \"¬¨(Ugly(x) ‚àß Handsome(x))\", \"(Evil(x) ‚Üí Ugly(x))\", \"(Gentleman(x) ‚Üí Handsome(x))\", \"(CEO(x) ‚Üí Gentleman(x))\", \"‚àÄx (Gentleman(x) ‚à® CEO(x))\",\n\"Kind(harry)\", \"Evil(harry)\", \"Ugly(harry)\"], \"fol_conc\": \"¬¨(Kind(harry) ‚à® Evil(harry)) ‚àß ¬¨(CEO(harry))\"}",
      "perplexity": 1.677393913269043,
      "answer": "B",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 102,
    "nl_problem": {
      "context": [
        "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.",
        "If people have siblings who are the same age, then they are twins or triplets.",
        "If people complain often about annoying siblings, then they have siblings who are the same age.",
        "If people do not live at home regularly, then they do not develop strong bonds with their family members.",
        "If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly.",
        "Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.   "
      ],
      "question": "Luke spends a lot of time hanging out and playing with his siblings.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"TwinOrTriplet(x)\", \"DevelopStrongBondsWithFamilyMembers(x)\", \"LiveAtHomeRegularly(x)\" , \"ComplainOftenAboutSiblings(x)\",\"SpendTimeHangingOutAndPlayingWithSiblings(x)\" ],\"fol_consts\":[ \"luke\"], \"fol_rules\": [], \"fol_conc\": \" SpendTimeHangingOutAndPlayingWithSiblings(luke)\"}\n",
      "perplexity": 1.8009912967681885,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 103,
    "nl_problem": {
      "context": [
        "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.",
        "If people have siblings who are the same age, then they are twins or triplets.",
        "If people complain often about annoying siblings, then they have siblings who are the same age.",
        "If people do not live at home regularly, then they do not develop strong bonds with their family members.",
        "If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly.",
        "Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.   "
      ],
      "question": "Luke complains often about annoying siblings.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"TwinOrTriplet(x)\", \"DevelopsStrongBondsWithFamilyMembers(x)\",\"LivesAtHomeRegularly(x)\" ,\"ComplainsAboutAnnoyingSiblings(x)\"],\n\"fol_consts\": [\"Luke\"], \",\"\n  \t \t: \"fol_rules\",\n     \"‚àÉx (TwinOrTriplet(x) ‚àß DevelopsStrongBondsWithFamilyMembers(x))\"\n   \t :\"fol_conc\" }",
      "perplexity": 4.09071159362793,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 104,
    "nl_problem": {
      "context": [
        "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.",
        "If people have siblings who are the same age, then they are twins or triplets.",
        "If people complain often about annoying siblings, then they have siblings who are the same age.",
        "If people do not live at home regularly, then they do not develop strong bonds with their family members.",
        "If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly.",
        "Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.   "
      ],
      "question": "Luke is neither a twin nor triplet nor complains often about annoying siblings.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 105,
    "nl_problem": {
      "context": [
        "It costs US $205 to take the GRE test.",
        "ETS provides financial aid to those GRE applicants who prove economic hardship.",
        "Economic hardship refers to difficulty caused by having too little money or too few resources.",
        "Tom lives in a single-parent family.",
        "His dad has been out of work for more than a year."
      ],
      "question": "Tom can apply for financial aid from ETS to take the GRE test.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Cost\", \"Provides\", \"EconomicHardship\", \"LiveInFamily\"], \"fol_consts\": [\"GRE\", \"ETS\", \"$205\", \"Tom\",\"dad\"], \"fol_rules\": [], \"fol_conc\": \"FinancialAid(Tom, ETS)\"}\n",
      "perplexity": 1.9365392923355103,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Costs(x, y)\", \"ProvidesFinancialAid(x, y)\", \"EconomicHardship(y)\", \"LivesInSingleParentFamily(x)\", \"UnemployedForMoreThanYear(y)\" ], \"fol_consts\": [\"gre\", \"tom\"], \"fol_rules\": [ \"(Costs(gre, 205) ‚Üí ProvidesFinancialAid(ets, gre))\", \"(EconomicHardship(x) ‚àß LivesInSingleParentFamily(tom) ‚Üí ETSProvidesFinancialAidToApplicant(toms, gre))\" ], \"fol_conc\": \"ETSProvidesFinancialAidToApplicant(tom, gre)\" }",
      "perplexity": 1.9651862382888794,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 106,
    "nl_problem": {
      "context": [
        "It costs US $205 to take the GRE test.",
        "ETS provides financial aid to those GRE applicants who prove economic hardship.",
        "Economic hardship refers to difficulty caused by having too little money or too few resources.",
        "Tom lives in a single-parent family.",
        "His dad has been out of work for more than a year."
      ],
      "question": "It cost below US $300 to take the GRE test.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"Cost(x, y)\",\n    \"ProvidesFinancialAid(x, y)\",\n    \"EconomicHardship(y)\", \n    \"LiveInSingleParentFamily(x)\" ,\n    \"UnemployedForMoreThanOneYear(y)\",\n    \"GRETest\" \n  ],\n  \"fol_consts\": [\n    \"205\",\n    \"300\",\n    \"ETS\",\n    \"Tom\",\n    \"EconomicHardship\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Cost(x, y) ‚â§ 300\"\n}\n\n\n\n",
      "perplexity": 1.515221357345581,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Cost(x, y) ‚â§ 300"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Cost(x, y)\", \"ProvidesFinancialAid(x, y)\",\"EconomicHardship(x)\"],\"fol_consts\": [ \"GRE\", \"$205\", \"ETS\", \"Tom\", \"single-parent family\", \"dad\", \"out of work\"],\"fol_rules\": [], \"fol_conc\": \"\"}\n",
      "perplexity": 1.964613437652588,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Cost(x, y)\", \"Provide(x, y)\", \"Hardship(x)\", \"SingleParentFamily(x)\"], \"fol_consts\": [\n  \"gre\",\n  \"ets\",\n  \"205\", \"300\"], \"fol_rules\": [\n    \"(Cost(gre, 205) ‚Üí (Provide(ets, gre) ‚àß Hardship(tom)))\",\n  \"Hardship(tom)\",\n  \"(SingleParentFamily(tom)) ‚àß (DadOutOfWorkForMoreThanAYear(father) ‚àß Cost(gre, 300))\"], \"fol_conc\": \"Cost(gre, 205)\" }",
      "perplexity": 2.122049570083618,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 107,
    "nl_problem": {
      "context": [
        "It costs US $205 to take the GRE test.",
        "ETS provides financial aid to those GRE applicants who prove economic hardship.",
        "Economic hardship refers to difficulty caused by having too little money or too few resources.",
        "Tom lives in a single-parent family.",
        "His dad has been out of work for more than a year."
      ],
      "question": "There is no financial aid available for the GRE test.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"costs\", \"provides\", \"economic_hardship\"], \"fol_consts\": [], \"fol_rules\": [\"\"], \"fol_conc\": \"\" }\n",
      "perplexity": 2.1722676753997803,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Cost(x, y)\", \"ProvideFinancialAid(x, y)\", \"EconomicHardship(y)\", \"SingleParentFamily(x, y)\",\"WorklessFor(x, y)\"], \"fol_consts\": [ \"gre\", \"ets\" ,\"tom\"],  \"fol_rules\": [ \"Cost(gre, 205) ‚àß ProvideFinancialAid(ets, x) ‚Üí NotEconomicHardship(x)\", \"NotEconomicHardship(x) ‚àß SingleParentFamily(tom, x)\" , \"WorklessFor(dad, tom)\"],  \"fol_conc\": \"NotFinancialAidAvailableForGRETest(gre)\"}",
      "perplexity": 1.9255925416946411,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 108,
    "nl_problem": {
      "context": [
        "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.",
        "All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.",
        "If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.",
        "If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.",
        "All households with a high net income have people who have parents who are very busy with their regular jobs.",
        "Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings. "
      ],
      "question": "Peter tidies his space consistently and enjoys the process of cleaning.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"Spill(x)\",\n    \"Tidy(x)\",\n    \"EnjoyCleaning(x)\",\n    \"Foodie(x)\",\n    \"OnlyChild(x)\",\n    \"Sibling(x)\" , \n    \"ParentBusyJob(x)\"\n  ],\n  \"fol_consts\": [\n    \"peter\",\n    \"household\" \n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Tidy(peter) ‚àß EnjoyCleaning(peter)\"\n}\n\n",
      "perplexity": 1.3874448537826538,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\" üß†\"\n  : \"fol_preds\", \":[ ][\" :\", 1 , 2 , 3, 4 ]], üí°\"\n   }\n    ",
      "perplexity": 44.16716766357422,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 109,
    "nl_problem": {
      "context": [
        "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.",
        "All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.",
        "If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.",
        "If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.",
        "All households with a high net income have people who have parents who are very busy with their regular jobs.",
        "Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings. "
      ],
      "question": "Peter is either a foodie who goes out frequently to find new food restaurants to try or belongs to a household with a high net income.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 110,
    "nl_problem": {
      "context": [
        "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.",
        "All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.",
        "If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.",
        "If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.",
        "All households with a high net income have people who have parents who are very busy with their regular jobs.",
        "Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings. "
      ],
      "question": "Peter is either a foodie who goes out frequently to find new food restaurants to try and belong to a household with a high net income or he is a foodie who goes out frequently to find new food restaurants to try nor belongs to a household with a high net income.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 111,
    "nl_problem": {
      "context": [
        "All fir trees are evergreens.",
        "Some objects of worship are fir trees."
      ],
      "question": "Some evergreens are not objects of worship.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"IsFirTree(x)\",\n    \"Evergreen(x)\",\n    \"isWorshipObject(x)\"\n  ],\n  \"fol_consts\": [], \n  \"fol_rules\": [], \n  \"fol_conc\": \"‚àÉx (Evergreen(x) ‚àß ¬¨ isWorshipObject(x))\" \n}\n```",
      "perplexity": 1.3666629791259766,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"FirTree(x)\", \"Evergreen(x)\", \"ObjectOfWorship(x)\" ], \"fol_consts\": [ \"firtree\", \"evergreen\" ], \"fol_rules\": [], \"fol_conc\": \"‚àÉx (Evergreen(x) ‚àß ¬¨ObjectOfWorship(x))\"}\n",
      "perplexity": 1.4129211902618408,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"FirTree(x)\", \"Evergreen(x)\", \"ObjectOfWorship(x)\"], \n\"fol_consts\": [\"fir\", \"evergreen\"], \n\"fol_rules\":[\n    \"‚àÄx (FirTree(x) ‚Üí Evergreen(x))\",\n    \"‚àÉx (ObjectOfWorship(x) ‚àß FirTree(x))\" ,\n  \"‚àÄx (Evergreen(x) ‚à® ¬¨ObjectOfWorship(x))\" ], \n \"fol_conc\": \"‚àÉx (Evergreen(x) ‚àß ¬¨ObjectOfWorship(x))\"}",
      "perplexity": 1.523328423500061,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 112,
    "nl_problem": {
      "context": [
        "The Picuris Mountains are a mountain range in New Mexico or Texas.",
        "Juan de Onate visited the Picuris Mountains.",
        "The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.",
        "There are no mountain ranges in texas that have mines which have been donated."
      ],
      "question": "Juan de Onate visited a mountain range in New Mexico.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"MountainRange(x)\", \"LocatedIn(y, x)\", \"Visited(z, y)\", \"Mine(x)\", \"Donate(x)\" ],\n\"fol_consts\": [\n  \"picurisMountains\", \",\"\n],\n\"fol_rules\": [],\n\"fol_conc\": \"Visited(Juan de Onate, MountainRange(NewMexico))\" } ",
      "perplexity": 2.3422882556915283,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Visited(Juan de Onate, MountainRange(NewMexico))"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"MountainRange(x)\", \"Visit(x, y)\", \"LocatedIn(x, y)\", \"MineDonated(x)\"], \"fol_consts\": [\"picuris\", \"juan\", \"newmexico\", \"texas\"], \"fol_rules\": [\n  \"‚àÄx (MountainRange(x) ‚à® MountainRange(y)) ‚Üí LocatedIn(x, picuris) ‚àß Visit(x, juan)\",\n  \"LocatedIn(x, picuris) ‚àß MineDonated(x)\" ,\n  \"NoMineDonation(x, texas)\", \"‚àÉx (MountainRange(x) ‚àß MineDonated(x))\",\n  \"Visit(juan, x) ‚Üí LocatedIn(x, newmexico)\"\n], \"fol_conc\": \"LocatedIn(newmexico, juan)\" }",
      "perplexity": 1.7792257070541382,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 113,
    "nl_problem": {
      "context": [
        "The Picuris Mountains are a mountain range in New Mexico or Texas.",
        "Juan de Onate visited the Picuris Mountains.",
        "The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.",
        "There are no mountain ranges in texas that have mines which have been donated."
      ],
      "question": "Juan de Onate visited a mountain range in Texas.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"MountainRange(x)\",\n    \"Visited(x, y)\",\n    \"LocatedIn(x, y)\", \n    \"Donate(x)\"\n  ],\n  \"fol_consts\": [\n    \"picurismountains\",\n    \"texas\",\n    \"hardingpegmatitemine\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Visited(juan de Onate, Texas)\" \n}\n```",
      "perplexity": 1.3221865892410278,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"MountainRange(x)\", \"Visited(x, y)\",\"LocationOfMine(x)\", \"Donate(y)\", \"HasMines(x, y)\" ],  \"fol_consts\":[\"picuris\", \"texas\"], \"fol_rules\": [\n    \"‚àÉx (MountainRange(x) ‚à® MountainRange(y))\",\n    \"JuanDeOnateVisited(juandeonates, picuris)\",\n    \"LocationOfMine(hardingpegmatite, picuris)\",\n    \"(TexasHasMines(texas) ‚Üí ¬¨Donation(texas, picuris))\",\n    \"¬¨Donate(texas, picuris)\"\n  ], \"fol_conc\": \"JuanDeOnateVisited(juandeonates, texas)\" }",
      "perplexity": 2.350214958190918,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 114,
    "nl_problem": {
      "context": [
        "The Picuris Mountains are a mountain range in New Mexico or Texas.",
        "Juan de Onate visited the Picuris Mountains.",
        "The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.",
        "There are no mountain ranges in texas that have mines which have been donated."
      ],
      "question": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"MountainRange(x)\",\n    \"LocationIn(x, y)\",\n    \"VisitedBy(x, y)\",\n    \"DonatedTo(x, y)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÉx (MountainRange(x) ‚à® MountainRange(y))\",\n    \"LocationIn(PicurisMountains, New Mexico)\",\n    \"LocationIn(HardingPegmatiteMine, Picuris Mountains)\",\n    \"¬¨(LocationIn(TexasMountainRanges, Harding Pegmatite Mine))\"\n  ],\n  \"fol_conc\": \"Not (LocationIn(NewMexicoMountainRange, Harding Pegmatite Mine))\" \n\n}\n\n\n\n",
      "perplexity": 1.6058306694030762,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Not (LocationIn(NewMexicoMountainRange, Harding Pegmatite Mine))"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"LocatedIn\", \"MountainRange\", \"VisitedBy\", \"DonatedTo\", \"Mine\" ], \"fol_consts\": [ \"PicurisMountains\", \"HardingPegmatiteMine\", \"NewMexico\",\"Texas\"], \"fol_rules\": [ \"\", \"\", \"\", \"\", \"\"], \"fol_conc\": \"Not LocatedIn(Harding Pegmatite Mine, New Mexico)\"}\n",
      "perplexity": 1.9122651815414429,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 115,
    "nl_problem": {
      "context": [
        "If a man is taller than another man, the taller one can block the other's shooting.",
        "Michael is a man who is taller than everyone else in his class.",
        "If person x is taller than person y, and person y is taller than person z, than x is taller than z",
        "Peter is a man who is taller than Michael.",
        "Michael can block any shooting from a person as long as the person does not jump when shooting.",
        "Michael cannot block Windy's shooting.",
        "Every shooter who can jump when shooting is a great shooter."
      ],
      "question": "Peter is shorter than a man in Michael's class.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"TallerThan(x, y)\", \"BlockShooting(x, y)\", \"PersonXis taller than PersonY\", \"Greaterthan(x,y)\", \"JumpWhenShooting(x)\"], \"fol_consts\": [ \"Michael\",\"Peter\",\"Windy\",\"Everyone in class\" ], \"fol_rules\": [\"\"], \"fol_conc\": \"\" }\n",
      "perplexity": 2.5583596229553223,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 116,
    "nl_problem": {
      "context": [
        "If a man is taller than another man, the taller one can block the other's shooting.",
        "Michael is a man who is taller than everyone else in his class.",
        "If person x is taller than person y, and person y is taller than person z, than x is taller than z",
        "Peter is a man who is taller than Michael.",
        "Michael can block any shooting from a person as long as the person does not jump when shooting.",
        "Michael cannot block Windy's shooting.",
        "Every shooter who can jump when shooting is a great shooter."
      ],
      "question": "Windy is a great shooter.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"tallerThan\", \"blockShooting\", \"isMan\", \"canJump\" ], \",\"\n  :\n    [ \"Michael\" , \"Peter\" ,\"Windy\" ]\n, \"fol_rules\": [ \"‚àÄx(tallerThan(x1, x2) ‚Üí blockShooting(x1, x2))\", \" Michael taller than everyone in his class.\", \"if x is taller than y and y is taller than z then x is taller than z \", \"Peter is a man who is taller than Michael. \", \"Michael can block any shooting from a person as long as the person does not jump when shooting\", \"Michael cannot block Windy's shooting.\", \"Every shooter who can jump when shooting is a great shooter.\" ],\n  \"fol_conc\": \"Windy is a great shooter.\"} ",
      "perplexity": 2.1762030124664307,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Michael taller than everyone in his class."
    }
  },
  {
    "id": 117,
    "nl_problem": {
      "context": [
        "If a man is taller than another man, the taller one can block the other's shooting.",
        "Michael is a man who is taller than everyone else in his class.",
        "If person x is taller than person y, and person y is taller than person z, than x is taller than z",
        "Peter is a man who is taller than Michael.",
        "Michael can block any shooting from a person as long as the person does not jump when shooting.",
        "Michael cannot block Windy's shooting.",
        "Every shooter who can jump when shooting is a great shooter."
      ],
      "question": "Peter can block Windy's shooting.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 118,
    "nl_problem": {
      "context": [
        "Barutin Cove is named after the Bulgarian settlement of Barutin.",
        "Barutin Cove is on the southwest coast of Snow Island.",
        "The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island.",
        "The South Shetland Islands are considered part of Antarctica.",
        "If A is located in B and B is located in C, then A is located in C."
      ],
      "question": "Barutin is named after all islands in Antarctica.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Location\", \"NamedBy\"],\"fol_consts\": [\"Barutin Cove\",\"Bulgarian settlement of Barutin\", \"Snow Island\", \"South Shetland Islands\", \"Greenwich Island\", \"Deception Island\", \"Antarctica\"],\"fol_rules\": [\n    \"(Located(barutin cove, snow island) ‚àß Located(snow island, south sheltland islands)) ‚Üí (Barutin Cove is located in Antarctica)\",\n    \"IsPartOf(SouthShetlandsIslands, Antarctic), IsLocatedOn(Snow Island, SouthShetland Islands)\",\n    \"If A is Located in B and B is Located in C then A is located in C\", 0\n  ], \"fol_conc\": \"Barutin is named after all islands in Antarctica.\"}\n",
      "perplexity": 2.2979366779327393,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"LocatedIn(x, y)\", \"NamedAfter(x, y)\"], \"fol_consts\": [ \"barutin\", \"snowisland\", \"southsheltariislands\",\"greenwich\", \"deception\", \"antarctica\" ], \"fol_rules\": [ \"‚àÄx ‚àÉy (LocatedIn(x, y) ‚Üí NamedAfter(x, y))\", \"SWHIsIncludeSnowIslandAndDeceptionIsland(s)\", \"AntarcticaIncludesSouthShetlandIslands(s)\" ], \"fol_conc\": \"NamedAfterAllIslandsOfAntarctica(barutin)\" }",
      "perplexity": 2.387037515640259,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 119,
    "nl_problem": {
      "context": [
        "Barutin Cove is named after the Bulgarian settlement of Barutin.",
        "Barutin Cove is on the southwest coast of Snow Island.",
        "The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island.",
        "The South Shetland Islands are considered part of Antarctica.",
        "If A is located in B and B is located in C, then A is located in C."
      ],
      "question": "There is at least one cove in Antarctica named after a place in Bulgaria.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"LocatedIn(x, y)\", \"NamedAfter(x, y)\"], \"fol_consts\": [\"barutincove\", \"snowisland\", \"southshelandislands\",\"greenwichisland\", \"deceptionisland\"], \"fol_rules\": [\n\"‚àÄx ‚àÉy (LocatedIn(x, y))\",\n\"‚àÄx ‚àÄy (LocatedIn(x, y) ‚Üí LocatedIn(y, x))\", \"(SouthShelandIslands(a) ‚Üí LocatedIn(a, barutincove))\", \"BarutinCove(barutincove)\",\n\"NamedAfter(b, a)\" ], \"fol_conc\": \"‚àÉx (LocatedIn(x, southshellandislands) ‚àß NamedAfter(x, barutincove))\"}",
      "perplexity": 2.1867787837982178,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 120,
    "nl_problem": {
      "context": [
        "Barutin Cove is named after the Bulgarian settlement of Barutin.",
        "Barutin Cove is on the southwest coast of Snow Island.",
        "The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island.",
        "The South Shetland Islands are considered part of Antarctica.",
        "If A is located in B and B is located in C, then A is located in C."
      ],
      "question": "Barutin is not located in Antarctica.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"NamedBy(x, y)\", \"LocatedIn(x, y)\", \"PartOf(y, z)\" , \"Location(x, y)\"],\n  \"fol_consts\": [ 0,\"Barutin\", \"Cove\",\"Bulgaria\",\"Snow Island\",\"South Shetland Islands\",\"Greenwich Island\",\"Deception Island\"],\n  \"fol_rules\": [],\n  \"fol_conc\": \" ¬¨PartOf(Barutin Cove, Antarctica)\" }",
      "perplexity": 2.454848051071167,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"LocatedIn(x, y)\", \"NamedAfter(x, y)\", \"OnCoastOf(y)\",\"IsPartOf(x, y)\"], \"fol_consts\": [\n  \"barutin\", \"snowisland\", \"southshetlandsislands\", \"antarctica\", \"barutincove\"], \"fol_rules\": [\n    \"(LocatedIn(barutin, snowisland)) ‚Üí (OnCoastOf(barutincove, snowisland) ‚àß IsPartOf(southshetlandsislands, barutincove))\",\n    \"IsPartOf(southshetlandsislands, antarctica)\", \"(LocatedIn(a, b) ‚àß LocatedIn(b, c)) ‚Üí LocatedIn(a, c)\"\n  ], \"fol_conc\": \"(NotLocatedIn(barutin, antarctica))\" }",
      "perplexity": 2.5313518047332764,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 121,
    "nl_problem": {
      "context": [
        "Some affection is love.",
        "Some love is positive."
      ],
      "question": "Some affection is positive.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Affection(x)\", \n    \"Love(x)\",\n    \"Positive(x)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n  \n  ],\n  \"fol_conc\": \"‚àÉx ( Affection(x) ‚àß Positive(x))\"\n}\n\n```",
      "perplexity": 1.3121129274368286,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Affection(x)\", \"Love(x)\", \"Positive(x)\"], \"fol_consts\": [], \"fol_rules\": [\"\"], \"fol_conc\": \"\"} ",
      "perplexity": 1.6168464422225952,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n  \"Affection(x)\",\n  \"Love(x)\",\n  \"Positive(y)\" ], \"fol_consts\": [\"affection\", \"love\"], \"fol_rules\": [\n    \"‚àÉx (Affection(x) ‚Üí Love(x))\",\n    \"‚àÉx (Love(x) ‚Üí Positive(x))\" ], \"fol_conc\": \"‚àÉx (Affection(x) ‚àß Positive(x))\"}",
      "perplexity": 1.7556802034378052,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 122,
    "nl_problem": {
      "context": [
        "If something can transport multiple passengers, then they are not empty.",
        "All airlines can transport multiple passengers.",
        "All planes are empty.",
        "All Boeing 707s are planes.",
        "If Greyhound is not an airline, then there are no Greyhound planes."
      ],
      "question": "Greyhound is an airline.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 123,
    "nl_problem": {
      "context": [
        "If something can transport multiple passengers, then they are not empty.",
        "All airlines can transport multiple passengers.",
        "All planes are empty.",
        "All Boeing 707s are planes.",
        "If Greyhound is not an airline, then there are no Greyhound planes."
      ],
      "question": "A Greyhound is a Boeing 707.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"canTransport\", \"empty\", \"airline\", \"plane\", \"Boeing707\"], \"fol_consts\": [\"Greyhound\",\"Airline\", \"Airplanes\", \"Boeing 707\"],\"fol_rules\": [],\"fol_conc\": \"Boeing707(greyhound)\" }\n",
      "perplexity": 2.0704100131988525,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"CanTransport(x, y)\", \"Empty(x)\", \"Airline(x)\", \"Plane(x)\", \"Boeing707(x)\", \"Greyhound(x)\"], \"fol_consts\":[\"airplanes\",\"greyhound\", \"boeing707\"], \"fol_rules\": [\n    \"‚àÄx (CanTransport(x, y) ‚Üí ¬¨Empty(x))\",\n    \"‚àÄx (Airline(x) ‚Üí CanTransport(x, y))\", \"(AllAirlines(x))\", \"(Plane(x) ‚Üí Boeing707(x))\", \"¬¨GreyhoundIsAirline(x)\", \"(NoGreyhoundPlanes(x))\", \"(CanTransport(y, z) ‚Üí (NotEmpty(z)))\"\n],  \"fol_conc\": \"GreyhoundIsBoeing707(greyhound)\" }",
      "perplexity": 2.355379104614258,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 124,
    "nl_problem": {
      "context": [
        "If something can transport multiple passengers, then they are not empty.",
        "All airlines can transport multiple passengers.",
        "All planes are empty.",
        "All Boeing 707s are planes.",
        "If Greyhound is not an airline, then there are no Greyhound planes."
      ],
      "question": "A Greyhound is not a Boeing 707.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"CanTransport(x, y)\", \"Empty(y)\", \"Airline(x)\", \"Plane(x)\", \"Boeing707(x)\", \"Greyhound(x)\"], \"fol_consts\": [\"greyhound\", \"planes\"], \"fol_rules\":[\n\"‚àÄx (CanTransport(x, y) ‚Üí ¬¨Empty(y))\", \"\\t\\t‚àÄx (Airline(x) ‚Üí CanTransport(x, y))\", \"\\t\\t‚àÄx (Plane(x) ‚Üí Empty(x))\", \"\\t\\t‚àÄx (Boeing707(x) ‚Üí Plane(x))\",\n\"¬¨Greyhound(x) ‚à® ¬¨Airline(x)  ‚Üí \\n no plane is a Greyhound\"], \"fol_conc\": \"Not Boeing707\"}",
      "perplexity": 2.001330614089966,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "¬¨Greyhound(x) ‚à® ¬¨Airline(x)  ‚Üí \n no plane is a Greyhound"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"CanTransport(x)\", \"Empty(x)\",\"Airline(x)\", \"Plane(x)\"], \"fol_consts\": [\"greyhound\", \"boeing707\", \"airlines\", \"planes\", \"groundrey\"], \"fol_rules\":[\n    \"‚àÄx (CanTransport(x) ‚Üí ¬¨Empty(x))\", \"‚àÄx (Airline(x) ‚Üí CanTransport(x))\", \"‚àÄx (Plane(x) ‚Üí Empty(x))\", \"(Boeing707(b) ‚Üí Plane(b))\", \"¬¨(Greyhound(g) ‚Üí NoPlanes(g))\"\n],  \"fol_conc\": \"¬¨Boeing707(greyhound)\" }",
      "perplexity": 2.035356044769287,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Greyhound/1, Greyhound/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Greyhound/1, Greyhound/0"
    }
  },
  {
    "id": 125,
    "nl_problem": {
      "context": [
        "All mammals are animals.",
        "All monkeys are mammals. ",
        "An animal is either a monkey or a bird.",
        "All birds fly.",
        "All animals breathe.",
        "If something can fly, then it has wings.",
        "If Rock is neither a fly nor a bird, then Rock neither flies nor breathes."
      ],
      "question": "Rock is a monkey.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"mammal\", \"animal\", \"monkey\", \"bird\", \"fly\", \"breathe\", \"wings\"], \",\"\n    \t:\"fol_consts\" , \":[\":\",\"\n\t\t  \t,\":\"\n\t\t\t : \"rock\", \"animals\"\n   \t :\" }, {\"\n  \t \t,\": [\"\n   \t\t: \"mammal\", \",\"\n\t\t\t\t :\"animal\", \"bird\"\n   \t :\"fly\", \":\"\n    \t:\"breathe\" ,\"wings\"\n   \t :\"Rock\",\n  \t \t\"animals\"\n\t  : \"rock\", \"monkey\"\n \t \t:\"birds\" , \",\"\n\t\t : \"flies\" ,\"breaths\"\n\t\t\t \t:\"neither flies nor breathes\", \"Rock neither flies nor breathes\"\n     : \"\"\n   }\n    \t",
      "perplexity": 9.68362045288086,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 126,
    "nl_problem": {
      "context": [
        "All mammals are animals.",
        "All monkeys are mammals. ",
        "An animal is either a monkey or a bird.",
        "All birds fly.",
        "All animals breathe.",
        "If something can fly, then it has wings.",
        "If Rock is neither a fly nor a bird, then Rock neither flies nor breathes."
      ],
      "question": "Rock has wings.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Animal(x)\", \"Mammal(x)\", \"Monkey(x)\", \"Bird(x)\", \"Fly(x)\", \"Breathe(x)\", \"Winged(x)\"], \"fol_consts\":[\"rock\"], \"fol_rules\": [\n\"‚àÄx (Animal(x) ‚Üí Mammal(x))\", \"(AllX(mammal, x) ‚àß AllX(monkey, x)) ‚Üí Animal(x) ‚à® Bird(x)\", \"(Bird(x) ‚äï Fly(x)) ‚àß (Fly(x) ‚Üí Winged(x))\", \"‚àÄx (Animal(x) ‚àß Breathe(x)) ‚à® (AllX(mammal, x) ‚àß AllX(bird, x))\"\n], \"fol_conc\": \"Winged(rock)\" }",
      "perplexity": 2.076075553894043,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Bird/1, Bird/0, Mammal/1, Mammal/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Bird/1, Bird/0, Mammal/1, Mammal/0"
    }
  },
  {
    "id": 127,
    "nl_problem": {
      "context": [
        "All mammals are animals.",
        "All monkeys are mammals. ",
        "An animal is either a monkey or a bird.",
        "All birds fly.",
        "All animals breathe.",
        "If something can fly, then it has wings.",
        "If Rock is neither a fly nor a bird, then Rock neither flies nor breathes."
      ],
      "question": "Rock does not have wings.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Mammal(x)\",\n    \"Animal(x)\",\n    \"Monkey(x)\",\n    \"Fly(x)\", \n    \"Bird(x)\",\n    \"Breathe(x)\" ,\n    \"HasWings(x)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (Mammal(x) ‚Üí Animal(x))\",\n    \"‚àÄx (Monkey(x) ‚àß Mammal(x))\",\n    \"‚àÄx (Animal(x) ‚à® Bird(x))\",\n    \"‚àÄx (Bird(x) ‚Üí Fly(x))\",\n    \"‚àÄx (Animal(x) ‚Üí Breathe(x))\",\n    \"¬¨Fly(Rock) ‚Üí ¬¨HasWings(Rock)\", \n  ],\n  \"fol_conc\": \"¬¨HasWings(Rock)\"\n}\n\n```",
      "perplexity": 1.22447669506073,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 19 column 3 (char 382)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Mammal\", \"Animal\", \"Monkey\", \"Bird\", \"Fly\", \"Breathe\", \"Wings\"],\n\"fol_consts\": [\n    \"Rock\"\n],\n\"fol_rules\": [ 1,2 ], \"\" :\", 3 ]}, 3] }, 3] , \" }\n  ",
      "perplexity": 6.720648288726807,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Animal(x)\", \"Mammal(x)\", \"Bird(x)\", \"Fly(x)\",\"Breathe(x)\" ,\"Wings(x)\"], \"fol_consts\": [ \"rock\" ],  \"fol_rules\": [\n    \"‚àÄx (Animal(x) ‚Üí Mammal(x))\",\n    \"‚àÄx (Monkey(x) ‚Üí Mammal(x))\", \"(Mammal(x) ‚à® Bird(x))\", \"(Bird(x) ‚Üí Fly(x))\", \"(Animal(x) ‚Üí Breathe(x))\", \"¬¨Fly(x) ‚Üí ¬¨Wings(x)\",\n    \"Not(fly, x) ‚Üí Not(breathe, x)\"],  \"fol_conc\": \"¬¨Wings(rock)\"}",
      "perplexity": 2.4294815063476562,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Breathe/1, Breathe/0, Fly/1, Fly/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Breathe/1, Breathe/0, Fly/1, Fly/0"
    }
  },
  {
    "id": 128,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John has a wedding that is well-attended.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 129,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John does not have a wedding that is well-attended.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 130,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John has at least one child.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 131,
    "nl_problem": {
      "context": [
        "All people who have a wedding are people who have at least one child.",
        "All people who travel to Paris for their honeymoon are people who have a wedding.",
        "All weddings that occur in July belong to people who travel to Paris for their honeymoon.",
        "Some weddings in July are well-attended.",
        "If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.",
        "If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon. "
      ],
      "question": "John has neither a wedding that is well-attended nor does he travel to Paris for his honeymoon.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 132,
    "nl_problem": {
      "context": [
        "[BG] Some mammals have teeth.",
        "Platypus have no teeth.",
        "Platypus are mammals. ",
        "Humans have teeth."
      ],
      "question": "Platypus are mammals with no teeth.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Mammal(x)\",\n    \"Teeth(x)\"\n  ],\n  \"fol_consts\": [\n    \"Platypus\",\n    \"Humans\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Mammal(x) ‚Üí Teeth(x))\",\n    \"¬¨(Platypus ‚àß ¬¨Teeth(platypus))\",\n    \"Platypus ‚àß Mammal(platypus)\",\n    \"Human ‚àß Teeth(humans)\"\n  ],\n  \"fol_conc\": \"Platypus ‚àß Mammal(platypus) ‚àß ¬¨Teeth(platypus)\"\n}\n```",
      "perplexity": 1.172028660774231,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "¬¨(Platypus ‚àß ¬¨Teeth(platypus))"
    },
    "logic_problem_json": {
      "raw": "{\" lls: [[\"\n  \t \t: [\"Mammal(x)\", \"Toothless(x)\"],\n  \"platypus\": \"Platypus\",\n  \"mammal\": \"Mammals\",\n    \"Humans\":\"Human\",\"teeth\" : \"Teeth\" , \"]]\"\n   \t\t: [],\n     \"fol_preds\": [\n\t \t\t\t\"Mammal(x)\",\n\t \t\t\t\"Toothless(x)\"],\n    \"fol_consts\": [\"platypus\", \"humans\"],\n  \"fol_rules\": [\n  ] ,\n  \"fol_conc\": \"\"\n   }\n",
      "perplexity": 4.973275184631348,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Mammal(x)\", \"HasTeeth(x)\", \"IsPlatypus(x)\"], \"fol_consts\": [\"platypus\", \"human\"], \"fol_rules\": [\n  \"‚àÄx (Mammal(x) ‚Üí HasTeeth(x))\", \"IsPlatypus(platypus)\" , \"¬¨(IsPlatypus(platypus)) ‚àß ¬¨HasTeeth(platypus)\", \"‚àÄx (Mammal(x) ‚Üí HasTeeth(x))\" ], \"fol_conc\": \"IsPlatypus(platypus) ‚àß ¬¨HasTeeth(platypus)\"}",
      "perplexity": 1.6653820276260376,
      "answer": "A",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 133,
    "nl_problem": {
      "context": [
        "[BG] Some mammals have teeth.",
        "Platypus have no teeth.",
        "Platypus are mammals. ",
        "Humans have teeth."
      ],
      "question": "Platypus are reptiles.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Mammal(x)\",\n    \"Teeth(x)\",\n    \"Reptile(x)\" \n  ],\n  \"fol_consts\": [\n    \"platypus\",\n    \"humans\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Mammal(x) ‚Üí Teeth(x))\",\n    \"Platypus ‚àà Mammal(x)\",\n    \"Platypus ‚àâ Teeth(x)\",\n    \"Humans ‚àà Mammal(x)\",\n    \"Humans ‚üπ Teeth(x)\"\n  ],\n  \"fol_conc\": \"Platypus ‚àâ Reptile(x)\" \n}\n```",
      "perplexity": 1.150987982749939,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Platypus ‚àà Mammal(x)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"mammal\", \"hasTeeth\", \"isPlatypus\", \"isHuman\" ],\n\"fol_consts\": [], \",\"\n  : \"fol_rules\", \":[{ \" :[],\n    \"\" : \"‚àÄx (Mammal(x) ‚Üí hasTeeth(x))\" ,\n    \"\": \"platypus is mammal ‚àß not platypus has teeth\" , \",\" :\"\"\n   } ",
      "perplexity": 7.387760162353516,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Mammal(x)\", \"Teeth(x)\", \"Reptile(y)\"], \"fol_consts\": [\"platypus\", \"human\"], \"fol_rules\": [ \"‚àÄx (Mammal(x) ‚Üí Teeth(x))\", \"Platypus(x) ‚àß Mammal(x) ‚Üí ¬¨Teeth(x)\", \"Human(x) ‚Üí Teeth(x)\" , \"(Platypus(x) ‚àß Mammal(x)) ‚Üí Reptile(y)\", \"Reptile(y)\"],  \"fol_conc\": \"Platypus(x) ‚àß Reptile(y)\" }",
      "perplexity": 1.5269546508789062,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 134,
    "nl_problem": {
      "context": [
        "[BG] Some mammals have teeth.",
        "Platypus have no teeth.",
        "Platypus are mammals. ",
        "Humans have teeth."
      ],
      "question": "Humans are mammals.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Mammal(x)\",\n    \"HasTeeth(x)\"\n  ],\n  \"fol_consts\": [\n    \"Platypus\",\n    \"Humans\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Humans are Mammals\" \n}\n\n```",
      "perplexity": 1.2968904972076416,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Humans are Mammals"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Mammal(x)\", \"Teeth(x)\"], \"fol_consts\": [\"humans\", \"platypus\"], \"fol_rules\": [\"\"], \"fol_conc\": \"Humans are mammals\"} ",
      "perplexity": 1.730789065361023,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Humans are mammals"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Mammal(x)\", \"HasTeeth(x)\"], \"fol_consts\": [\"platypus\", \"human\"], \"fol_rules\": [\n    \"‚àÄx (Mammal(x) ‚Üí HasTeeth(x))\", \"PlatypusHasNoTeeth(platypus)\", \"PlatypusIsAMammal(platypus)\", \"HumansHaveTeeth(human)\"\n  ], \"fol_conc\": \"HumanIsMammal(human)\" }",
      "perplexity": 2.2163147926330566,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 135,
    "nl_problem": {
      "context": [
        "Plungers suck.",
        "Vacuums suck.",
        "Vampires suck.",
        "Space is a vacuum.",
        "A duster is a household appliance that doesn't suck."
      ],
      "question": "Space sucks.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Suck(x)\",\n    \"HouseholdAppliance(x)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"\",\n    \"\",\n    \"‚àÄx ( Suck(x) ‚àß HouseholdAppliance(duster)) ‚Üí ¬¨Suck(Space)\", \n   \"‚àÉx (Vacuum(x) ‚à® Space suck)\" ,\n  ],\n  \"fol_conc\": \"suck(space)\"\n}\n\n```",
      "perplexity": 1.9679017066955566,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 12 column 3 (char 224)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"Suck(x)\", \"HouseholdAppliance(x)\" ], \",\"\n  :\n    \"fol_consts\" ,\n     \":[\": \", \" , \"Space\"\n  :\n  \"fol_rules\" ,\n   \"‚àÄx (Suck(x) ‚Üí Suck(Plungers)) \\n\"\n   :\n  \"‚àÄx (Suck(x) ‚Üí Suck(Vacuums)) \\n\" ,\"‚àÉx (Suck(x) & HouseholdAppliance(x) )\\n\"\n  :\n    \"fol_conc\", \"Space sucks.\" :\"} \"}",
      "perplexity": 5.529197692871094,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Suck(x)\", \"HouseholdAppliance(x)\"], \"fol_consts\": [\"space\", \"plungers\", \"vacuums\",\"vampires\",\"duster\"], \"fol_rules\": [\n    \"‚àÄx (Suck(x) ‚àß Suck(vaccum))\",\n    \"¬¨Suck(duster)\",\n    \"SpaceSucking(space, vacuums)\" , \"Vacuum(space, vacuums) ‚Üí SpaceSucking(space, vacuums)\"\n], \"fol_conc\": \"SpaceSucks(space)\" }",
      "perplexity": 2.4331910610198975,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 136,
    "nl_problem": {
      "context": [
        "Plungers suck.",
        "Vacuums suck.",
        "Vampires suck.",
        "Space is a vacuum.",
        "A duster is a household appliance that doesn't suck."
      ],
      "question": "Space is a vampire.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Suck(x)\",\n    \"HouseholdAppliance(x)\",\n    \"Vampire(x)\"\n  ],\n  \"fol_consts\": [\n    \"space\",\n    \"plunger\",\n    \"vacuum\" , \n    \"duster\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Space is a vampire.\" \n}\n```",
      "perplexity": 1.2603522539138794,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Space is a vampire."
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"Suck(x)\", \"HouseholdAppliance(x)\", \"Vampire(x)\", \"Space\" ],\n  \"fol_consts\": [], \",\"\n  \t \t: \"Plunger\",\n  \t\t\"Vacuum\": \"Vacuums suck.\",\n  \t\t\"Vampire\": \"Vampires suck.\" ,\n   \t\t\"Duster\": \"A duster is a household appliance that doesn't suck.\",\n    \t\"Space\": \"Space sucks.\"\n  ,\"fol_rules\": [ 0,1 ],\n\"fol_conc\": \"Space is a vampire.\" } ",
      "perplexity": 3.3419508934020996,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Suck(x)\", \"HouseholdAppliance(x)\", \"Vampire(x)\", \"Space(x)\"], \"fol_consts\": [\"plunger\", \"vacuum\",\"duster\"], \"fol_rules\": [\n    \"‚àÄx (Suck(x) ‚Üí HouseholdAppliance(x)) ‚àß ¬¨Suck(plunger)\",\n  \"‚àÄx (Suck(x) ‚Üí HouseholdAppliance(x)) ‚àß ¬¨Suck(vacuum)\",\n  \"‚àÄx (Suck(x) ‚Üí HouseholdAppliance(x)) ‚àß ¬¨Suck(duster)\" , \"‚àÄx (Space(x) ‚àß Vacuum(space))\",\n    \"‚àÉx (Vampire(x) ‚àß Suck(space))\" ], \"fol_conc\": \"Space(x) ‚àß Vampire(x)\"}",
      "perplexity": 1.5627449750900269,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 137,
    "nl_problem": {
      "context": [
        "Plungers suck.",
        "Vacuums suck.",
        "Vampires suck.",
        "Space is a vacuum.",
        "A duster is a household appliance that doesn't suck."
      ],
      "question": "If something is a household appliance, it sucks.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Suck(x)\",\n    \"HouseholdAppliance(x)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (HouseholdAppliance(x) ‚Üí Suck(x))\",\n  ],\n  \"fol_conc\": \"‚àÉx (Suck(x) ‚àß HouseholdAppliance(x))\"\n}\n```",
      "perplexity": 1.1892337799072266,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 9 column 3 (char 151)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Suck(x)\", \"HouseholdAppliance(y)\"],\"fol_consts\":[\"plungers\", \"vacuums\", \"vampires\", \"space\", \"duster\"] , \"fol_rules\":[\"\"], \"fol_conc\":\"‚àÄx (HouseholdAppliance(x) ‚Üí Suck(x))\"} ",
      "perplexity": 1.7894078493118286,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Suck(x)\"], \"fol_consts\": [ \"household\", \"plunger\", \"vacuum\",\"duster\", \"vampire\", \"space\" ], \"fol_rules\": [ \"‚àÄx (HouseholdAppliance(x)) ‚Üí Suck(x)\", \"‚àÉx (Vampire(x) ‚àß Suck(x))\", \"Suck(household)\" ], \"fol_conc\": \"‚àÄx (HousehldAppliance(x) ‚Üí Suck(x))\" }",
      "perplexity": 2.011246681213379,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 138,
    "nl_problem": {
      "context": [
        "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.",
        "Unsupervised learning doesn't require labelled data.",
        "The state-of-the-art text summarization model is trained with machine learning algorithms.",
        "Reinforcement learning is not used to train the state-of-the-art text summarization model.",
        "The Machine Learning algorithm for training text summarization model requires labelled data."
      ],
      "question": "Supervised learning is used to train the state-of-the-art text summarization model.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n\"MLAlgorithm(x)\",\n\"SupervisedLearning(y)\",\n\"UnsupervisedLearning(z)\", \",\"\n  ] , \"\"\n    : \"ReinforcementLearning(w)\",\n \"TrainModel(x, y) \"\n     : \"UseLabeledData (x)\",\n  \"TextSummarizationModel(u)\"\n   : \"\"\n,\"StateOfTheArt(v)\"\n   : \"\", \"\"\n  : \"\" , \"\"\n   : []\n  }",
      "perplexity": 6.150611400604248,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 139,
    "nl_problem": {
      "context": [
        "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.",
        "Unsupervised learning doesn't require labelled data.",
        "The state-of-the-art text summarization model is trained with machine learning algorithms.",
        "Reinforcement learning is not used to train the state-of-the-art text summarization model.",
        "The Machine Learning algorithm for training text summarization model requires labelled data."
      ],
      "question": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 140,
    "nl_problem": {
      "context": [
        "If a cartoon character is funny, then it is popular.",
        "If a cartoon character is ugly, then it is not popular.",
        "If a cartoon character is loved by children, then it is funny.",
        "If a cartoon character is from The Simpsons, then it is loved by children.",
        "If a cartoon character is yellow, then it is from The Simpsons.",
        "Ben is either from The Simpsons or funny."
      ],
      "question": "Ben is loved by children.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Funny(x)\",\n    \"Popular(x)\",\n    \"Ugly(x)\",\n    \"LovedByChildren(x)\",\n    \"FromSimpsons(x)\",\n    \"Yellow(x)\"\n  ],\n  \"fol_consts\": [\n    \"ben\",\n    \"simpsons\" \n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Funny(x) ‚Üí Popular(x))\",\n    \"‚àÄx (Ugly(x) ‚Üí ¬¨Popular(x))\",\n    \"‚àÄx (LovedByChildren(x) ‚Üí Funny(x))\",\n    \"‚àÄx (FromSimpsons(x) ‚Üí LovedByChildren(x))\", \n    \"‚àÄx (Yellow(x) ‚Üí FromSimpsons(x))\",\n    \"‚àÉx (FromSimpsons(x) ‚à® Funny(x))\"\n  ],\n  \"fol_conc\": \"LovedByChildren(ben)\"\n}\n```",
      "perplexity": 1.0678433179855347,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"funny\", \"popular\", \"ugly\", \"lovedByChildren\" , \"fromTheSimpsons\"], \",\"\n  : [\"ben\"]\n,\"fol_rules\":[\n    \"‚àÄx (Funny(x) ‚Üí Popular(x))\",\n    \"‚àÄx (Ugly(x) ‚Üí ¬¨Popular(x))\",\n    \"‚àÄx (LovedByChildren(x) ‚Üí Funny(x))\", \",\"\n   \t, \"‚àÄx (fromTheSimpsons(x) ‚àß LovedByChildren(x))\", \",\" ,\"If x is from the Simpsons then x is loved by children\", 0], \",\"\n  : [ ], \"fol_conc\": \"LovedByChildren(ben)\" }",
      "perplexity": 3.3765058517456055,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 141,
    "nl_problem": {
      "context": [
        "If a cartoon character is funny, then it is popular.",
        "If a cartoon character is ugly, then it is not popular.",
        "If a cartoon character is loved by children, then it is funny.",
        "If a cartoon character is from The Simpsons, then it is loved by children.",
        "If a cartoon character is yellow, then it is from The Simpsons.",
        "Ben is either from The Simpsons or funny."
      ],
      "question": "Ben is ugly or yellow.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Funny(x)\",\n    \"Popular(x)\",\n    \"Ugly(x)\",\n    \"LovedByChildren(x)\",\n    \"FromTheSimpsons(x)\"\n  ],\n  \"fol_consts\": [\n    \"ben\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Funny(x) ‚Üí Popular(x))\",\n    \"‚àÄx (Ugly(x) ‚äï NotPopular(x))\",\n    \"‚àÄx (LovedByChildren(x) ‚àß Funny(x))\",\n    \"FromTheSimpsons(ben) ‚àß LovedByChildren(ben)\",\n    \"Yellow(ben) ‚Üí FromTheSimpsons(ben)\",\n  ],\n  \"fol_conc\": \"Ugly(ben) ‚à® Yellow(ben)\" \n}\n```",
      "perplexity": 1.195400357246399,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 18 column 3 (char 381)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Funny(x)\", \"Popular(x)\", \"Ugly(x)\", \"LovedByChildren(x)\", \"FromTheSimpsons(x)\", \"Yellow(x)\"], \"fol_consts\": [ \"Ben\" ], \"fol_rules\": [], \"fol_conc\": \"Ugly(ben) ‚à® Yellow(ben)\" }",
      "perplexity": 1.3835718631744385,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 142,
    "nl_problem": {
      "context": [
        "If a cartoon character is funny, then it is popular.",
        "If a cartoon character is ugly, then it is not popular.",
        "If a cartoon character is loved by children, then it is funny.",
        "If a cartoon character is from The Simpsons, then it is loved by children.",
        "If a cartoon character is yellow, then it is from The Simpsons.",
        "Ben is either from The Simpsons or funny."
      ],
      "question": "Ben is either yellow and ugly or neither yellow nor ugly.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\" llows for first order logic conversion, and it's crucial to understand the rules we need to follow. Here is a breakdown of the problem-solving process:  We will use predicate symbols (like \" :\"\", \"funny,\"\n   :\"popular\", \"loved by children\"\n    :\"from The Simpsons,\" , \"yellow,\" :\"\"\n    , \"is funny\"\n   :\") and constants for characters (e.g., \"\n    , \"Ben) to express our statements in a formal logic form:  Here's how we can translate the provided natural language into first-order logic:  We start by identifying predicates needed and defining them as logical formulas that describe what kind of things these concepts refer to 2. Then use those to formulate rules using the \"\n    :\"popular\", \":\" :\") symbols for quantifiers (‚àÄ,‚àÉ) in our system.\" } ",
      "perplexity": 14.329974174499512,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Funny(x)\", \"Popular(x)\", \"Ugly(x)\", \"LovedByChildren(x)\", \"FromTheSimpsons(x)\"], \"fol_consts\": [\"ben\"], \"fol_rules\": [\n    \"‚àÄx (Funny(x) ‚Üí Popular(x))\", \"‚àÄx (Ugly(x) ‚Üí ¬¨Popular(x))\",\n    \"‚àÄx (LovedByChildren(x) ‚Üí Funny(x))\", \"‚àÄx (FromTheSimpsons(x) ‚Üí LovedByChildren(x))\", \"‚àÄx (Yellow(x) ‚Üí FromTheSimpsons(x))\",\n    \"‚àÉx (FromTheSimpsons(x) ‚à® Funny(x))\"], \"fol_conc\": \"Yellow(ben) ‚äï Ugly(ben)\" }",
      "perplexity": 1.5665266513824463,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 143,
    "nl_problem": {
      "context": [
        "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.",
        "Heck cattle were bred-back in the 1920s to resemble the aurochs.",
        "[BG] Heck cattle are animals.",
        "[BG] Aurochs are animals.",
        "Some animals to be bred-back resemble animals that are extinct."
      ],
      "question": "Some Heck cattle are artificially selected.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"BreedingBack(x)\", \n    \"BredBackIn(x, y)\",\n    \"Animal(x)\" ,\n    \"ArtificiallySelected(x, y)\" \n  ],\n  \"fol_consts\": [\n    \"heck cattle\",\n    \"aurochs\"\n  ],\n  \"fol_rules\": [\n    \"BredBackIn(heckcattle,1920s) ‚Üí BreedingBack(heckcattle)\",\n    \"(Animal(Heck Cattle) ‚àß Animal(Aurochs))\",\n    \"ArtificiallySelected(x,y) ‚äï BredBackIn( Heck cattle, y)\"  \n   ],\n  \"fol_conc\": \"‚àÉx (BreedingBack(x))\"\n\n}\n```",
      "perplexity": 1.7138291597366333,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\" ingle: \"\n  \t  : [\n    \"BreedingBack(x)\",\n    \"ArtificialSelection(y, x)\",\n    \"Animal(x)\",\n    \"HeckCattle(x)\",\n    \"Aurochs(x)\"\n  ], \"\\n\\tfol_consts\": [\n    \"heckcattle\",\n    \"aurochs\"\n  ], \"\\n\\tfol_rules\":[\n    \"(BreedingBack(x) ‚Üí ArtificialSelection(x, x))\", 0\n]\n}",
      "perplexity": 3.6152679920196533,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n\"BreedBack(x)\",\n\"ArtificiallySelected(x)\" ,\n \"Animal(x)\",\n  \"ResemblesExtinct(x, y)\"], \n\"fol_consts\": [\n    \"heckcattle\",\n    \"aurochs\"\n], \n\"fol_rules\": [\n  \"BreedBack(heckcattle) ‚Üí ArtificiallySelected(heckcattle)\",\n   \"Animal(heckcattle) ‚àß Animal(aurochs) ‚Üí ResemblesExtinct(heckcattle, aurochs)\"\n  ], \n \"fol_conc\": \"ArtificiallySelected(someheckcattle)\" }",
      "perplexity": 1.8890951871871948,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 144,
    "nl_problem": {
      "context": [
        "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.",
        "Heck cattle were bred-back in the 1920s to resemble the aurochs.",
        "[BG] Heck cattle are animals.",
        "[BG] Aurochs are animals.",
        "Some animals to be bred-back resemble animals that are extinct."
      ],
      "question": "Aurochs are extinct.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n{\n  \"fol_preds\": [\n    \"BreedingBack(x)\",\n    \"Animals(x)\" \n  ],\n  \"fol_consts\": [\n    \"heck\", \"aurochs\"\n  ],\n  \"fol_rules\": [\n    \"breedingback(Heck, aurochs) ‚Üí (animals(Heck)) ‚àß (animals(aurochs))\",\n   ],\n  \"fol_conc\": \"aurochs are extinct\"\n\n} \n\n\n\n",
      "perplexity": 1.8536328077316284,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 11 column 4 (char 204)"
    },
    "logic_problem_json": {
      "raw": "{\" ¬†¬†¬†  \"\n   \t :\"+ { \" } ",
      "perplexity": 598.5481567382812,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"BredBack(x)\", \"Animal(x)\", \"Extinct(x)\"], \"fol_consts\": [\n\"heckcattle\",\n\"aurochs\",\n\"animals\"], \n\"fol_rules\": [\n\"‚àÄx (BredBack(x) ‚Üí Animal(x))\",\n\"¬¨(BredBack(heckcattle) ‚Üí Extincited(heckcattle))\",\n\"‚àÉx (BredBack(x) ‚àß Animal(x) ‚àß Extinct(aurochs))\" , \"Animal(aurochs)\", \"Extinct(aurochs)\" ],  \"fol_conc\": \"Extinct(aurochs)\"}",
      "perplexity": 1.900162935256958,
      "answer": "C",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 145,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Jerry is young.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Student(x)\", \"Human(x)\", \"Studies(x, y)\", \"Teaches(y)\"],\"fol_consts\": [\"Jerry\", \"Rose\"],\"fol_rules\": [\n  \"‚àÄx (Student(x) ‚àß Human(x))\",\n  \"‚àÄx (Studies(x, y) ‚Üí Student(x))\",\n  \"‚àÉx (Students(x) ‚äï Teaches(y))\",\n  \"¬¨Young(Y) ‚àß Teachs(X) ‚Üí ¬¨Y = X\",\n  \"(Jerry ‚àâ Teaching ‚àß Jerry ‚àâ Management) ‚Üí Young(Jerry)\" ,\n  \"Rose ‚äÜ Y or Student(Y)\",\n  \"‚àÄx (Students(X) ‚äï Teaches(y)) ‚â° ‚àÉx (Studies(x, y))\"\n], \"fol_conc\": \"Young(Jerry)\"}",
      "perplexity": 2.0125131607055664,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "¬¨Young(Y) ‚àß Teachs(X) ‚Üí ¬¨Y = X"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Student(x)\", \"Human(x)\", \"Studies(x)\", \"Teaches(x)\"], \"fol_consts\":[\"jerry\",\"rose\", \"young\"],  \"fol_rules\": [\n    \"‚àÄx (Student(x) ‚Üí Human(x))\", \"(Studies(x) ‚àß Student(x))\", \"(Teachs(x) ‚à® Studies(x))\", \"¬¨Young(x) ‚àß Teaches(x)\", \"(Jerry(x) ‚àß ¬¨Teaches(x)) ‚äï (Jerry(x) ‚àß ¬¨Manage(x))\", \"Rose(y) ‚à® Student(y)\"\n],  \"fol_conc\": \"Young(jerry)\" }",
      "perplexity": 2.050366163253784,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Jerry/1, Jerry/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Jerry/1, Jerry/0"
    }
  },
  {
    "id": 146,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Jerry is not young.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Human(x)\",\n    \"Studies(x)\",\n    \"Teaches(x)\",\n    \"Young(x)\" , \n    \"Student(x)\",\n    \"Manager(x)\" \n  ],\n  \"fol_consts\": [\n    \"jerry\",\n    \"rose\" \n  ],\n  \"fol_rules\": [\n   \"‚àÄx (Human(x) ‚Üí Student(x))\",\n    \"‚àÄx (Studies(x) ‚Üí Student(x))\",\n     \"‚àÄx (Teaches(x) ‚äï Studying(x))\", \n    \"¬¨Young(x) ‚àß Teachees(x)\",\n   \"(Not Young(Jerry) ‚àß Not Manager(Jerry))\" , \n  ],\n  \"fol_conc\": \"Not Young(Jerry)\" \n}\n```",
      "perplexity": 1.4348814487457275,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 20 column 3 (char 384)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Human\", \"Student\", \"Studies\", \"Teaches\", \"Young\"], \",\"\n   : \"fol_consts\" , \":[\"\n   : \"jerry\", \"rose\" :[], \"fol_rules\": [\n    \"‚àÄx (Human(x) ‚Üí Student(x)),\",\n    \"‚àÄx (Studies(x) ‚Üí Student(x))\",\n    \"‚àÉx (Teaches(x) ‚äï Studies(x))\",\n    \"¬¨Young(y) ‚àß Teachees(y)\",\n    \"¬¨Teach(Jerry) ‚àß ¬¨Manager(Jerry)\",\n    \"Rose ‚à® Student(Rose)\"\n  ], \"fol_conc\": \"¬¨Young(jerry)\"}",
      "perplexity": 2.6724865436553955,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "‚àÄx (Human(x) ‚Üí Student(x)),"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Human(x)\", \"Studies(x)\", \"Teahs(x)\", \"Young(x)\"], \"fol_consts\": [ \"jerry\", \"rose\" ], \"fol_rules\": [\n    \"‚àÄx (Student(x) ‚Üí Human(x))\",\n    \"‚àÄx (Studies(x) ‚àß Student(x))\",\n    \"‚àÉx (Teahs(x) ‚äï Studies(x))\",\n    \"¬¨Young(y) ‚àß Teahs(y)\",\n    \"¬¨Teach(j) ‚à® ¬¨Manager(j)\" ,\n    \"Young(rose) ‚à® Student(rose)\" ], \"fol_conc\": \"¬¨Young(jerry)\" }",
      "perplexity": 1.6228022575378418,
      "answer": "C",
      "predicted_answer": "A",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 147,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Rose is a human or a manager.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Student(x)\",\n    \"Human(x)\",\n    \"Studies(x)\",\n    \"Teaches(x)\",\n    \"Manager(x)\"\n  ],\n  \"fol_consts\": [\n    \"jerry\",\n    \"rose\" \n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Student(x) ‚Üí Human(x))\",\n    \"‚àÄx (Studies(x) ‚Üí Student(x))\",\n    \"‚àÉx (Teaches(x) ‚äï Studys(x))\",\n    \"¬¨Young(rose) ‚Üí Teachees(rose)\",\n    \"¬¨Young(jerry) ‚àß ¬¨Manager(jerry)\"\n  ],\n  \"fol_conc\": \"Rose ‚àà Human ‚à® Manager\"\n}\n```",
      "perplexity": 1.202061653137207,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "Rose ‚àà Human ‚à® Manager"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"Student(x)\",\n  \"Human(x)\",\n  \"Studies(x)\",\n  \"Teaches(x)\",\n  \"Manager(x)\"\n], \"fol_consts\": [\"Jerry\", \"Rose\"], \",\"\n  : \"fol_rules\" ,\n  \"[\\\\exists x (Student(x) ‚Üí Studies(x))]\"\n   : \"[Students] = [Human] || [Studies]\"\n   , \":[Youngs] = [Humans] && [Not Students]\" :\",[Manager]=[People] && [Teaching]\",\n  \"Jerry ‚àß Not Manager. \" : \"Rose ‚à® Student\", \",\" :\"fol_conc\" , \"Rose is a human or manager.\" :\"}\"}",
      "perplexity": 6.028706073760986,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Student(x)\", \"Human(x)\", \"Studies(x, y)\", \"Teaches(x)\"], \n\"fol_consts\": [\"jerry\", \"rose\"], \n\"fol_rules\": [\n    \"‚àÄx (Student(x) ‚Üí Human(x))\",\n    \"‚àÄx (Studies(x) ‚Üí Student(x))\",\n    \"‚àÉx (Teaches(x) ‚äï Studys(x))\",\n    \"¬¨Young(rose) ‚Üí Teacheing(rose)\",\n    \"¬¨Teaching(jerry) ‚à® ¬¨Mananger(jerry)\" , \"RoseStudent(rose, student)\"\n], \n\"fol_conc\": \"RoseHumanOrManager(rose)\"\n}",
      "perplexity": 1.7967300415039062,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "'NoneType' object has no attribute 'rstrip'"
    }
  },
  {
    "id": 148,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "Rose is a human or Jerry is a manager.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Student(x)\",\n    \"Human(x)\",\n    \"Studies(x)\",\n    \"Teaches(x)\",\n    \"Manager(x)\"\n  ],\n  \"fol_consts\": [\n    \"Jerry\",\n    \"Rose\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"Human(rose) ‚à® Manager(jerry)\"\n}\n```",
      "perplexity": 1.1216384172439575,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Student\", \"Human\", \"Studies\", \"Teaches\"], \",\"\n  :[\"Jerry\" , \"Rose\"] , \"fol_consts\": [], \",\"\n   : \"students, humans, managers\" ,\"fol_rules\":[\n    \"‚àÄx (Student(x) ‚Üí Human(x))\", \",\"\n    ,\"‚àÄx (Studies(x) ‚Üí Student(x))\", \"¬¨(Teaches(x) ‚à® Teachs(x))\", 0,\"Jerry is a manager, then Jerry is not a student or Teaches(j)\",\n    \"Rose is young ‚à® Rose is a student\",\"None of these can be true at the same time.  This statement could lead to a logical contradiction.\" ] , \"fol_conc\": \"Rose is a human or Jerry is a manager\"} ",
      "perplexity": 4.506725311279297,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Human(x)\", \"Student(x)\", \"Studies(x)\", \"Teaches(x)\", \"Manager(x)\"],  \"fol_consts\": [\"rose\", \"jerry\"], \"fol_rules\": [\n    \"‚àÄx (Human(x) ‚àß Student(x))\",\n    \"‚àÄx (Studies(x) ‚Üí Student(x))\",\n    \"‚àÉx (Studes(x) ‚à® Teaches(x))\",\n    \"¬¨Young(y) ‚Üí Teaches(y)\",\n    \"¬¨Teaches(x) ‚àß ¬¨Manager(x)\" , \"Student(x) ‚à® Young(x)\"\n],  \"fol_conc\": \"RoseHumanOrJerryManager(rose, jerry)\" }",
      "perplexity": 1.7302165031433105,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 149,
    "nl_problem": {
      "context": [
        "All students are humans. ",
        "If someone studies, then they are a student.",
        "A person either studys or teaches.",
        "No young person teaches.",
        "Jerry neither teaches nor is a manager.",
        "Rose is young or a student."
      ],
      "question": "It is not true that Rose is a student and Jerry is a human.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"student\",\n    \"human\",\n    \"studies\",\n    \"teaches\",\n    \"young\" \n  ],\n  \"fol_consts\": [\n    \"jerry\",\n    \"rose\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (student(x) ‚Üí human(x))\",\n    \"‚àÄx (studies(x) ‚Üí student(x))\",\n    \"‚àÉx (studys(x) ‚äï teaches(x))\",\n    \"¬¨young(j) ‚à® teach(j)\",\n    \"¬¨teach(j) ‚àß ¬¨manager(j)\",\n    \"rose ‚à® student(r)\"\n  ],\n  \"fol_conc\": \"not (student(r) and human(jerry))\" \n}\n```",
      "perplexity": 1.247185230255127,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "rose ‚à® student(r)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Human(x)\", \"Student(x)\", \"Studies(x)\", \"Teaches(x)\", \"Manager(x)\"],\"fol_consts\":[\"Jerry\", \"Rose\"],\"fol_rules\":[\n  \"‚àÄx (Human(x) ‚àß Student(x)) ‚Üí Studies(x)\",\n  \"‚àÉx (Studied(x) ‚äï Teaches(x))\",\n  \"¬¨Young(x) ‚àß Teaches(x) ‚Üí False\",\n  \"¬¨Young(Jerry) ‚àß ¬¨Manager(Jerry)\" ,\n  \"(Young(Rose) ‚à® Student(Rose))\",\n \"Not (Student(Rose) ‚àß Human(Jerry))\"],\"fol_conc\":\"False\"}",
      "perplexity": 1.682162880897522,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "¬¨Young(x) ‚àß Teaches(x) ‚Üí False"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Student(x)\", \"Human(x)\", \"Studies(x)\", \"Teaches(x)\", \"Manager(x)\"], \"fol_consts\": [\"jerry\", \"rose\"], \"fol_rules\": [\n    \"‚àÄx (Student(x) ‚àß Human(x))\", \"Study(x) ‚Üí Student(x)\", \"Some(x) ‚Üí Not(student, x)\", \"NoYoung(y) ‚Üí NoTeacher(y)\", \"NotTeachOrManager(j) ‚Üí (Teaching(j) ‚à® Management(j))\",\n    \"RoseStudent(r) ‚à® RoseHuman(r)\",\n  \"¬¨(Study(jerry) ‚àß Student(jerry) ‚àß Human(jerry))\"], \"fol_conc\": \"¬¨(RoseStudent(rose) ‚àß JerryIsHuman(jerry))\"}",
      "perplexity": 2.2208476066589355,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Student/1, Student/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Student/1, Student/0"
    }
  },
  {
    "id": 150,
    "nl_problem": {
      "context": [
        "New Vessel Press is a publishing house which specializes in translating foreign literature into English.",
        "All of New Vessel Press's published books are in English.",
        "Neapolitan Chronicles is a book published by New Vessel Press.",
        "Neapolitan Chronicles was translated from Italian.",
        "Palace of Flies is a book published by New Vessel Press."
      ],
      "question": "Neapolitan Chronicles is an English book.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"PublishingHouse(x)\",\n    \"TranslatesToEnglish(x, y)\",\n    \"PublishedBook(x)\",\n    \"IsInEnglish(y)\" \n  ],\n  \"fol_consts\": [\n    \"NewVesselPress\",\n    \"NeapolitanChronicles\",\n    \"PalaceofFlies\"\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"IsInTheEnglish(Neapolitan Chronicles)\"\n}\n```",
      "perplexity": 1.44345223903656,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"Publish(x, y)\", \"TranslateFrom(y, z)\", \"IsBook(z)\", \"IsEnglish(z)\" ],\n\"fol_consts\": [\"NewVesselPress\", \"NeapolitanChronicles\", \"PalaceOfFlies\"], \",\"\n  \t  : [\n    \"‚àÄx (Publish(x, NewVesselPress) ‚Üí IsBook(x))\",\n    \"TranslateFrom(Italian, NeapolitanChronicles)\",\n    \"IsEnglish(NeapolitanChronicles)\" ,\n   \"‚àÄx (IsEnglish(PalaceOfFlies))\", 2 ]\n  }\n",
      "perplexity": 3.2525413036346436,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n  \"Published(x)\", \"TranslatedFrom(y, z)\",\"EnglishBook(y)\"\n], \"fol_consts\":[\n  \"newvesselpress\",\n  \"neapolitanchronicles\",\n  \"palaceofflies\"\n], \"fol_rules\": [\n  \"‚àÄx (Published(x) ‚Üí EnglishBook(x))\", \"(TranslatedFrom(x, y) ‚àß Published(y) ‚Üí EnglishBook(y))\"\n], \"fol_conc\": \"EnglishBook(neapolitanchronicles)\" }",
      "perplexity": 2.6324386596679688,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 151,
    "nl_problem": {
      "context": [
        "New Vessel Press is a publishing house which specializes in translating foreign literature into English.",
        "All of New Vessel Press's published books are in English.",
        "Neapolitan Chronicles is a book published by New Vessel Press.",
        "Neapolitan Chronicles was translated from Italian.",
        "Palace of Flies is a book published by New Vessel Press."
      ],
      "question": "Harry Potter was published by New Vessel Press.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"PublishedBy(x, y)\", \", \"\n  , \"TranslatesFrom(x, y)\", \", \"\n  , \"Book(x)\", \",\"\n  , \"EnglishPublication(y)\", \",\"\n], \"fol_consts\": [\"New Vessel Press\"], \"fol_rules\": [\n  \"‚àÄ x (PublishedBy(x, NewVesselPress) ‚Üí EnglishPublication(x))\", 0\n  , \"AllBooksTranslatesFrom(x, y) ‚Üí Book(x)\"\n] , \"fol_conc\": \"EnglishPublication(Harry Potter)\" }",
      "perplexity": 3.0854289531707764,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Publish(x, y)\", \"TranslatesFrom(x, y)\", \"PublishedBy(x, y)\"], \n\"fol_consts\": [\"newvesselpress\", \"harrypotter\",\"neapolitanchronicles\", \"palaceofflies\", \"english\"], \n\"fol_rules\": [\n    \"‚àÄy (Publish(y, newvesselpress) ‚Üí PublishedBy(y, newvesselpress))\",\n    \"PublishedBy(newvesselpress, neapolitanchronicles)\", \"TranslatesFrom(neapolitanchronicles, italian)\"\n], \"fol_conc\": \"Publish(harrypotter, newvesselpress)\"\n}",
      "perplexity": 2.0100479125976562,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 152,
    "nl_problem": {
      "context": [
        "New Vessel Press is a publishing house which specializes in translating foreign literature into English.",
        "All of New Vessel Press's published books are in English.",
        "Neapolitan Chronicles is a book published by New Vessel Press.",
        "Neapolitan Chronicles was translated from Italian.",
        "Palace of Flies is a book published by New Vessel Press."
      ],
      "question": "Palace of Flies was translated from Italian.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"isPublishedBy(x, y)\",\n    \"publishedInLanguage(y)\", \n    \"translatedFrom(x, y)\" \n  ],\n  \"fol_consts\": [\n    \"NewVesselPress\",\n    \"NeapolitanChronicles\",\n    \"PalaceofFlies\",\n    \"Italian\"\n  ],\n  \"fol_rules\": [\n    \"isPublishedBy(NewVesselPress, NewVesselPress)\",\n    \"publishedInLanguage(NeapolitanChronicles) ‚Üí publishedInLanguage(English)\", \n    \"translatedFrom(NeapolitanChronicles, Italian)\" ,\n  ],\n  \"fol_conc\": \"translatedFrom(PalaceofFlies, Italian)\"\n}\n```",
      "perplexity": 1.2982449531555176,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 17 column 3 (char 425)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"PublishedBy\", \"TranslatedFrom\"], \"fol_consts\": [\"NewVesselPress\", \"NeapolitanChronicles\", \"PalaceOfFlies\", \"English\", \"Italian\"], \"fol_rules\": [], \"fol_conc\": \"TranslatedFrom(PalaceOfFlies, Italian)\"}\n",
      "perplexity": 1.5828633308410645,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"PublishedBy(x, y)\", \"TranslatedFrom(x, y)\", \"WrittenIn(x, y)\"], \n\"fol_consts\": [\n  \"newvesselpress\", \"neapolitanchronicles\", \"palaceofflies\" ], \n\"fol_rules\": [\n  \"(PublishedBy(newvesselpress, x) ‚Üí WrittenIn(x, english))\",\n  \"NewVesselPress(x)\" , \"(TranslatedFrom(y, z) ‚àß PublishedBy(z, x)) ‚äï (WrittenIn(z, english) ‚àß PublishedBy(z, newvesselpress))\",\n  \"(PublishedBy(newvesselpress, y) ‚à® TranslatedFrom(y, italian))\" ], \n \"fol_conc\": \"(TranslatedFrom(palaceofflies, italian))\" }",
      "perplexity": 2.4257588386535645,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 153,
    "nl_problem": {
      "context": [
        "If people own a large desktop monitor at their home, then they work regularly and often at home.",
        "All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.",
        "All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.",
        "All people who work regularly and often at home visit the office supply store regularly.",
        "If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. ",
        "Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home. "
      ],
      "question": "Remy visits the office supply store regularly.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [ \"OwnDesktopMonitor\", \"WorkRegularlyAndOftenAtHome\", \"StockedAndImpressiveHomeOffice\", \"VisitOfficeSupplyStore\", \"SpendFreeTimeTidyingOrganizingSpacesInHome\",\"GoBedLateWakeUpNoonOrLater\", \"BeBusy\" ],\n  \"fol_consts\": [ \"remy\"],\n  \"fol_rules\": [], \",\"\n  :\n    \"‚àÄx (OwnDesktopMonitor(x) ‚Üí WorkRegularlyAndOftenAtHome(x))\",\n    \"‚àÄx (StockedAndImpressiveHomeOffice(x) ‚Üí OwnDesktopMonitor(x))\"\n     : \"WorkRegularlyAndOftenAtHome(remy)\", \",\"\n   :\n   \":  \" ,\n  \"fol_conc\": \"BeBusy(Remy)\" }",
      "perplexity": 2.889055013656616,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 154,
    "nl_problem": {
      "context": [
        "If people own a large desktop monitor at their home, then they work regularly and often at home.",
        "All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.",
        "All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.",
        "All people who work regularly and often at home visit the office supply store regularly.",
        "If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. ",
        "Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home. "
      ],
      "question": "Remy has a fully stocked and impressive home office and also visits the office supply store regularly.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 155,
    "nl_problem": {
      "context": [
        "If people own a large desktop monitor at their home, then they work regularly and often at home.",
        "All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.",
        "All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.",
        "All people who work regularly and often at home visit the office supply store regularly.",
        "If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. ",
        "Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home. "
      ],
      "question": "If Remy either goes to bed late and wakes up every day after noon or visits the office supply store regularly, then Remy neither spends their free time tidying and organizing the spaces in their home nor has a fully stocked and impressive home office.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Owns(x, y)\", \"WorksRegularlyAndOftenAtHome\", \"HasImpressiveHomeOffice\", \"SpendsFreeTimeTidyingAndOrganizingSpaces\", \"VisitsOfficeSupplyStore\", \"GoesToBedLate\", \"WakesUpEveryDayAfterNoon\"],\"fol_consts\":[ \"remy\"] , \"fol_rules\": [\"\"], \"fol_conc\": \"\" }\n",
      "perplexity": 1.8269823789596558,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 156,
    "nl_problem": {
      "context": [
        "All humans are mortal.",
        "All Greeks are humans."
      ],
      "question": "Some Greeks are mortal.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Human(x)\",\n    \"Mortal(x)\" ,\n    \"Greek(x)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [],\n  \"fol_conc\": \"‚àÉx (Greek(x) ‚àß Mortal(x))\" \n}\n```",
      "perplexity": 1.1783685684204102,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"Human(x)\",\n  \"Mortal(x)\"\n], \"fol_consts\": [ 0 ], \"}\\n\\n{ \\n\\\"fol_rules\\\": [\\n \\\"‚àÄx (Human(x) ‚Üí Mortal(x))\\\", \\n  \\\"\"\n    \t:\"‚àÄx (Greeks(x) ‚àß Human(x))\" , \"\\\"],\\n\"\n   \t :\"+ \"\n } ",
      "perplexity": 5.559216022491455,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n  \"Human(x)\", \"Mortal(x)\" , \"Greek(x)\" ], \n  \"fol_consts\": [\n    \"humans\", \"greeks\"], \n  \"fol_rules\": [\n    \"‚àÄx (Human(x) ‚Üí Mortal(x))\", \"‚àÄx (Greeks(x) ‚àß Human(x))\",\n    \"‚àÉx (Greeks(x) ‚àß Mortal(x))\", \"(AllHumans(humans)) ‚äï AllGreeks(greeks)\"\n  ], \n  \"fol_conc\": \"‚àÉx (Greeks(x) ‚àß Mortal(x))\"\n}",
      "perplexity": 2.4580650329589844,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Greeks/1, Greeks/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Greeks/1, Greeks/0"
    }
  },
  {
    "id": 157,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "James has a part-time job offered by the university.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 158,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "James does not have a part-time job offered by the university.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 159,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "James either takes the database course or has a part-time job offered by the university.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Student(x)\", \"WorksInLibrary(y)\", \"CSDepartment(z)\", \"PartTimeJobOfferedByUniversity(w)\"], \"fol_consts\": [\"James\", \"Jack\"], \"fol_rules\":[\"\"], \"fol_conc\":\"‚àÉx (TakeDatabaseCourse(x) ‚à® PartTimeJobOfferedByUniversity(j))\"}\n",
      "perplexity": 2.276130437850952,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 160,
    "nl_problem": {
      "context": [
        "No students who work in the library are from the computer science department. ",
        "All students who have part-time jobs offered by the university are students who work in the library. ",
        "All students who take the database course are from the computer science department. ",
        "All students instructed by professor David are taking the database course. ",
        "All students working in the lab are instructed by professor David. ",
        "James is a student working in the lab. ",
        "Jack neither has a part-time job offered by the university nor works in the lab. "
      ],
      "question": "Jack takes the database course.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 161,
    "nl_problem": {
      "context": [
        "If George likes music, he wants to compose.",
        "If George has access to a program, he can compose.",
        "If George can compose and wants to compose, he will compose."
      ],
      "question": "If George likes music and has access to a program, he will compose.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"LikeMusic(x)\",\n    \"CanCompose(x)\",\n    \"WantToCompose(x)\",\n    \"Compose(x)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n   \"‚àÄx (LikeMusic(x) ‚Üí CanCompose(x))\",\n   \"‚àÄx (CanCompose(x) ‚àß WantToCompose(x) ‚Üí Compose(x))\"\n  ],\n  \"fol_conc\": \"If George likes music and has access to a program, he will compose.\"\n\n}\n```",
      "perplexity": 1.2733312845230103,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "If George likes music and has access to a program, he will compose."
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"LikesMusic(x)\", \"Composes(x)\", \"HasAccess(x, y)\"], \"fol_consts\": [\"george\", \"program\"],\"fol_rules\": [], \"fol_conc\": \"If george likes music and has access to a program, he will compose.\" } ",
      "perplexity": 1.8559141159057617,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "If george likes music and has access to a program, he will compose."
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [ \"Likes(x, y)\", \"Composes(x)\", \"HasAccess(x, y)\" ], \"fol_consts\": [\"george\"], \"fol_rules\": [ \"‚àÄx (Likes(x, music) ‚àß HasAccess(x, program)) ‚Üí Composes(x)\", \"If(likesmusic, compomise) ‚Üí If(hasaccess, compose) ‚Üí If(compoese, likesmusic)\" ],  \"fol_conc\": \"Composes(george)\" }",
      "perplexity": 2.1284990310668945,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 162,
    "nl_problem": {
      "context": [
        "If George likes music, he wants to compose.",
        "If George has access to a program, he can compose.",
        "If George can compose and wants to compose, he will compose."
      ],
      "question": "If George will not compose, George can not compose.",
      "options": [],
      "answer": "C"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Likes(x, y)\",\n    \"Composes(x)\",\n    \"HasAccess(x, y)\"\n  ],\n  \"fol_consts\": [\n    \"George\",\n    \"music\", \n    \"program\"\n  ],\n  \"fol_rules\": [\n    \"‚àÄx (Likes(x, music) ‚Üí Composes(x))\",\n    \"‚àÄx (HasAccess(x, program) ‚Üí Composes(x))\",\n    \"(Composes(x) ‚àß WantsToCompose(x)) ‚Üí Composes(x)\",\n    \"¬¨Composes(x) ‚Üí ¬¨CanCompose(x)\"  \n  ],\n  \"fol_conc\": \"Cannot Compose(George)\"\n}\n```",
      "perplexity": 1.2291083335876465,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Likes\", \"Composes\", \"AccessesProgram\"], \"fol_consts\": [\"George\"], \"fol_rules\": [], \"fol_conc\": \"\"\n}",
      "perplexity": 2.17045521736145,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Likes(x, y)\", \"CanCompose(x)\", \"WantToCompose(x)\"], \"fol_consts\": [ \"george\" ],  \"fol_rules\": [\n    \"‚àÄx (Likes(x, music) ‚Üí CanCompose(x))\",\n    \"‚àÄx (AccessToProgram(x) ‚àß CanCompose(x) ‚Üí WantToCompose(x))\", \"(CanCompose(x) ‚àß WantToCompose(x)) ‚Üí Compose(x)\",\n    \"¬¨(Compose(x) ‚à® WantToCompose(x)) ‚Üí ¬¨CanCompose(x)\" ], \"fol_conc\": \"CanCompose(george)\"}",
      "perplexity": 1.7467881441116333,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 163,
    "nl_problem": {
      "context": [
        "A hawk never lands. ",
        "Some birds are hawks."
      ],
      "question": "All birds land",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Hawk(x)\",\n    \"Land(x)\" ,\n    \"Bird(x)\" \n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [],\n  \"fol_conc\": \"‚àÄx (Bird(x) ‚Üí Land(x))\"\n}\n\n```",
      "perplexity": 1.2464889287948608,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n    \"Hawk(x)\", \",\"\n  ], \"fol_consts\": [], \"fol_rules\": [], \"fol_conc\": \"\" }",
      "perplexity": 3.938260316848755,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"Land(x)\", \"Hawk(x)\", \"Bird(x)\"], \"fol_consts\": [ \"hawk\", \"birds\" ], \"fol_rules\": [\n    \"‚àÄx (¬¨Hawk(x) ‚Üí ‚àÉy (Land(y)))\",\n    \"‚àÉx (Bird(x) ‚àß Hawk(x))\",\n    \"AllBirdsLand(bird)\" ],  \"fol_conc\": \"AllBirdsLand(birds)\"}",
      "perplexity": 2.149888277053833,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "execution error",
      "error": "(FATAL)\n%%ERROR: The following symbols are used with multiple arities: Bird/1, Bird/0.\n\n\nFatal error:  The following symbols are used with multiple arities: Bird/1, Bird/0"
    }
  },
  {
    "id": 164,
    "nl_problem": {
      "context": [
        "On some Mondays at 8 pm, roses are given out on TV.",
        "Every rose given out on TV is on the Bachelor.",
        "Everything on the Bachelor portrays the lives of real people.",
        "All shows portraying the lives of real people are reality TV shows.",
        "Breaking Bad is not a reality TV show."
      ],
      "question": "Breaking Bad is on Monday at 8 pm.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"GiveOutTV(x, y)\",\n  \"OnTheBachelor(y)\",\n  \"PortraysLivesRealPeople(x)\",\n  \"RealityShow(x)\",\n  \"BreakingBadIsNotRealityShow(x)\"\n], \"\\n\" :\"fol_consts\" , \"breakingbad\\n\" : [\n    \"monday at 8 pm\",\n  \"], \\n\"\n   ,\"fol_rules\" , [\"‚àÄx (GiveOutTV(x, tv) ‚Üí OnTheBachelor(y)) \\n\" ,\n    \"\\t‚àÉx (PortraysLivesRealPeople(x) ‚àß RealityShow(x))\"] ] }",
      "perplexity": 3.7150630950927734,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"GivenOutOnTV(x)\", \"IsOnTheBachelor(x)\", \"PortraysRealLives(x)\", \"RealityShow(y)\"], \n\"fol_consts\":[\"breakingbad\",\"monday\", \"8pm\"], \n\"fol_rules\": [\n    \"‚àÄx (GivenOutOnTV(x) ‚Üí IsOnTheBachelor(x))\", \"(IsOnTheBachelor(x) ‚àß PortraysRealLives(x) ‚àß RealityShow(y)) ‚Üí RealityShow(y)\", \"(RealityShow(y) ‚àß NotBreakingBad(y))\", \"NotBreakingBad(y)\"\n], \n\"fol_conc\": \"GivenOutOnTV(breakingbad)\"}",
      "perplexity": 1.954160213470459,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 165,
    "nl_problem": {
      "context": [
        "On some Mondays at 8 pm, roses are given out on TV.",
        "Every rose given out on TV is on the Bachelor.",
        "Everything on the Bachelor portrays the lives of real people.",
        "All shows portraying the lives of real people are reality TV shows.",
        "Breaking Bad is not a reality TV show."
      ],
      "question": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"TVShow(x)\", \n    \"RosesGivenOutOnTV(x, y)\",\n    \"Bachelor(x)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [\n    \"‚àÄx (TVShow(x) ‚Üí RosesGivenOutOnTV(x, Monday at 8 pm))\",\n    \"‚àÄx (RosesGivenOutOnTV(x, Bachelor) ‚àß EveryRoseGivenoutOnTV(Bachelor))\",\n    \"EveryRoseGivenoutOnTV(Bachelor) ‚Üí EverythingIsRealityTVShow(Bachelor)\",\n    \"EverythingIsRealityTVShow(Bachelor) ‚äï NotRealtyTVshow(BreakingBad)\",\n  ],\n  \"fol_conc\": \"Not TV show in which roses are given out on Monday at 8 pm is Breaking Bad.\"\n}\n```",
      "perplexity": 1.6350072622299194,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 13 column 3 (char 419)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"TVShow(x)\", \"RoseGivenOutOnTV(x, y)\", \"RealityTVshow(x)\", \"BacheloretteParty(y)\"],\"fol_consts\":[\"BreakingBad\",\"Monday\",\"8pm\"] , \"fol_rules\": [\n  \"‚àÉx (TVShow(x) ‚àß RoseGivenOutOnTV(x,\" ], \",\" :[], \"fol_conc\":\"\\n\"}",
      "perplexity": 4.111120223999023,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "‚àÉx (TVShow(x) ‚àß RoseGivenOutOnTV(x,"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"TVShow(x)\", \"RosesGivenOutOn(y, x)\"], \"fol_consts\": [\"breakingbad\", \"monday\", \"8pm\"], \"fol_rules\":[\n\"‚àÄx (TVShow(x) ‚Üí RosesGivenOutOn(tvshow, x))\", \"(RoseGivesOut(tvrealitytv, tvshows) ‚äï (RosesGivenOutOn(tvseries, tvrealitytv)))\" , \"(RealityTVShow(tvrealitytv) ‚Üí TVShowsAreRealPeopleLife(tvrealitytv))\", \"BreakingBadIsATVShow(breakingbad)\",\n  \"ForSomeMondayAt8pmRoseGiveoutTvShowExists(breakingbad)\" ], \"fol_conc\": \"BreakingBadIsATVshowInWhichRosesGivenOutOnMondayat8pmbreakingsBadTVShowExists(breakingbad)\"}",
      "perplexity": 3.721248149871826,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 166,
    "nl_problem": {
      "context": [
        "On some Mondays at 8 pm, roses are given out on TV.",
        "Every rose given out on TV is on the Bachelor.",
        "Everything on the Bachelor portrays the lives of real people.",
        "All shows portraying the lives of real people are reality TV shows.",
        "Breaking Bad is not a reality TV show."
      ],
      "question": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"GiveOut(x, y)\", \", ‚àÉx (TVShow(y) ‚Üí GiveOut(x, TVShow(y))), \" ,\n  \"OnMondayAtEightPm(x, y)\", \"EveryRoseGivenout(x)\",\n   \"Bachelor(x)\",\n  \"RealityTVShow(x)\",\n  \"BadIsNot(x)\" ], \"\"\n    : [ 2,\n  \"GiveOut\",\n  \"OnMondayAtEightpm\",\n  \"Roses Given Out\",\n \"Bachelors Shows\",\n\"Real People Portrays\", 2], \"\"\n    : [\"on_monday_8PM.tv\", \"roses\"], \"\"\n   : [ ], \"\"\n    : \"\",\"BachelorShow(x) is a show on the Bachelor that portrays real people, RealityTVshow(y)\" :\"\"}",
      "perplexity": 7.587700843811035,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"GivenOutOnTV(x)\", \"IsOnTheBachelor(x)\", \"PortraysRealLives(x)\", \"RealityShow(x)\", \"BreakingBad(y)\"],  \"fol_consts\":[ \"monday\", \"8pm\", \"roses\"], \"fol_rules\": [\n    \"‚àÄt (GivenOutOnTV(roses) ‚àß IsOnTheBachelor(x)) ‚Üí RealityShow(x)\",\n    \"‚àÄt (RealityShow(x) ‚àß NotBreakingBad(y)) ‚Üí GivenOutOnTV(y)\",\n    \"NotRealLife(y) ‚äï RealLife(y)\"\n], \"fol_conc\": \"IfGivenOutOnTV(roses) ‚àß IsOnTheBachelor(rose) ‚àß MondayAt8PM(x) ‚àß NotBreakingBad(x) ‚àß RealityShow(x) ‚àß GivenOutOnTV(rose)\"}",
      "perplexity": 2.2255516052246094,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 167,
    "nl_problem": {
      "context": [
        "Heinrich Scmidt was a Nazi German politician. ",
        "Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag."
      ],
      "question": "Heinrich Schmidt was either German or Russian.",
      "options": [],
      "answer": "A"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"NaziGermanPolitician(x)\",\n    \"MemberPrussianStateParliament(x)\",\n    \"MemberNaziReichstag(x)\", \n    \"German(x)\",\n    \"Russian(x)\"\n  ],\n  \"fol_consts\": [\n    \"HeinrichSchmidt\",\n  ],\n  \"fol_rules\": [],\n  \"fol_conc\": \"‚àÉx (NaziGermanPolitician(x) ‚à® German(x))\"\n}\n\n```",
      "perplexity": 1.278273344039917,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "json error",
      "error": "Expecting value: line 11 column 3 (char 203)"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"German\", \"Russian\", \"Nazi\", \"Member\", \"Politician\"], \",\"\n  : [ ]\n  ,\n\"fol_consts\": [\"Heinrich Schmidt\"] ,\n\"fol_rules\": [],\n\"fol_conc\": \" German ‚à® Russian\"\n} ",
      "perplexity": 4.092769622802734,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "German ‚à® Russian"
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\n    \"Politician(x)\", \"MemberOfParliament(y)\", \"NaziReichstag(z)\", \"German(a)\", \"Russian(b)\"\n  ],  \"fol_consts\": [\"heinrichscmidt\"], \n   \"fol_rules\": [\n     \"‚àÄx (Politician(x) ‚Üí MemberOfParliament(x))\",\n     \"‚àÄx (MemberOfParliament(x) ‚àß NaziReichstag(x) ‚Üí Politician(x))\",\n    \"‚àÄx ((German(x) ‚à® Russian(x)) ‚Üí Politician(x))\"\n   ], \"fol_conc\": \"Politician(heinrichscmidt)\"}",
      "perplexity": 2.240954875946045,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 168,
    "nl_problem": {
      "context": [
        "Heinrich Scmidt was a Nazi German politician. ",
        "Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag."
      ],
      "question": "Some Nazi German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
      "options": [],
      "answer": "A"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"NaziGermanPolitician\", \"MemberPrussianStateParliament\", \"MemberNazistReichstag\"], \",\"\n  \t  :\"HeinrichScmidt\" ,\n    \"FOL_consts\":[ \"Henrich Scmidt\" ],\n\"fol_rules\": [\"\"],\n   \"fol_conc\": \"\"\n}\n",
      "perplexity": 5.390170097351074,
      "answer": "A",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    },
    "logic_problem_gcd": {
      "raw": "{\"fol_preds\": [\"NaziGermanPolitician(x)\", \"MemberOf(x, y)\"], \n\"fol_consts\": [ \"heinrichscmidt\", \"prussianstateparliament\", \"nazistreich\"], \n\"fol_rules\": [\n  \"(NaziGermanPolitician(hscmidt) ‚Üí MemberOf(hscmidt, prussianstateparliament))\",\n  \"(NaziGermanPolitician(hscmidt) ‚Üí MemberOf(hscmidt, nazistreich))\" ], \n \"fol_conc\": \"(MemberOf(hscmidt, prussianstateparliament) ‚àß MemberOf(hscmidt, nazistreich))\" }",
      "perplexity": 1.9882292747497559,
      "answer": "A",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 169,
    "nl_problem": {
      "context": [
        "Heinrich Scmidt was a Nazi German politician. ",
        "Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag."
      ],
      "question": "No politicans are part of the Nazi Reichstag.",
      "options": [],
      "answer": "B"
    },
    "logic_problem": {
      "raw": "\n```json\n{\n  \"fol_preds\": [\n    \"Politician(x)\",\n    \"MemberOfParliament(x, y)\",\n    \"NaziReichstag(x)\"\n  ],\n  \"fol_consts\": [],\n  \"fol_rules\": [],\n  \"fol_conc\": \"¬¨‚àÄx (MemberOfParliament(x, NaziReichstag))\"\n}\n```",
      "perplexity": 1.2111687660217285,
      "answer": "B",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"politician\", \"member\"],\n\"fol_consts\": [\"Heinrich Scmidt\"], \",\"\n  \t  :\n  \"fol_rules\"\n    , \"\\n\" :\"‚àÄx (member(x) ‚Üí politician(x))\", \":\"\n  \t\t:\n   [\n   \"\"] , \"None\"\n   :\n \"\"\n }",
      "perplexity": 9.91392993927002,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  },
  {
    "id": 170,
    "nl_problem": {
      "context": [
        "If something is a deadly disease, then its survival rate is low. ",
        "All severe cancers are deadly diseases.",
        "Bile duct cancer is a severe cancer. ",
        "All Cholangiocarcinoma is bile duct cancer.",
        "No one with mild flu has a low survival rate.",
        "If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer."
      ],
      "question": "Colorectal cancer is a severe cancer",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 171,
    "nl_problem": {
      "context": [
        "If something is a deadly disease, then its survival rate is low. ",
        "All severe cancers are deadly diseases.",
        "Bile duct cancer is a severe cancer. ",
        "All Cholangiocarcinoma is bile duct cancer.",
        "No one with mild flu has a low survival rate.",
        "If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer."
      ],
      "question": "If colorectal cancer is a bile duct cancer or a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer and a mild flu.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 172,
    "nl_problem": {
      "context": [
        "If something is a deadly disease, then its survival rate is low. ",
        "All severe cancers are deadly diseases.",
        "Bile duct cancer is a severe cancer. ",
        "All Cholangiocarcinoma is bile duct cancer.",
        "No one with mild flu has a low survival rate.",
        "If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer."
      ],
      "question": "If colorectal cancer is not a mild flu and a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer or a Cholangiocarcinoma.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 173,
    "nl_problem": {
      "context": [
        "All people who eat salads regularly are very conscious about their health and eating habits.",
        "All people who grew up in health-conscious childhood homes eat salads regularly.",
        "All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.",
        "If people have good relationships with their parents, then they fulfill their nutritional daily intakes.",
        "If people have good relationships with their parents, then they do not eat salads regularly.",
        "If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.",
        "It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents."
      ],
      "question": "Taylor eats salads regularly.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 174,
    "nl_problem": {
      "context": [
        "All people who eat salads regularly are very conscious about their health and eating habits.",
        "All people who grew up in health-conscious childhood homes eat salads regularly.",
        "All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.",
        "If people have good relationships with their parents, then they fulfill their nutritional daily intakes.",
        "If people have good relationships with their parents, then they do not eat salads regularly.",
        "If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.",
        "It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents."
      ],
      "question": "Taylor visits the gym at least once a day.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 175,
    "nl_problem": {
      "context": [
        "All people who eat salads regularly are very conscious about their health and eating habits.",
        "All people who grew up in health-conscious childhood homes eat salads regularly.",
        "All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.",
        "If people have good relationships with their parents, then they fulfill their nutritional daily intakes.",
        "If people have good relationships with their parents, then they do not eat salads regularly.",
        "If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.",
        "It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents."
      ],
      "question": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 176,
    "nl_problem": {
      "context": [
        "[BG] The Olympic games is a sporting event. ",
        "The last Olympic games was in Tokyo.",
        "The United States won the most medals in Tokyo. "
      ],
      "question": "The world championships is a sporting event.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"SportingEvent(x)\", \"LastOlympicsGames(x)\", \"USMedalWins(x, y)\"],\"fol_consts\": [\"Olympic Games\",\"Tokyo\", \"World Championships\"],\"fol_rules\": [\"\"],\n  \"fol_conc\": \"\"\n} ",
      "perplexity": 2.386343479156494,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": ""
    }
  },
  {
    "id": 177,
    "nl_problem": {
      "context": [
        "[BG] The Olympic games is a sporting event. ",
        "The last Olympic games was in Tokyo.",
        "The United States won the most medals in Tokyo. "
      ],
      "question": "The last Olympic games were not in Tokyo.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 178,
    "nl_problem": {
      "context": [
        "[BG] The Olympic games is a sporting event. ",
        "The last Olympic games was in Tokyo.",
        "The United States won the most medals in Tokyo. "
      ],
      "question": "The United States won the most medals in the last Olympic games.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 179,
    "nl_problem": {
      "context": [
        "All horses have hooves.",
        "No humans have hooves."
      ],
      "question": "Some humans are horses.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 180,
    "nl_problem": {
      "context": [
        "Susan flies to LGA airport.",
        "The departure and arrival can not be the same airport.",
        "John flies from LGA airport."
      ],
      "question": "Susan flies from LGA airport.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 181,
    "nl_problem": {
      "context": [
        "Susan flies to LGA airport.",
        "The departure and arrival can not be the same airport.",
        "John flies from LGA airport."
      ],
      "question": "John flies to LGA airport.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"flies(x, y)\", \"departure(x)\", \"arrival(x)\", \"sameairport(x,y)\"],\"fol_consts\":[\"Susan\",\"LGA\",\"John\"], \"fol_rules\": [\"\"], \"fol_conc\":\"John flies to LGA airport\"} ",
      "perplexity": 1.995105504989624,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "John flies to LGA airport"
    }
  },
  {
    "id": 182,
    "nl_problem": {
      "context": [
        "No one nice to animals is mean to animals.",
        "Some grumpy people are mean to animals.",
        "All animal lovers are nice to animals.",
        "If someone owns a pet, then they love animals.",
        "Tom is a pet owner."
      ],
      "question": "Tom is a grumpy person.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 183,
    "nl_problem": {
      "context": [
        "No one nice to animals is mean to animals.",
        "Some grumpy people are mean to animals.",
        "All animal lovers are nice to animals.",
        "If someone owns a pet, then they love animals.",
        "Tom is a pet owner."
      ],
      "question": "Tom is not a grumpy person and mean to animals.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 184,
    "nl_problem": {
      "context": [
        "No one nice to animals is mean to animals.",
        "Some grumpy people are mean to animals.",
        "All animal lovers are nice to animals.",
        "If someone owns a pet, then they love animals.",
        "Tom is a pet owner."
      ],
      "question": "If Tom is not a grumpy person and mean to animals, then Tom is neither a grumpy person nor an Animal Lover.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 185,
    "nl_problem": {
      "context": [
        "A podcast is not a novel.",
        "[BG] If a person is born in American City, the person is American.",
        "[BG] If a book is novel and it is written by a person, then the person is a novel writer.",
        "Dani Shapiro is an American writer.",
        "Family History is written by Dani Shapiro.",
        "Family History is a novel written in 2003.",
        "Dani Shapiro created a podcast called Family Secrets.",
        "[BG] Boston is an American city."
      ],
      "question": "Dani Shapiro is a novel writer.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 186,
    "nl_problem": {
      "context": [
        "A podcast is not a novel.",
        "[BG] If a person is born in American City, the person is American.",
        "[BG] If a book is novel and it is written by a person, then the person is a novel writer.",
        "Dani Shapiro is an American writer.",
        "Family History is written by Dani Shapiro.",
        "Family History is a novel written in 2003.",
        "Dani Shapiro created a podcast called Family Secrets.",
        "[BG] Boston is an American city."
      ],
      "question": "Family Secrets is a novel.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 187,
    "nl_problem": {
      "context": [
        "A podcast is not a novel.",
        "[BG] If a person is born in American City, the person is American.",
        "[BG] If a book is novel and it is written by a person, then the person is a novel writer.",
        "Dani Shapiro is an American writer.",
        "Family History is written by Dani Shapiro.",
        "Family History is a novel written in 2003.",
        "Dani Shapiro created a podcast called Family Secrets.",
        "[BG] Boston is an American city."
      ],
      "question": "Dani Shapiro was born in Boston.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 188,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "Yuri is an American.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Player(x)\", \"American(x)\", \"Tall(x)\", \"LargeShoeSize(x)\", \"LargeClothesSize(x)\"],\"fol_consts\": [ \"yuri\"],\"fol_rules\": [],\"fol_conc\":\"american(yuri)\" } ",
      "perplexity": 2.2491202354431152,
      "answer": "C",
      "predicted_answer": "C",
      "status": "success",
      "error": ""
    }
  },
  {
    "id": 189,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "Yuri is not an American basketball player.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 190,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "Yuri is an American basketball player.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 191,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "If Yuri does not wear large shoes, then Yuri is an American basketball player.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 192,
    "nl_problem": {
      "context": [
        "Some basketball players are not American.",
        "All basketball players are tall.",
        "If someone is tall, they wear large shoes.",
        "If someone wears large shoes, they wear large-sized clothes.",
        "Yuri does not wear large-size clothes."
      ],
      "question": "If Yuri is not an American basketball player, then Yuri is a basketball player.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 193,
    "nl_problem": {
      "context": [
        "Events are either happy or sad.",
        "At least one event is happy. "
      ],
      "question": "All events are sad.",
      "options": [],
      "answer": "B"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\"Happy(x)\", \"Sad(x)\"],\n\"fol_consts\": [],\n\"fol_rules\": [], \",\"\n  : 0.5,\n   \"fol_conc\": \"All events are sad.\"}\n",
      "perplexity": 4.6688947677612305,
      "answer": "B",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": "All events are sad."
    }
  },
  {
    "id": 194,
    "nl_problem": {
      "context": [
        "The winner of the 1992 du Maurier Classic was Steinhauer.",
        "Steinhauer participated in the 1992 du Maurier Classic.",
        "There was one six-way tie on the leaderboard and one person in the six-way tie was from Belgium.",
        "Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.",
        "All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic."
      ],
      "question": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 195,
    "nl_problem": {
      "context": [
        "The winner of the 1992 du Maurier Classic was Steinhauer.",
        "Steinhauer participated in the 1992 du Maurier Classic.",
        "There was one six-way tie on the leaderboard and one person in the six-way tie was from Belgium.",
        "Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.",
        "All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic."
      ],
      "question": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 196,
    "nl_problem": {
      "context": [
        "If an animal barks, then Jane does not like it.",
        "All dogs are animals that bark.",
        "If an animal jumps, then Jane likes it.",
        "If an animal has legs, then it jumps.",
        "If an animal is terricolous, then it has legs. ",
        "If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs."
      ],
      "question": "KiKi is terricolous.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 197,
    "nl_problem": {
      "context": [
        "If an animal barks, then Jane does not like it.",
        "All dogs are animals that bark.",
        "If an animal jumps, then Jane likes it.",
        "If an animal has legs, then it jumps.",
        "If an animal is terricolous, then it has legs. ",
        "If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs."
      ],
      "question": "KiKi barks and is a dog.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 198,
    "nl_problem": {
      "context": [
        "If an animal barks, then Jane does not like it.",
        "All dogs are animals that bark.",
        "If an animal jumps, then Jane likes it.",
        "If an animal has legs, then it jumps.",
        "If an animal is terricolous, then it has legs. ",
        "If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs."
      ],
      "question": "KiKi neither barks nor is a dog.",
      "options": [],
      "answer": "A"
    }
  },
  {
    "id": 199,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "No one playing for Nautico is Brazilian.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 200,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton Silva foes not play for a football club.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 201,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton was not loaned out to a football club.",
      "options": [],
      "answer": "B"
    }
  },
  {
    "id": 202,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton Silva played for Fluminense.",
      "options": [],
      "answer": "C"
    }
  },
  {
    "id": 203,
    "nl_problem": {
      "context": [
        "Ailton Silva, born in 1995, is commonly known as Ailton.",
        "Ailton is a football player who was loaned out to Braga.",
        "Ailton Silva is a Brazillian footballer who plays for Nautico.",
        "Nautico is a football club along with Braga.",
        "Fluminense is a football club."
      ],
      "question": "Ailton Silva was loaned out to a football club.",
      "options": [],
      "answer": "C"
    },
    "logic_problem_json": {
      "raw": "{\"fol_preds\": [\n  \"Born(x, y)\",\n  \"KnownAs(x, y)\",\n  \"FootballPlayer(x)\",\n  \"LoanedOutTo(x, y)\", \"],\" ]}",
      "perplexity": 3.45862078666687,
      "answer": "C",
      "predicted_answer": "N/A",
      "status": "parsing error",
      "error": null
    }
  }
]