\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{multirow}
\usepackage{parskip}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Conference Paper Title*\\
% {\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
% should not be used}
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

% Iterative process of working on project
% Iterating early > iterating late

% Define problem
% Write statement + question (measurable, achievable)
% Study literature
% Refine problem statement with precisemetrics (do not put solution together and then optimize for best metric). Limit the scope.
% If the metric changes the problem then it's ok
% Make a plan after 1 month to stick to.
% Baseline (Hermes). Have to do anyway later but doing it earlier allows you to implement the initial framework.
% Design solution.
% Thesis outline, only sections and subsections headers. Define experiments.
% Do experiments, get results. Define tables and visualizations, what would go there etc.
% Detailed outline: each section and subsec only 1 sentence or bullets. Add figures and tables.
% Write thesis: abstract, discussion, results, methods, background, intro, conclusion.
% Every section should describe what comes after and nothing more.
% Every paragraph should contain one idea, given in the first sentence.


% Deliverable:
% 12 page paper (shorter is fine), double column, IEEE format. If many details/experiments, put in appendix.
% Dockerized version of code to reproduce easily.

% Responsibilities:
% After 1 month make plan and discuss with Mike
% Meet once every two weeks

% What Mike does:
% Review outline until ok
% review test twice
% after 30 comments no more review

\author{\IEEEauthorblockN{1\textsuperscript{st} Federico Raspanti}
\IEEEauthorblockA{
    \textit{Eindhoven University of Technology} \\
    \textit{Université Cöte d'Azur}\\
    City, Country \\
    f.raspanti@student.tue.nl
    }
}

\maketitle

\begin{abstract}
% \lipsum[1]
\end{abstract}

\begin{IEEEkeywords}
% component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction}
% \lipsum[1-2]
% Please state your research question(s) and intended contributions.

% Introduction usually follows this structure: context, 
% motivation, problem, research questions, contributions.
\subsection*{context}
LLMs have shown remarkable capabilities for logical reasoning, especially when 
guided with prompting techniques such as chain-of-thought and few-shot examples

\subsection*{motivation}
The autoregressive nature of LLMs prevents them from reasoning in a determistic
and truly logical fashion, making them unreliable when it comes to logical reasoning task.

\subsection*{problem}

Given a natural language reasoning problem \\
$P_{NL} = (R_{NL}, Q_{NL})$.\\
$R_{NL} =$ list of rules in natural language\\
$Q_{NL} =$ statement to be proven

We aim to extract \\
$P_{LOG} = (R_{LOG}, Q_{LOG})$ \\
$R_{LOG} =$ list of logical rules\\
$Q_{LOG} =$ logical statement to be proven


\subsection*{research questions}

\begin{itemize}
    \item \textbf{R1}: Does the \textit{accuracy} (F1 score) of the generated logical problems improve when 
    providing \textit{embedding-wise} similar few-shot examples?
    \item \textbf{R2}: By using Grammar Constrained Decoding (GCD) to guarantee \textit{validity}, how 
    much does the LLM's response degrade?
\end{itemize}

\subsection*{contributions}

\begin{itemize}
    \item we show the impact of semantic similarity in NL-Logic conversion.
    \item we provide a new approach to self-correcting of the LLM's mistakes by dynamicall generating
    grammar constraints
\end{itemize}

\section{Related Work}
\subsection{Logic-LM}
% \lipsum[3]

\subsection{LoGiPT}
% \lipsum[4]

\subsection{LLM-R}
% \lipsum[5]

\section{Preliminaries}
\subsection{Grammar-Constrained Decoding}
% \lipsum[6]

\subsection{In-context Learning}
% \lipsum[7]

\subsection{Chain-of-thought Reasoning}
% \lipsum[8]

\section{Methodology}
% \lipsum[9]

\subsection{Retrieving Relevant Examples}
% \lipsum[11]
For each test problem, we retrieve the most similar problems from our datasets' training sets 
by ranking them according to \textit{cosine score} of their embeddings.

\subsection{Sketching}
We use a powerful, black-box LLM to convert the NL problems to Logical Problems.

\subsection{Grammar-Constrained Formulation}
We use an open-source model with logit access to correct all \textit{invalid} logical problems
generated during Sketching

% \subsection{Pooling the Formulations}
% \subsubsection{Free-form Formulation}
% % \lipsum[16]

% \subsubsection{Grammar-Constrained Formulation}
% \lipsum[17]

\subsection{Solving the Problem}
We use a symbolic solver to solve the generated logical problem.

\subsubsection*{First-Order-Logic}
We use Prover9
% \lipsum[18]

\subsubsection*{Logic Programming}
We use pyke
% \lipsum[19]

\section{Experiments}
\subsection{Datasets}

\subsubsection*{FOLIO}
\subsubsection*{PrOntoQA}
\subsubsection*{ProofWriter}

% \lipsum[25-26]

\subsection{Baselines}
% \lipsum[25-26]

\subsection{Metrics}
% \lipsum[27]

\subsection{Implementaion Details}
% \lipsum[28]

\section{Results}
% \lipsum[29]

\begin{table*}[t]
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    \textbf{Dataset}                                                            & \multicolumn{1}{c|}{Accuracy (F1)} & \multicolumn{1}{c|}{Formula Validity}  \\ \hline
    \textbf{Logic-LM}                                                           & $59.25$|$54.67$      &    \\ 
    \multicolumn{1}{|r|}{+Refinement}                                           & $58.69$|$58.57$      &    \\ \hline  
    \textbf{DynoReasoner}                                                       & $63.12$|$62.93$      &    \\ 
    \multicolumn{1}{|r|}{\hspace{1cm}+Refinement}                               & $62.16$                &    \\ 
    \multicolumn{1}{|r|}{\hspace{1cm}+Constrained Generation}                   & $63.55$                &    \\ 
    \multicolumn{1}{|r|}{\hspace{1cm}+Refinement \& Constrained Generation}     &                          &    \\ \hline
    % \textbf{DynoReasoner 2Steps}                                                & $64.53\%$      &  &  \\ \hline
\end{tabular}
\caption{Accuracy of executable samples (F1)}    
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Dataset}                    & \textbf{Logic-LM}       & \textbf{+ Refinement}     &      \textbf{+ Dynamic Examples}  & \textbf{+ Both}             \\ \hline
    % FOLIO                               &      $63.72\%$           &     $63.72\%$             &                                     &                          \\ \hline
    FOLIOv2                             &      $61.57\%$           &     $60.59\%$             &      \textbf{64.03\%}                      &           $63.54\%$        \\ \hline
    PrOntoQA                            &                          &                           &                                     &                          \\ \hline
    ProofWriter                         &                          &                           &                                     &                          \\ \hline
\end{tabular}
\caption{Accuracy (F1) with Few-shot CoT backup if samples are non-executable}    
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Dataset}                    &       \textbf{Direct Few-shot}         & \textbf{CoT Few-shot}                                  \\ \hline
    FOLIOv2                             &  $47.05\%$|$42.85$|$41.37$    &  $66.17\%$|$64.61\%$|$66.12\%$|$67.27\%$      \\ \hline
    PrOntoQA                            &                               &                                               \\ \hline
    ProofWriter                         &                               &                                               \\ \hline
    \end{tabular}
\caption{Accuracy (F1) of backup on non-executable samples}    
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Dataset}                    &       \textbf{Direct Few-shot}         & \textbf{CoT Few-shot}                                  \\ \hline
    FOLIOv2                             &  $47.05\%$|$42.85$|$41.37$    &  $66.17\%$|$64.61\%$|$66.12\%$|$67.27\%$      \\ \hline
    PrOntoQA                            &                               &                                               \\ \hline
    ProofWriter                         &                               &                                               \\ \hline
    \end{tabular}
\caption{Accuracy (F1) of backup on non-executable samples}    
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Dataset}                    & \textbf{Logic-LM}             & \textbf{+ Refinement}         & \textbf{+ Dynamic Examples}         & \textbf{+ Both}           \\ \hline
    % FOLIO                               &  $59.80\%$|$59.80\%$                    &     $61.76\%$|$61.27\%$                &                                   &         \\ \hline
    FOLIOv2                             &  $66.50\%$|$68.47\%$          &     $67.98\%$|$68.96\%$       &      $69.45\%$|$70.44\%$          &     \textbf{72.90\%}    \\ \hline
    PrOntoQA                            &                               &                               &                                   &         \\ \hline
    ProofWriter                         &                               &                               &                                   &         \\ \hline
    \end{tabular}
\caption{Fully executable samples rate - samples that can be both parsed and executed (\%)}    
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Dataset}                    & \textbf{Logic-LM}     & \textbf{+ Refinement}         & \textbf{+ Dynamic Examples}       & \textbf{+ Both}                \\ \hline
    FOLIOv2                             &  \textbf{13.79\%}     &     $13.79\%$|$14.28\%$       &      $15.27\%$|$15.76\%$          &     $14.77\%$                  \\ \hline
    PrOntoQA                            &                       &                               &                                   &                                \\ \hline
    ProofWriter                         &                       &                               &                                   &                                \\ \hline
    \end{tabular}
\caption{Parsing errors rate (\%)}    
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Dataset}                    & \textbf{Logic-LM}     & \textbf{+ Refinement}         & \textbf{+ Dynamic Examples}       & \textbf{+ Both}                \\ \hline
    FOLIOv2                             &  $19.70\%$            &     $18.22\%$|$16.74\%$       &      $15.27\%$|$12.80\%$          &     \textbf{12.31\%}           \\ \hline
    PrOntoQA                            &                       &                               &                                   &                                \\ \hline
    ProofWriter                         &                       &                               &                                   &                                \\ \hline
    \end{tabular}
\caption{Execution errors rate (\%)}    
\end{table*}




% \begin{table*}[t!]
%     \centering
%     \begin{tabular}{|c|ccc|c|ccc|}
%     \hline
%     \textbf{Dataset} & \multicolumn{3}{c|}{\textbf{Logic-LM}}            & \textbf{+ Refinement}        &      \multicolumn{3}{c|}{\textbf{Dymanic Examples}}             \\ \hline
%     \textbf{Backup}                   & \textbf{Random} & \textbf{Direct}               & \textbf{CoT} & \textbf{Direct}& \textbf{Random} & \textbf{Direct} & \textbf{CoT}  \\ \hline
%     FOLIO                             & $52.94\%$         &      $58.82\%$              &              &                    &         &            &                          \\ \hline
%     FOLIOv2                           & $45.32\%$         & $53.20\%$                   &              &     $55.17\%$     & $54.18\%$         &      $56.65\%$        &                           \\ \hline
%     PrOntoQA                          &                   &                             &              &                    &                   &              &                           \\ \hline
%     ProofWriter                       &                   &                             &              &                    &                   &              &                        \\ \hline
% \end{tabular}
% \caption{Accuracy (F1)}    
% \end{table*}

% \begin{table*}[t!]
%     \centering
%     \begin{tabular}{|c|ccc|c|ccc|}
%     \hline
%     \textbf{Dataset} & \multicolumn{3}{c|}{\textbf{Logic-LM}}    & \textbf{+ Refinement} & \multicolumn{3}{c|}{\textbf{Dymanic Examples}}       \\ \hline
%     \textbf{Backup}                     & \textbf{Random} & \textbf{Direct}     & \textbf{CoT} & \textbf{Direct}    & \textbf{Random} & \textbf{Direct} & \textbf{CoT}  \\ \hline
%     FOLIO                               &  $59.80\%$        &  $59.80\%$        &              &                        &                  &              &                 \\ \hline
%     FOLIOv2                             &  $68.47\%$        &  $68.47\%$        &              &    $71.42\%$       &        $69.95\%$           &     $70.44\%$         &                 \\ \hline
%     PrOntoQA                            &                   &                   &              &                        &                   &              &                        \\ \hline
%     ProofWriter                         &                   &                   &              &                        &                   &              &                        \\ \hline
%     \end{tabular}
% \caption{Exec\_Rate (\%)}    
% \end{table*}

% \begin{table*}[t!]
%     \centering
%     \begin{tabular}{|c|ccc|c|ccc|}
%     \hline
%     \textbf{Dataset} & \multicolumn{3}{c|}{\textbf{Logic-LM}} & \textbf{+ Refinement}    & \multicolumn{3}{c|}{\textbf{Dymanic Examples}}       \\ \hline
%     \textbf{Backup}                     & \textbf{Random}   & \textbf{Direct}      & \textbf{CoT} &   \textbf{Direct}         & \textbf{Random} & \textbf{Direct} & \textbf{CoT}  \\ \hline
%     FOLIO                               &  $66.39\%$        &  $66.39\%$           &              &                              &                   &              &                 \\ \hline
%     FOLIOv2                             &  $54.67\%$        &  $54.67\%$           &              &            $62.75\%$                 &       $62.67\%$            &     $62.93\%$         &                 \\ \hline
% PrOntoQA                                &                   &                          &              &                               &                   &              &                        \\ \hline
% ProofWriter                             &                   &                          &              &                               &                   &              &                        \\ \hline
%     \end{tabular}
% \caption{Exec\_Acc (\%)}    
% \end{table*}




\subsection{Main Results}
% \lipsum[30]

\subsection{Further Analysis}
\subsubsection{Impact of dynamic example retrieval}
% \lipsum[31]

% \subsubsection{Impact of chain-of-thought reasoning}
% \lipsum[33]

\subsubsection{Impact of Constrained decoding}
% \lipsum[32]

% \subsubsection{Impact of formulation pooling}
% \lipsum[34]

\subsubsection{Impact of self-verification loop}
% \lipsum[35]

\section{Conclusion and Future Work}
% \lipsum[36-38]

\section*{Acknowledgment}
% \lipsum[39]


% \begin{thebibliography}{00}
% \bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
% \bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
% \bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
% \bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
% \bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
% \bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
% \bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
% \end{thebibliography}


\appendix
\subsection{Grammars}
% \lipsum[40]
\subsection{Prompts}
% \lipsum[41]
\subsection{Formulations}
% \lipsum[42]
\end{document}
