{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils import OSModel\n",
    "from models.utils import calculate_perplexity\n",
    "from pprint import pp\n",
    "\n",
    "prompt_template= \"\"\"\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "[[question]]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "model = OSModel(\n",
    "    model_path='/data/users/fraspant/LLMs/llama-3.1-8b-it.gguf', n_ctx=512, logits_all=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.replace('[[question]]', 'Is the sun hot or cold?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar: None\n",
      "Response: The sun is extremely hot. Its surface temperature is about 5,500 degrees Celsius (9,932 degrees Fahrenheit), and its core is a scorching 15,000,000 degrees Celsius (27,000,000 degrees Fahrenheit). This intense heat is what makes the sun shine and gives us light and warmth.\n",
      "Perplexity: 1.163486123085022\n",
      "Logprobs:\n",
      "\n",
      "[{'The': np.float32(-0.00028093686)},\n",
      " {' sun': np.float32(-0.03550408)},\n",
      " {' is': np.float32(-0.003335153)},\n",
      " {' extremely': np.float32(-0.7449534)},\n",
      " {' hot': np.float32(-0.001265202)},\n",
      " {'.': np.float32(-0.07450456)},\n",
      " {' Its': np.float32(-0.6453549)},\n",
      " {' surface': np.float32(-0.003575007)},\n",
      " {' temperature': np.float32(-0.0024374798)},\n",
      " {' is': np.float32(-0.14349708)}]\n",
      "\n",
      "\n",
      "#########################\n",
      "\n",
      "\n",
      "Grammar: root ::= \"The sun is extremely hot\" \n",
      "Response: The sun is extremely hot\n",
      "Perplexity: 1.1700749397277832\n",
      "Logprobs:\n",
      "\n",
      "[{'The': np.float32(-0.00028093686)},\n",
      " {' sun': np.float32(-0.03550408)},\n",
      " {' is': np.float32(-0.003335153)},\n",
      " {' extremely': np.float32(-0.7449534)},\n",
      " {' hot': np.float32(-0.001265202)}]\n",
      "\n",
      "\n",
      "#########################\n",
      "\n",
      "\n",
      "Grammar: root ::= \"The sun is extremely cold\" \n",
      "Response: The sun is extremely cold\n",
      "Perplexity: 26.019214630126953\n",
      "Logprobs:\n",
      "\n",
      "[{'The': np.float32(-0.00028093686)},\n",
      " {' sun': np.float32(-0.03550408)},\n",
      " {' is': np.float32(-0.003335153)},\n",
      " {' extremely': np.float32(-0.7449534)},\n",
      " {' hot': np.float32(-0.001265202), ' cold': np.float32(-15.510102)}]\n",
      "\n",
      "\n",
      "#########################\n",
      "\n",
      "\n",
      "Grammar: root ::= \"The sun is a square\" \n",
      "Response: The sun is a square\n",
      "Perplexity: 335.3362121582031\n",
      "Logprobs:\n",
      "\n",
      "[{'The': np.float32(-0.00028093686)},\n",
      " {' sun': np.float32(-0.03550408)},\n",
      " {' is': np.float32(-0.003335153)},\n",
      " {' extremely': np.float32(-0.7449534), ' a': np.float32(-6.5223007)},\n",
      " {' massive': np.float32(-0.18033041), ' s': np.float32(-9.631769)},\n",
      " {'izzling': np.float32(-0.030016523), 'quare': np.float32(-18.697609)}]\n",
      "\n",
      "\n",
      "#########################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for raw_grammar in [None, 'root ::= \"The sun is extremely hot\" ', 'root ::= \"The sun is extremely cold\" ', 'root ::= \"The sun is a square\" ']:\n",
    "    response = model.invoke(prompt=prompt, logprobs = True, max_tokens=150, \n",
    "                            raw_grammar=raw_grammar,\n",
    "                            temperature=0.5,\n",
    "                            top_p = 1,\n",
    "                            top_k=10,\n",
    "                            min_p=0.1,\n",
    "                            tfs_z=1,\n",
    "                            repeat_penalty=1,)\n",
    "\n",
    "    print('Grammar:', raw_grammar)\n",
    "    print('Response:', response['choices'][0]['text'])\n",
    "    print('Perplexity:', calculate_perplexity(response['choices'][0]['logprobs']))\n",
    "    print('Logprobs:\\n')\n",
    "    pp(response['choices'][0]['logprobs']['top_logprobs'][:10])\n",
    "    print('\\n')\n",
    "    print('#'*25)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The sun is extremely hot\n",
      "Perplexity: 1.1700749397277832\n",
      "Logprobs:\n",
      "\n",
      "[{'The': np.float32(-0.00028093686)},\n",
      " {' sun': np.float32(-0.03550408)},\n",
      " {' is': np.float32(-0.003335153)},\n",
      " {' extremely': np.float32(-0.7449534)},\n",
      " {' hot': np.float32(-0.001265202)}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = model.invoke(prompt=prompt, logprobs = True, max_tokens=150, \n",
    "                        raw_grammar=raw_grammar,\n",
    "                        temperature=0.5,\n",
    "                        top_p = 1,\n",
    "                        top_k=10,\n",
    "                        min_p=0.1,\n",
    "                        tfs_z=1,\n",
    "                        repeat_penalty=1,)\n",
    "\n",
    "print('Response:', response['choices'][0]['text'])\n",
    "print('Perplexity:', calculate_perplexity(response['choices'][0]['logprobs']))\n",
    "print('Logprobs:\\n')\n",
    "pp(response['choices'][0]['logprobs']['top_logprobs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The sun is extremely cold\n",
      "Perplexity: 26.019214630126953\n",
      "Logprobs:\n",
      "\n",
      "[{'The': np.float32(-0.00028093686)},\n",
      " {' sun': np.float32(-0.03550408)},\n",
      " {' is': np.float32(-0.003335153)},\n",
      " {' extremely': np.float32(-0.7449534)},\n",
      " {' hot': np.float32(-0.001265202), ' cold': np.float32(-15.510102)}]\n"
     ]
    }
   ],
   "source": [
    "raw_grammar = \"\"\"root ::= \"The sun is extremely cold\" \"\"\"\n",
    "\n",
    "response = model.invoke(prompt=prompt, logprobs = True, max_tokens=150, \n",
    "                        raw_grammar=raw_grammar,\n",
    "                        temperature=0.5,\n",
    "                        top_p = 1,\n",
    "                        top_k=10,\n",
    "                        min_p=0.1,\n",
    "                        tfs_z=1,\n",
    "                        repeat_penalty=1,)\n",
    "\n",
    "print('Response:', response['choices'][0]['text'])\n",
    "print('Perplexity:', calculate_perplexity(response['choices'][0]['logprobs']))\n",
    "print('Logprobs:\\n')\n",
    "pp(response['choices'][0]['logprobs']['top_logprobs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The sun is a square\n",
      "Perplexity: 335.3362121582031\n",
      "Logprobs:\n",
      "\n",
      "[{'The': np.float32(-0.00028093686)},\n",
      " {' sun': np.float32(-0.03550408)},\n",
      " {' is': np.float32(-0.003335153)},\n",
      " {' extremely': np.float32(-0.7449534), ' a': np.float32(-6.5223007)},\n",
      " {' massive': np.float32(-0.18033041), ' s': np.float32(-9.631769)},\n",
      " {'izzling': np.float32(-0.030016523), 'quare': np.float32(-18.697609)}]\n"
     ]
    }
   ],
   "source": [
    "raw_grammar = \"\"\"root ::= \"The sun is a square\" \"\"\"\n",
    "\n",
    "response = model.invoke(prompt=prompt, logprobs = True, max_tokens=150, \n",
    "                        raw_grammar=raw_grammar,\n",
    "                        temperature=0.5,\n",
    "                        top_p = 1,\n",
    "                        top_k=10,\n",
    "                        min_p=0.1,\n",
    "                        tfs_z=1,\n",
    "                        repeat_penalty=1,)\n",
    "\n",
    "print('Response:', response['choices'][0]['text'])\n",
    "print('Perplexity:', calculate_perplexity(response['choices'][0]['logprobs']))\n",
    "print('Logprobs:\\n')\n",
    "pp(response['choices'][0]['logprobs']['top_logprobs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth of proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from models.symbolic_solvers.fol_solver.Formula import FOL_Formula\n",
    "from models.symbolic_solvers.fol_solver.prover9_solver import FOL_Prover9_Program\n",
    "\n",
    "def check_fol_validity(premises, conclusion):\n",
    "    # Validate premises\n",
    "    fol_premises = []\n",
    "    for premise in premises:\n",
    "        fol_formula = FOL_Formula(premise)\n",
    "        \n",
    "        if not fol_formula.is_valid:\n",
    "            print(f\"Invalid FOL premise: {premise}\")\n",
    "            return False\n",
    "        fol_premises.append(fol_formula)\n",
    "    \n",
    "    # Validate conclusion\n",
    "    fol_conclusion = FOL_Formula(conclusion)\n",
    "    if not fol_conclusion.is_valid:\n",
    "        print(f\"Invalid FOL conclusion: {conclusion}\")\n",
    "        return False\n",
    "    \n",
    "    # Create logic program\n",
    "    logic_program = {\n",
    "        \"fol_rules\": premises,\n",
    "        \"fol_conc\": conclusion\n",
    "    }\n",
    "    \n",
    "    # Use FOL_Prover9_Program to check validity\n",
    "    prover9_program = FOL_Prover9_Program(logic_program)\n",
    "    \n",
    "    if not prover9_program.flag:\n",
    "        print(f\"Error in logic program: {prover9_program.formula_error}\")\n",
    "        return False\n",
    "    \n",
    "    answer, error_message = prover9_program.execute_program()\n",
    "    if error_message:\n",
    "        print(f\"Error during execution: {error_message}\")\n",
    "        return True\n",
    "    \n",
    "    return True, prover9_program, answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "premises = [\n",
    "      \"∀x (TalentShows(x) → Engaged(x))\",\n",
    "      \"∀x (TalentShows(x) ∨ Inactive(x))\",\n",
    "      \"∀x (Chaperone(x) → ¬Students(x))\",\n",
    "      \"∀x (Inactive(x) → Chaperone(x))\",\n",
    "      \"∀x (AcademicCareer(x) → Students(x))\",\n",
    "      \"(Engaged(bonnie) ∧ Students(bonnie)) ⊕ (¬Engaged(bonnie) ∧ ¬Students(bonnie))\"\n",
    "    ]\n",
    "conclusion = \"AcademicCareer(bonnie) ⊕ Chaperone(bonnie) → AcademicCareer(bonnie) ⊕ Inactive(bonnie)\"\n",
    "\n",
    "is_valid, prover9_program, answer = check_fol_validity(premises, conclusion)\n",
    "if is_valid:\n",
    "    print(\"The premises and conclusion are valid.\")\n",
    "else:\n",
    "    print(\"The premises and conclusion are not valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== prooftrans ============================\n",
      "Prover9 (64) version 2009-11A, November 2009.\n",
      "Process 57838 was started by fraspant on hotpot,\n",
      "Mon Oct 28 18:00:00 2024\n",
      "The command was \"models/symbolic_solvers/Prover9/bin/prover9\".\n",
      "============================== end of head ===========================\n",
      "\n",
      "============================== end of input ==========================\n",
      "\n",
      "============================== PROOF =================================\n",
      "\n",
      "% -------- Comments from original proof --------\n",
      "% Proof 1 at 0.00 (+ 0.00) seconds.\n",
      "% Length of proof is 27.\n",
      "% Level of proof is 6.\n",
      "% Maximum clause weight is 2.000.\n",
      "% Given clauses 0.\n",
      "\n",
      "\n",
      "1 (all x (TalentShows(x) -> Engaged(x))).  [assumption].\n",
      "2 (all x (TalentShows(x) | Inactive(x))).  [assumption].\n",
      "3 (all x (Chaperone(x) -> -Students(x))).  [assumption].\n",
      "4 (all x (Inactive(x) -> Chaperone(x))).  [assumption].\n",
      "5 (all x (AcademicCareer(x) -> Students(x))).  [assumption].\n",
      "6 Engaged(Bonnie) & Students(Bonnie) & -(-Engaged(Bonnie) & -Students(Bonnie)) | -(Engaged(Bonnie) & Students(Bonnie)) & -Engaged(Bonnie) & -Students(Bonnie).  [assumption].\n",
      "7 (AcademicCareer(Bonnie) & -Chaperone(Bonnie) | -AcademicCareer(Bonnie) & Chaperone(Bonnie) -> AcademicCareer(Bonnie)) & -Inactive(Bonnie) | -(AcademicCareer(Bonnie) & -Chaperone(Bonnie) | -AcademicCareer(Bonnie) & Chaperone(Bonnie) -> AcademicCareer(Bonnie)) & Inactive(Bonnie).  [goal].\n",
      "8 TalentShows(x) | Inactive(x).  [clausify(2)].\n",
      "9 -TalentShows(x) | Engaged(x).  [clausify(1)].\n",
      "10 -Inactive(x) | Chaperone(x).  [clausify(4)].\n",
      "11 -Chaperone(x) | -Students(x).  [clausify(3)].\n",
      "12 AcademicCareer(Bonnie) | Chaperone(Bonnie) | Inactive(Bonnie).  [deny(7)].\n",
      "13 AcademicCareer(Bonnie) | -Chaperone(Bonnie) | -Inactive(Bonnie).  [deny(7)].\n",
      "14 AcademicCareer(Bonnie) | Inactive(Bonnie) | -Students(Bonnie).  [resolve(12,b,11,a)].\n",
      "15 -AcademicCareer(x) | Students(x).  [clausify(5)].\n",
      "16 -AcademicCareer(Bonnie) | Inactive(Bonnie).  [deny(7)].\n",
      "17 AcademicCareer(Bonnie) | -Inactive(Bonnie) | -Inactive(Bonnie).  [resolve(13,b,10,b)].\n",
      "18 Students(Bonnie) | -Engaged(Bonnie).  [clausify(6)].\n",
      "20 Inactive(x) | Engaged(x).  [resolve(8,a,9,a)].\n",
      "21 -Inactive(Bonnie) | -Inactive(Bonnie) | Students(Bonnie).  [resolve(17,a,15,a)].\n",
      "22 -Inactive(x) | -Students(x).  [resolve(10,b,11,a)].\n",
      "23 Inactive(Bonnie) | -Students(Bonnie) | Inactive(Bonnie).  [resolve(14,a,16,a)].\n",
      "24 Inactive(Bonnie) | Students(Bonnie).  [resolve(20,b,18,b)].\n",
      "25 -Inactive(Bonnie) | -Inactive(Bonnie) | -Inactive(Bonnie).  [resolve(21,c,22,b)].\n",
      "26 -Inactive(Bonnie).  [copy(25),merge(b),merge(c)].\n",
      "27 Inactive(Bonnie) | Inactive(Bonnie) | Inactive(Bonnie).  [resolve(24,b,23,b)].\n",
      "28 $F.  [copy(27),merge(b),merge(c),unit_del(a,26)].\n",
      "\n",
      "============================== end of proof ==========================\n"
     ]
    }
   ],
   "source": [
    "print(prover9_program.prover.proof())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
